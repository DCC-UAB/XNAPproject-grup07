HEAD
{"cells":[{"cell_type":"markdown","metadata":{"_uuid":"969bd0a45cfbe4f4804ac2f920de35cbbc7bf1a8"},"source":["# Overview\n","\n","Can a computer \"learn\" to classify artists by their paintings? \n","\n","ResNet50 is a good model for classifying ImageNet data. How about a set of 38 artists?\n","\n","We use transfer learning to re-train a ResNet50 model to identify one of 38 artists who have more than ~~300~~ ***200*** paintings in the dataset. \n","\n","This notebook is part of a project for CSC 480 taught by [Dr. Franz J. Kurfess](http://users.csc.calpoly.edu/~fkurfess/) at Cal Poly\n","\n","A web application is [in development](https://github.com/SomethingAboutImages/WebImageClassifier) to make use of the model that this notebook outputs. "]},{"cell_type":"code","execution_count":4,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":false,"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","scrolled":true,"trusted":true},"outputs":[],"source":["import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","# %matplotlib inline\n","import matplotlib.pyplot as plt\n","from random import seed # for setting seed\n","import tensorflow\n","from IPython import sys_info\n","\n","import gc # garbage collection"]},{"cell_type":"code","execution_count":5,"metadata":{"_uuid":"4cd71d6411b0bb2bee9d5a9f2421f8310509e008","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["{'commit_hash': '37242ba43',\n"," 'commit_source': 'installation',\n"," 'default_encoding': 'utf-8',\n"," 'ipython_path': '/anaconda/envs/azureml_py38_PT_and_TF/lib/python3.8/site-packages/IPython',\n"," 'ipython_version': '8.12.0',\n"," 'os_name': 'posix',\n"," 'platform': 'Linux-5.15.0-1061-azure-x86_64-with-glibc2.10',\n"," 'sys_executable': '/anaconda/envs/azureml_py38_PT_and_TF/bin/python',\n"," 'sys_platform': 'linux',\n"," 'sys_version': '3.8.5 (default, Sep  4 2020, 07:30:14) \\n[GCC 7.3.0]'}\n"]}],"source":["MY_SEED = 42 # 480 could work too\n","seed(MY_SEED)\n","np.random.seed(MY_SEED)\n","tensorflow.random.set_seed(MY_SEED)\n","\n","print(sys_info())\n","# get module information\n","# !pip freeze > frozen-requirements.txt\n","# append system information to file\n","with open(\"frozen-requirements.txt\", \"a\") as file:\n","    file.write(sys_info())"]},{"cell_type":"code","execution_count":6,"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"_uuid":"6bab4e1e53b22a9af9908fbefaeaa6f0e8b1110d","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["[name: \"/device:CPU:0\"\n","device_type: \"CPU\"\n","memory_limit: 268435456\n","locality {\n","}\n","incarnation: 7910028659058601276\n","xla_global_id: -1\n",", name: \"/device:GPU:0\"\n","device_type: \"GPU\"\n","memory_limit: 15247015936\n","locality {\n","  bus_id: 1\n","  links {\n","  }\n","}\n","incarnation: 3411629076494569092\n","physical_device_desc: \"device: 0, name: Tesla V100-PCIE-16GB, pci bus id: 0001:00:00.0, compute capability: 7.0\"\n","xla_global_id: 416903419\n","]\n"]},{"name":"stderr","output_type":"stream","text":["2024-05-09 14:56:21.599741: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-05-09 14:56:31.098864: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /device:GPU:0 with 14540 MB memory:  -> device: 0, name: Tesla V100-PCIE-16GB, pci bus id: 0001:00:00.0, compute capability: 7.0\n"]}],"source":["from tensorflow.python.client import device_lib\n","# print out the CPUs and GPUs\n","print(device_lib.list_local_devices())"]},{"cell_type":"code","execution_count":7,"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"_uuid":"1caeac96229a1e6db1d07b316cbfe62e1ee858d7","trusted":true},"outputs":[],"source":["# https://stackoverflow.com/questions/25705773/image-cropping-tool-python\n","# because painting images are hella big\n","from PIL import Image\n","Image.MAX_IMAGE_PIXELS = None"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"ca219817e229ad5e947b9a53a6bc9626cc7e2e02","trusted":true},"outputs":[],"source":["# globals\n","\n","DATA_DIR = '/home/xnmaster/Project/input/'\n","\n","TRAIN_1_DIR = '/home/xnmaster/Project/input/train_1'\n","# TRAIN_2_DIR = '../input/painters-train-part-1/train_2/train_2/'\n","# TRAIN_3_DIR = '../input/painters-train-part-1/train_3/train_3/'\n","\n","# TRAIN_4_DIR = '../input/painters-train-part-2/train_4/train_4/'\n","# TRAIN_5_DIR = '../input/painters-train-part-2/train_5/train_5/'\n","# TRAIN_6_DIR = '../input/painters-train-part-2/train_6/train_6/'\n","\n","# TRAIN_7_DIR = '../input/painters-train-part-3/train_7/train_7/'\n","# TRAIN_8_DIR = '../input/painters-train-part-3/train_8/train_8/'\n","# TRAIN_9_DIR = '../input/painters-train-part-3/train_9/train_9/'\n","\n","# TRAIN_DIRS = [TRAIN_1_DIR, TRAIN_2_DIR, TRAIN_3_DIR,\n","#              TRAIN_4_DIR, TRAIN_5_DIR, TRAIN_6_DIR,\n","#              TRAIN_7_DIR, TRAIN_8_DIR, TRAIN_9_DIR]\n","\n","TRAIN_DIRS = [TRAIN_1_DIR]\n","TEST_DIR = '/home/xnmaster/Project/input/test/'"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true,"_uuid":"8946b27facacf6814c81f06c53d34f8be7e5c53f","trusted":true},"outputs":[],"source":["df = pd.read_csv(DATA_DIR + 'train_info/train_info.csv')\n","print(\"df.shape\", df.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"_uuid":"8aa0abdf69b880c834752ab85206dfcb6fef38d9","trusted":true},"outputs":[],"source":["# # quick fix for corrupted files\n","# list_of_corrupted = ['3917.jpg','18649.jpg','20153.jpg','41945.jpg',\n","# '79499.jpg','91033.jpg','92899.jpg','95347.jpg',\n","# '100532.jpg','101947.jpg']\n","# # display the corrupted rows of dataset for context\n","# corrupt_df = df[df[\"new_filename\"].isin(list_of_corrupted) == True]\n","# print(corrupt_df.head(len(list_of_corrupted)))\n","\n","# # completely get rid of them\n","# df = df[df[\"new_filename\"].isin(list_of_corrupted) == False]\n","\n","# # try to see if they are still there\n","# print(df[df[\"new_filename\"].isin(list_of_corrupted) == True])\n","\n","# print(\"df.shape\", df.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["test_df = df[['artist', 'filename']]\n","print(\"test_df.shape\", test_df.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["test_df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_kg_hide-input":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"outputs":[],"source":["\n","# train_df = df[df[\"in_train\"] == True]\n","# test_df = df[df['in_train'] == False]\n","train_df = df[['artist', 'filename']]\n","# test_df = test_df[['artist', 'new_filename']]\n","\n","# print(\"test_df.shape\", test_df.shape)\n","print(\"train_df.shape\", train_df.shape)\n","\n","artists = {} # holds artist hash & the count\n","for a in train_df['artist']:\n","    if (a not in artists):\n","        artists[a] = 1\n","    else:\n","        artists[a] += 1\n","\n","training_set_artists = []\n","for a,count in artists.items():\n","    if(int(count) >= 200):\n","        training_set_artists.append(a)\n","\n","print(\"number of artists\",len(training_set_artists))\n","\n","print(\"\\nlist of artists...\\n\", training_set_artists)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true,"_uuid":"374cf6e0025c7221bbd1973c88f3702158e38c3f","trusted":true},"outputs":[],"source":["t_df = train_df[train_df[\"artist\"].isin(training_set_artists)]\n","\n","t_df.head(5)"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true,"_uuid":"b44f0b775da104dd716f4601cc164e7c4284bcec","trusted":true},"outputs":[],"source":["t1_df = t_df[t_df['filename'].str.startswith('1')]\n","\n","t2_df = t_df[t_df['filename'].str.startswith('2')]\n","\n","t3_df = t_df[t_df['filename'].str.startswith('3')]\n","\n","t4_df = t_df[t_df['filename'].str.startswith('4')]\n","\n","t5_df = t_df[t_df['filename'].str.startswith('5')]\n","\n","t6_df = t_df[t_df['filename'].str.startswith('6')]\n","\n","t7_df = t_df[t_df['filename'].str.startswith('7')]\n","\n","t8_df = t_df[t_df['filename'].str.startswith('8')]\n","\n","t9_df = t_df[t_df['filename'].str.startswith('9')]\n","\n","all_train_dfs = [t1_df, t2_df, t3_df,\n","                t4_df, t5_df, t6_df,\n","                t7_df, t8_df, t9_df]\n","\n","t9_df.head(5)"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":false,"_kg_hide-output":false,"_uuid":"9f35f9102dabe4fd4c05d9b4da88929811c574cd","trusted":true},"outputs":[],"source":["from tensorflow.keras.applications import ResNet50\n","from tensorflow.python.keras.models import Sequential\n","from tensorflow.python.keras.layers import Dense, Flatten, GlobalAveragePooling2D\n","\n","from tensorflow.keras.applications.resnet50 import preprocess_input\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n"]},{"cell_type":"markdown","metadata":{"_uuid":"30506b48fd6f5fd2636520b60baed80e20b8b944"},"source":["# specify the model that classifies 38 artists 🎨 🖌"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"e74625505706e025d7981c6712d21861f3ff6407","trusted":true},"outputs":[],"source":["len(training_set_artists)"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"d3222704a8161b0530f4df9911acbbc54ce97039","trusted":true},"outputs":[],"source":["num_classes = len(training_set_artists) # one class per artist\n","weights_notop_path = '../input/resnet50/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5'\n","model_adam = Sequential()\n","model_adam.add(ResNet50(\n","  include_top=False,\n","  weights='imagenet',\n","  pooling='avg'\n","))\n","model_adam.add(Dense(\n","  num_classes,\n","  activation='softmax'\n","))\n","\n","model_adam.layers[0].trainable = False"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model_sgd = Sequential()\n","model_sgd.add(ResNet50(\n","  include_top=False,\n","  weights='imagenet',\n","  pooling='avg'\n","))\n","model_sgd.add(Dense(\n","  num_classes,\n","  activation='softmax'\n","))\n","\n","model_sgd.layers[0].trainable = False"]},{"cell_type":"markdown","metadata":{"_uuid":"b14546c60c000f6f763d7ef225c2d5bb9bad75ee"},"source":["# Compile Model"]},{"cell_type":"markdown","metadata":{},"source":["## Adam"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"431d98d4322666bf0995dd65e7370e8e8d3ff36e","trusted":true},"outputs":[],"source":["model_adam.compile(\n","  optimizer='adam', # lots of people reccommend Adam optimizer\n","  loss='categorical_crossentropy', # aka \"log loss\" -- the cost function to minimize \n","  # so 'optimizer' algorithm will minimize 'loss' function\n","  metrics=['accuracy'] # ask it to report % of correct predictions\n",")"]},{"cell_type":"markdown","metadata":{},"source":["**Observation**\n","para un problema de clasificación binaria, a menudo se utiliza la 'entropía cruzada binaria', mientras que la 'entropía cruzada categórica' se utiliza para la clasificación de clases múltiples.\n","https://www.sourcetrail.com/es/pit%C3%B3n/keras/modelo-compilar-keras/"]},{"cell_type":"markdown","metadata":{},"source":["## SGD"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model_sgd.compile(\n","  optimizer='sgd', # lots of people reccommend Adam optimizer\n","  loss='categorical_crossentropy', # aka \"log loss\" -- the cost function to minimize \n","  # so 'optimizer' algorithm will minimize 'loss' function\n","  metrics=['accuracy'] # ask it to report % of correct predictions\n",")"]},{"cell_type":"markdown","metadata":{"_uuid":"7e00f7674040ad997d2e3c67d8e61b7f214e3709"},"source":["# Setup the image data generator for each training directory "]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"c8005d5e86576cebc2b0fa0034ca2baed91c6de1","trusted":true},"outputs":[],"source":["# model globals\n","IMAGE_SIZE = 224\n","BATCH_SIZE = 96\n","TEST_BATCH_SIZE = 17 # because test has 23817 images and factors of 23817 are 3*17*467\n","                     # it is important that this number evenly divides the total num images \n","VAL_SPLIT = 0.25"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"_uuid":"6d229aed54ae275e7cff6382f3500a4ad21e4701","trusted":true},"outputs":[],"source":["def setup_generators(\n","    val_split, train_dataframe, train_dir,\n","    img_size, batch_size, my_seed, list_of_classes,\n","    test_dataframe, test_dir, test_batch_size\n","):\n","    print(\"-\"*20)\n","    if not preprocess_input:\n","          raise Exception(\"please do import call 'from tensorflow.python.keras.applications.resnet50 import preprocess_input'\")\n","\n","    # setup resnet50 preprocessing \n","    data_gen = ImageDataGenerator(\n","        preprocessing_function=preprocess_input,\n","        validation_split=val_split)\n","\n","    print(len(train_dataframe), \"images in\", train_dir, \"and validation_split =\", val_split)\n","    print(\"\\ntraining set ImageDataGenerator\")\n","    train_gen = data_gen.flow_from_dataframe(\n","        dataframe=train_dataframe.reset_index(), # call reset_index() so keras can start with index 0\n","        directory=train_dir,\n","        x_col='new_filename',\n","        y_col='artist',\n","        has_ext=True,\n","        target_size=(img_size, img_size),\n","        subset=\"training\",\n","        batch_size=batch_size,\n","        seed=my_seed,\n","        shuffle=True,\n","        class_mode='categorical',\n","        classes=list_of_classes\n","    )\n","\n","    print(\"\\nvalidation set ImageDataGenerator\")\n","    valid_gen = data_gen.flow_from_dataframe(\n","        dataframe=train_dataframe.reset_index(), # call reset_index() so keras can start with index 0\n","        directory=train_dir,\n","        x_col='new_filename',\n","        y_col='artist',\n","        has_ext=True,\n","        subset=\"validation\",\n","        batch_size=batch_size,\n","        seed=my_seed,\n","        shuffle=True,\n","        target_size=(img_size,img_size),\n","        class_mode='categorical',\n","        classes=list_of_classes\n","    )\n","\n","    test_data_gen = ImageDataGenerator(preprocessing_function=preprocess_input)\n","\n","    print(\"\\ntest set ImageDataGenerator\")\n","    test_gen = test_data_gen.flow_from_dataframe(\n","        dataframe=test_dataframe.reset_index(), # call reset_index() so keras can start with index 0\n","        directory=test_dir,\n","        x_col='new_filename',\n","        y_col=None,\n","        has_ext=True,\n","        batch_size=test_batch_size,\n","        seed=my_seed,\n","        shuffle=False, # dont shuffle test directory\n","        class_mode=None,\n","        target_size=(img_size,img_size)\n","    )\n","\n","    return (train_gen, valid_gen, test_gen)\n","\n","print(\"defined setup_generators()\")"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true,"_uuid":"b899ca31427b36e183abfbc897caa05ca6102e05","trusted":true},"outputs":[],"source":["# delete some unused dataframes to free some RAM for training\n","del df\n","del t_df\n","del t1_df\n","del t2_df\n","del t3_df\n","del t4_df\n","del t5_df\n","del t6_df\n","del t7_df\n","del t8_df\n","del t9_df\n","gc.collect()"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-output":true,"_uuid":"906343b306f3d44981bc0693ed5185d8e2fdb446","trusted":true},"outputs":[],"source":["train_gens = [None]*len(TRAIN_DIRS)\n","valid_gens = [None]*len(TRAIN_DIRS)\n","test_gen  = None # only 1 test_gen\n","i = 0\n","for i in range(0, len(TRAIN_DIRS)):\n","    train_gens[i], valid_gens[i], test_gen = setup_generators(\n","        train_dataframe=all_train_dfs[i], train_dir=TRAIN_DIRS[i],\n","        val_split=VAL_SPLIT, img_size=IMAGE_SIZE, batch_size=BATCH_SIZE, my_seed=MY_SEED, \n","        list_of_classes=training_set_artists, test_dataframe=test_df, \n","        test_dir=TEST_DIR, test_batch_size=TEST_BATCH_SIZE\n","    )\n","    i += 1"]},{"cell_type":"markdown","metadata":{"_uuid":"d7978eabacec7bf8c313d1fda177d876a2a38cc1"},"source":["# TRAINING TIME!  🎉 🎊 🎁"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"31f15a418cd7e0550700645090e006d3438c4f59","trusted":true},"outputs":[],"source":["MAX_EPOCHS = 5 * len(train_gens) # should be a multiple of 9 because need evenly train each train_dir\n","DIR_EPOCHS = 1 # fit each train_dir at least this many times before overfitting"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-output":true,"_uuid":"71704f10dbbf6803e03934be1f3ac8de05d878f4","trusted":true},"outputs":[],"source":["histories_adam = []\n","\n","e=0\n","while ( e < MAX_EPOCHS):\n","    for i in range(0, len(train_gens)):\n","        # train_gen.n = number of images for training\n","        STEP_SIZE_TRAIN = train_gens[i].n//train_gens[i].batch_size\n","        # train_gen.n = number of images for validation\n","        STEP_SIZE_VALID = valid_gens[i].n//valid_gens[i].batch_size\n","        print(\"STEP_SIZE_TRAIN\",STEP_SIZE_TRAIN)\n","        print(\"STEP_SIZE_VALID\",STEP_SIZE_VALID)\n","        histories_adam.append(\n","            model_adam.fit_generator(generator=train_gens[i],\n","                                steps_per_epoch=STEP_SIZE_TRAIN,\n","                                validation_data=valid_gens[i],\n","                                validation_steps=STEP_SIZE_VALID,\n","                                epochs=DIR_EPOCHS)\n","        )\n","        e+=1"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["histories_sgd = []\n","\n","e=0\n","while ( e < MAX_EPOCHS):\n","    for i in range(0, len(train_gens)):\n","        # train_gen.n = number of images for training\n","        STEP_SIZE_TRAIN = train_gens[i].n//train_gens[i].batch_size\n","        # train_gen.n = number of images for validation\n","        STEP_SIZE_VALID = valid_gens[i].n//valid_gens[i].batch_size\n","        print(\"STEP_SIZE_TRAIN\",STEP_SIZE_TRAIN)\n","        print(\"STEP_SIZE_VALID\",STEP_SIZE_VALID)\n","        histories_sgd.append(\n","            model_sgd.fit_generator(generator=train_gens[i],\n","                                steps_per_epoch=STEP_SIZE_TRAIN,\n","                                validation_data=valid_gens[i],\n","                                validation_steps=STEP_SIZE_VALID,\n","                                epochs=DIR_EPOCHS)\n","        )\n","        e+=1"]},{"cell_type":"markdown","metadata":{"_uuid":"3a05218bcf6f36b56519fd3091b182c2efd756a9"},"source":["# Evaluate the model 🧐 🤔"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true,"_uuid":"30f09ae79b59fbec2375dd5eadee5c1af61dbb03","trusted":true},"outputs":[],"source":["accuracies_adam = []\n","val_accuracies_adam = []\n","losses_adam = []\n","val_losses_adam = []\n","for hist in histories_adam:\n","    if hist:\n","        accuracies_adam += hist.history['acc']\n","        val_accuracies_adam += hist.history['val_acc']\n","        losses_adam += hist.history['loss']\n","        val_losses_adam += hist.history['val_loss']"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["accuracies_sgd = []\n","val_accuracies_sgd = []\n","losses_sgd = []\n","val_losses_sgd = []\n","for hist in histories_sgd:\n","    if hist:\n","        accuracies_sgd += hist.history['acc']\n","        val_accuracies_sgd += hist.history['val_acc']\n","        losses_sgd += hist.history['loss']\n","        val_losses_sgd += hist.history['val_loss']"]},{"cell_type":"markdown","metadata":{},"source":["## Plots\n","### Accuracies"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true,"_uuid":"b2b8b4d7f244b57cc3df0fba829fb73a93da8d23","trusted":true},"outputs":[],"source":["# Plot training & validation accuracy values\n","plt.plot(accuracies_adam, label = \"Adam Train\")\n","plt.plot(val_accuracies_adam, label = \"Adam Test\")\n","\n","plt.plot(accuracies_sgd, label = \"SGD Train\")\n","plt.plot(val_accuracies_sgd, label = \"SGD Test\")\n","\n","plt.title('Model accuracy')\n","plt.ylabel('Accuracy')\n","plt.xlabel('Epoch')\n","plt.legend()\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["### Loss values"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Plot training & validation loss values\n","plt.plot(losses_adam, label = \"Adam Train\")\n","plt.plot(val_losses_adam, label = \"Adam Test\")\n","\n","plt.plot(losses_sgd, label = \"SGD Train\")\n","plt.plot(val_losses_sgd, label = \"SGD Test\")\n","\n","plt.title('Model loss')\n","plt.ylabel('Loss')\n","plt.xlabel('Epoch')\n","plt.legend()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"15433eaf26bb11ff67095ba0cbe781b62453a62a","trusted":true},"outputs":[],"source":["import time\n","timestr = time.strftime(\"%Y%m%d-%H%M%S\") # e.g: 20181109-180140\n","model_adam.save('painters_adam_e45_'+timestr+'.h5')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["timestr = time.strftime(\"%Y%m%d-%H%M%S\") # e.g: 20181109-180140\n","model_sgd.save('painters_adam_e45_'+timestr+'.h5')"]},{"cell_type":"markdown","metadata":{"_uuid":"2fa3ebde72fb64279bc367da190783f2524d2bad"},"source":["# Predict the output 🔮 🎩"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"160deb675d28625a391b3760ffa105e2272bb023","trusted":true},"outputs":[],"source":["PRED_STEPS = len(test_gen) #100 # default would have been len(test_gen)"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"98425b4ae320934e1ef68b50ea34deac31c284ab","trusted":true},"outputs":[],"source":["# Need to reset the test_gen before calling predict_generator\n","# This is important because forgetting to reset the test_generator results in outputs with a weird order.\n","test_gen.reset()\n","pred_adam = model_adam.predict_generator(test_gen, verbose=1, steps=PRED_STEPS)"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-output":true,"_uuid":"3bcf77f568962e91f1245ed77b00c5746ad4b48e","trusted":true},"outputs":[],"source":["print(len(pred_adam),\"\\n\",pred_adam)"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"dfb50c45a54612d6b6a0210d3f2c00f999bc1b52","trusted":true},"outputs":[],"source":["predicted_class_indices_adam = np.argmax(pred_adam,axis=1)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def retrieve_results(predicted_class_indices, train_gens):\n","    print(len(predicted_class_indices),\"\\n\",predicted_class_indices)\n","    print(\"it has values ranging from \",min(predicted_class_indices),\"...to...\",max(predicted_class_indices))\n","    labels = (train_gens[0].class_indices)\n","    labels = dict((v,k) for k,v in labels.items())\n","    predictions = [labels[k] for k in predicted_class_indices]\n","    print(\"*\"*20+\"\\nclass_indices\\n\"+\"*\"*20+\"\\n\",train_gens[0].class_indices,\"\\n\")\n","    print(\"*\"*20+\"\\nlabels\\n\"+\"*\"*20+\"\\n\",labels,\"\\n\")\n","    print(\"*\"*20+\"\\npredictions has\", len(predictions),\"values that look like\",\"'\"+str(predictions[0])+\"' which is the first prediction and corresponds to this index of the classes:\",train_gens[0].class_indices[predictions[0]])\n","    # Save the results to a CSV file.\n","    filenames=test_gen.filenames[:len(predictions)] # because \"ValueError: arrays must all be same length\"\n","\n","    real_artists = []\n","    for f in filenames:\n","        real = test_df[test_df['new_filename'] == f].artist.get_values()[0]\n","        real_artists.append(real)\n","\n","    results=pd.DataFrame({\"Filename\":filenames,\n","                        \"Predictions\":predictions,\n","                        \"Real Values\":real_artists})\n","    results.to_csv(\"results.csv\",index=False)\n","\n","    return results"]},{"cell_type":"markdown","metadata":{},"source":["## Adam"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["results_adam = retrieve_results(predicted_class_indices_adam, train_gens)"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"4acad3f61b891c2551a657ca242e6ee267919343","trusted":true},"outputs":[],"source":["results_adam.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"69605197bb4b01b272bccab9291b49f17e80fe0a","trusted":true},"outputs":[],"source":["len(training_set_artists)"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"8b1cd478370459daba02120d7613350baadd0518","trusted":true},"outputs":[],"source":["print(training_set_artists)"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"598d6d1189366f72d179c1f88ac026dade7dc1de","trusted":true},"outputs":[],"source":["def testing_new_images(results, training_set_artists):  \n","    count = 0\n","    match = 0\n","    unexpected_count = 0\n","    unexpected_match = 0\n","    match_both_expected_unexpected = 0\n","\n","    for p, r in zip(results['Predictions'], results['Real Values']):\n","        if r in training_set_artists:\n","            count += 1\n","            if p == r:\n","                match += 1\n","        else:\n","            unexpected_count += 1\n","            if p == r:\n","                unexpected_match += 1\n","\n","    print(\"test accuracy on new images for TRAINED artsits\")\n","    acc = match/count\n","    print(match,\"/\",count,\"=\",\"{:.4f}\".format(acc))\n","\n","    print(\"test accuracy on new images for UNEXPECTED artsits\")\n","    u_acc = unexpected_match/unexpected_count\n","    print(unexpected_match,\"/\",unexpected_count,\"=\",\"{:.4f}\".format(u_acc))\n","\n","    print(\"test accuracy on new images\")\n","    total_match = match+unexpected_match\n","    total_count = count+unexpected_count\n","    total_acc = (total_match)/(total_count)\n","    print(total_match,\"/\",total_count,\"=\",\"{:.4f}\".format(total_acc))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["testing_new_images(results_adam, training_set_artists)"]},{"cell_type":"markdown","metadata":{},"source":["## SGD"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["test_gen.reset()\n","pred_sgd = model_sgd.predict_generator(test_gen, verbose=1, steps=PRED_STEPS)\n","print(len(pred_sgd),\"\\n\",pred_sgd)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["predicted_class_indices_sgd = np.argmax(pred_sgd,axis=1)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["results_sgd = retrieve_results(predicted_class_indices_sgd, train_gens)\n","results_sgd.head()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(len(training_set_artists))\n","print(training_set_artists)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["testing_new_images(results_sgd, training_set_artists)"]},{"cell_type":"markdown","metadata":{"_uuid":"b71eebdaf00b0fa1d0b1401d8e00dff4a7b5111e"},"source":["So, it seems like the model may have learned some interesting patterns related to the artists that it expects. \n","\n","**Questions to explore:**\n","* [What does the model actually \"see\"](https://arxiv.org/abs/1312.6034) in a painting by [Pablo Picasso](https://www.wikiart.org/en/pablo-picasso/) as opposed to [Vincent van Gogh](https://www.wikiart.org/en/vincent-van-gogh)?\n","* What would happen if we trained the model on the full artist dataset or at least on artists with over 200 paintings in the dataset?\n","* Can the accuracy be improved with techniques like data augmentation or with a custom convolutional neural network? How about doing transfer learning with different [pre-trained model](https://keras.io/applications)?\n","* How can the learning rate be tuned to improve the accuracy?\n","* Would a regularization technique like [dropout](https://machinelearningmastery.com/dropout-regularization-deep-learning-models-keras/) be helpful?\n","* This notebook uses the [Adam](https://keras.io/optimizers/#adam) optimizer... what if we tried RMSprop?\n","* How about using an [ensemble of models](https://machinelearningmastery.com/ensemble-machine-learning-algorithms-python-scikit-learn/)?"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"}},"nbformat":4,"nbformat_minor":1}
=======
{"cells":[{"cell_type":"markdown","metadata":{"_uuid":"969bd0a45cfbe4f4804ac2f920de35cbbc7bf1a8"},"source":["# Overview\n","\n","Can a computer \"learn\" to classify artists by their paintings? \n","\n","ResNet50 is a good model for classifying ImageNet data. How about a set of 38 artists?\n","\n","We use transfer learning to re-train a ResNet50 model to identify one of 38 artists who have more than ~~300~~ ***200*** paintings in the dataset. \n","\n","This notebook is part of a project for CSC 480 taught by [Dr. Franz J. Kurfess](http://users.csc.calpoly.edu/~fkurfess/) at Cal Poly\n","\n","A web application is [in development](https://github.com/SomethingAboutImages/WebImageClassifier) to make use of the model that this notebook outputs. "]},{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":false,"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","scrolled":true,"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-05-09 22:06:29.451560: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-05-09 22:06:42.741070: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/intel/compilers_and_libraries_2018.1.163/linux/tbb/lib/intel64_lin/gcc4.7:/opt/intel/compilers_and_libraries_2018.1.163/linux/compiler/lib/intel64_lin:/opt/intel/compilers_and_libraries_2018.1.163/linux/mkl/lib/intel64_lin::/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64/\n","2024-05-09 22:06:42.741255: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/intel/compilers_and_libraries_2018.1.163/linux/tbb/lib/intel64_lin/gcc4.7:/opt/intel/compilers_and_libraries_2018.1.163/linux/compiler/lib/intel64_lin:/opt/intel/compilers_and_libraries_2018.1.163/linux/mkl/lib/intel64_lin::/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64/\n","2024-05-09 22:06:42.741271: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"]}],"source":["import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","# %matplotlib inline\n","import matplotlib.pyplot as plt\n","from random import seed # for setting seed\n","import tensorflow\n","from IPython import sys_info\n","\n","import gc # garbage collection"]},{"cell_type":"code","execution_count":2,"metadata":{"_uuid":"4cd71d6411b0bb2bee9d5a9f2421f8310509e008","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["{'commit_hash': '37242ba43',\n"," 'commit_source': 'installation',\n"," 'default_encoding': 'utf-8',\n"," 'ipython_path': '/anaconda/envs/azureml_py38_PT_and_TF/lib/python3.8/site-packages/IPython',\n"," 'ipython_version': '8.12.0',\n"," 'os_name': 'posix',\n"," 'platform': 'Linux-5.15.0-1061-azure-x86_64-with-glibc2.10',\n"," 'sys_executable': '/anaconda/envs/azureml_py38_PT_and_TF/bin/python',\n"," 'sys_platform': 'linux',\n"," 'sys_version': '3.8.5 (default, Sep  4 2020, 07:30:14) \\n[GCC 7.3.0]'}\n"]}],"source":["MY_SEED = 42 # 480 could work too\n","seed(MY_SEED)\n","np.random.seed(MY_SEED)\n","tensorflow.random.set_seed(MY_SEED)\n","\n","print(sys_info())\n","# get module information\n","# !pip freeze > frozen-requirements.txt\n","# append system information to file\n","# with open(\"frozen-requirements.txt\", \"a\") as file:\n","#     file.write(sys_info())"]},{"cell_type":"code","execution_count":3,"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"_uuid":"6bab4e1e53b22a9af9908fbefaeaa6f0e8b1110d","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["[name: \"/device:CPU:0\"\n","device_type: \"CPU\"\n","memory_limit: 268435456\n","locality {\n","}\n","incarnation: 15060742536233510159\n","xla_global_id: -1\n",", name: \"/device:GPU:0\"\n","device_type: \"GPU\"\n","memory_limit: 15247015936\n","locality {\n","  bus_id: 1\n","  links {\n","  }\n","}\n","incarnation: 2968224721677669394\n","physical_device_desc: \"device: 0, name: Tesla V100-PCIE-16GB, pci bus id: 0001:00:00.0, compute capability: 7.0\"\n","xla_global_id: 416903419\n","]\n"]},{"name":"stderr","output_type":"stream","text":["2024-05-09 22:06:59.029818: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-05-09 22:07:08.017927: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /device:GPU:0 with 14540 MB memory:  -> device: 0, name: Tesla V100-PCIE-16GB, pci bus id: 0001:00:00.0, compute capability: 7.0\n"]}],"source":["from tensorflow.python.client import device_lib\n","# print out the CPUs and GPUs\n","print(device_lib.list_local_devices())"]},{"cell_type":"code","execution_count":4,"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"_uuid":"1caeac96229a1e6db1d07b316cbfe62e1ee858d7","trusted":true},"outputs":[],"source":["# https://stackoverflow.com/questions/25705773/image-cropping-tool-python\n","# because painting images are hella big\n","from PIL import Image\n","Image.MAX_IMAGE_PIXELS = None"]},{"cell_type":"code","execution_count":21,"metadata":{"_uuid":"ca219817e229ad5e947b9a53a6bc9626cc7e2e02","trusted":true},"outputs":[],"source":["# globals\n","\n","DATA_DIR = '/home/xnmaster/Project/input/'\n","\n","TRAIN_1_DIR = '/home/xnmaster/Project/input/train_1'\n","# TRAIN_2_DIR = '../input/painters-train-part-1/train_2/train_2/'\n","# TRAIN_3_DIR = '../input/painters-train-part-1/train_3/train_3/'\n","\n","# TRAIN_4_DIR = '../input/painters-train-part-2/train_4/train_4/'\n","# TRAIN_5_DIR = '../input/painters-train-part-2/train_5/train_5/'\n","# TRAIN_6_DIR = '../input/painters-train-part-2/train_6/train_6/'\n","\n","# TRAIN_7_DIR = '../input/painters-train-part-3/train_7/train_7/'\n","# TRAIN_8_DIR = '../input/painters-train-part-3/train_8/train_8/'\n","# TRAIN_9_DIR = '../input/painters-train-part-3/train_9/train_9/'\n","\n","# TRAIN_DIRS = [TRAIN_1_DIR, TRAIN_2_DIR, TRAIN_3_DIR,\n","#              TRAIN_4_DIR, TRAIN_5_DIR, TRAIN_6_DIR,\n","#              TRAIN_7_DIR, TRAIN_8_DIR, TRAIN_9_DIR]\n","TRAIN_DIRS = [TRAIN_1_DIR]\n","\n","TEST_DIR = '/home/xnmaster/Project/input/test/'"]},{"cell_type":"code","execution_count":6,"metadata":{"_kg_hide-input":true,"_uuid":"8946b27facacf6814c81f06c53d34f8be7e5c53f","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["df.shape (79433, 6)\n"]}],"source":["df = pd.read_csv(DATA_DIR + 'train_info/train_info.csv')\n","print(\"df.shape\", df.shape)"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>filename</th>\n","      <th>artist</th>\n","      <th>title</th>\n","      <th>style</th>\n","      <th>genre</th>\n","      <th>date</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>102257.jpg</td>\n","      <td>5b39c876740bfc1cfaf544721c43cac3</td>\n","      <td>Uriel</td>\n","      <td>Color Field Painting</td>\n","      <td>abstract</td>\n","      <td>1955.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>75232.jpg</td>\n","      <td>5b39c876740bfc1cfaf544721c43cac3</td>\n","      <td>Vir Heroicus Sublimis</td>\n","      <td>Color Field Painting</td>\n","      <td>abstract</td>\n","      <td>1950.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>29855.jpg</td>\n","      <td>96e5bc98488ed589b9bf17ad9fd09371</td>\n","      <td>Night March of a Hundred Demons (left half)</td>\n","      <td>Yamato-e</td>\n","      <td>mythological painting</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>62252.jpg</td>\n","      <td>5b39c876740bfc1cfaf544721c43cac3</td>\n","      <td>Who’s Afraid of Red,  Yellow and Blue II</td>\n","      <td>Color Field Painting</td>\n","      <td>abstract</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>63861.jpg</td>\n","      <td>5b39c876740bfc1cfaf544721c43cac3</td>\n","      <td>Black Fire I</td>\n","      <td>Color Field Painting</td>\n","      <td>abstract</td>\n","      <td>1963.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["     filename                            artist   \n","0  102257.jpg  5b39c876740bfc1cfaf544721c43cac3  \\\n","1   75232.jpg  5b39c876740bfc1cfaf544721c43cac3   \n","2   29855.jpg  96e5bc98488ed589b9bf17ad9fd09371   \n","3   62252.jpg  5b39c876740bfc1cfaf544721c43cac3   \n","4   63861.jpg  5b39c876740bfc1cfaf544721c43cac3   \n","\n","                                         title                 style   \n","0                                        Uriel  Color Field Painting  \\\n","1                        Vir Heroicus Sublimis  Color Field Painting   \n","2  Night March of a Hundred Demons (left half)              Yamato-e   \n","3     Who’s Afraid of Red,  Yellow and Blue II  Color Field Painting   \n","4                                Black Fire I   Color Field Painting   \n","\n","                   genre    date  \n","0               abstract  1955.0  \n","1               abstract  1950.0  \n","2  mythological painting     NaN  \n","3               abstract     NaN  \n","4               abstract  1963.0  "]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"_uuid":"8aa0abdf69b880c834752ab85206dfcb6fef38d9","trusted":true},"outputs":[],"source":["# # quick fix for corrupted files\n","# list_of_corrupted = ['3917.jpg','18649.jpg','20153.jpg','41945.jpg',\n","# '79499.jpg','91033.jpg','92899.jpg','95347.jpg',\n","# '100532.jpg','101947.jpg']\n","# # display the corrupted rows of dataset for context\n","# corrupt_df = df[df[\"new_filename\"].isin(list_of_corrupted) == True]\n","# print(corrupt_df.head(len(list_of_corrupted)))\n","\n","# # completely get rid of them\n","# df = df[df[\"new_filename\"].isin(list_of_corrupted) == False]\n","\n","# # try to see if they are still there\n","# print(df[df[\"new_filename\"].isin(list_of_corrupted) == True])\n","\n","# print(\"df.shape\", df.shape)"]},{"cell_type":"code","execution_count":8,"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_kg_hide-input":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["train_df.shape (79433, 2)\n","number of artists 71\n","\n","list of artists...\n"," ['d09f796f2b0aa11dffc88badd9806119', '83e9823eb4868ca162fd3b7adff70096', '8e441c5899bf3d2f3b2c493e62fb92bf', 'db1318d32df7428076e03513ebf762bb', '6460e3ba02dfa3b57ebf5d3d0823aa47', '82665201c4108381d854740ddcb86e67', '397c63db1c7b507d23abff3f8bb0fa18', '8cdd41002b7b5c5d112865054a7fe13e', 'a6027a4ba71b61a55ea598379c9d508c', '1a8d67dbb446bdc4298cc0be56932a38', 'c8041306a183cbaf39ff8cd707c9cc7f', 'c3e9d9ebe5f2900190bef9342c440bd9', 'e60882af79cababb03ddfa980a75448c', 'd8a3c897c506be7de91d8f892f14f934', '4a30943bf6dd5da55d12ccd14aaff0d8', 'bfb541e54ad5c7320e8f80e2a2163e93', '8a1a67964c0cbea29fc9801b5c42c553', '96e7b1bc8d52e18caf0af34fec2e9bcb', '5fc2ffdd3d24ab503edd9a271dc379bd', 'dd4989789d310581024ae2b9203d5439', '50591a7061fb340d875723f38e00cc3b', 'b874a616affcb766bb0e7a4f2a0803f0', '54e7b38b5c91716bd3ad99a0ab740a18', '234c8d1df0b49b512791078cf00cf352', '3cc9a44380296d93e68b71a27643c25f', 'c16781c4321948227193214b68477a5c', 'dc589f213ba7bd398714ac2796b7c0ab', 'b64b426fa2b080ad94a2e1c7f423413c', '10bc951c2eb4a2f05fa773bdaace4e3b', 'bc58ed3c3e7750f9644953020a39e867', 'b844978933b7ae43e32ce775494821eb', '4b0465826ffd6db797ea6f3a5898df79', 'c9380d13360b37f21cfd174d92a7247e', '481c5c92d55717167e01821144a54635', '6f80666437feea42f295cdc0f1eb4df9', 'de42ef05d5901837bbe974fdb3c30ba5', 'b36edf57ed623e40e433565053f5f6ca', 'aceaa52f487dd19129857232b2eeb3d5', '45f4183820ce1fa775f8a27d3120aad6', '0eeac4ecff259dc515be795e1a76019a', '68cbc428edbcf480cbbb9a0e66e7046d', 'c56bcab4b317984013ebef5d3c4b5906', 'f7e1cb7b67e7b154d9dca7d12879d7b0', 'e1587900e782de448f604b37cde0fdfd', '121fffad1eb6f7dff228b8a71b6aec72', '31dbc08b8d0a3196c5484c0c068b2bcc', '3f8dc381ccfe9d5cc88b75970262715b', '512fb34e01bd21a92e7ec1380577c985', '1e8267251976e6f3b771b00f32c5798b', 'ce3d8977aae5986601232aa58d15282a', '1468ab18764365ded902fc726aec2c89', '49bb8d79587c2172c6cd04dd705fd891', '40f86d376acde0d9862ce7493745bdae', '1950e9aa6ad878bc2a330880f77ae5a1', '129349585c3d1f312535b6619fc36bf7', 'bc0ddf03c667c5edb17982be481ef360', '7b016984b86b58f83977299591cf4e38', '3937af6d364e2f24d1cce16fe3916536', '62b4406512c45730d2c7c40f5e3d0d12', '3edc6a404b8c67b7dad1405d52228c96', '80687062449ff7454e2c8926be56f643', 'cc47068929413a16aa707faefbdf4b70', '9649a0013a798a8367d2c493e37468ec', '147b0f64f4c2848bc0ad7bc1cdf74afe', '5e560e9b2ae0c20cfc57b308742bc677', '5aabfc58470d01bb2362795a44a2603b', 'c31b03be3da5810b44ea4782d2f3b8a0', '861c29e13205420326f7443ea77de5c9', 'bd14ef3c1a25cf0c5368ccd92a3c5f04', 'ccb8b07e7e3d837b2cd08d3edaf009cd', '5ae394770a82dac7cea5d95ef6482a11']\n"]}],"source":["\n","# train_df = df[df[\"in_train\"] == True]\n","# test_df = df[df['in_train'] == False]\n","train_df = df[['artist', 'filename']]\n","# test_df = test_df[['artist', 'new_filename']]\n","\n","# print(\"test_df.shape\", test_df.shape)\n","print(\"train_df.shape\", train_df.shape)\n","\n","artists = {} # holds artist hash & the count\n","for a in train_df['artist']:\n","    if (a not in artists):\n","        artists[a] = 1\n","    else:\n","        artists[a] += 1\n","\n","training_set_artists = []\n","for a,count in artists.items():\n","    if(int(count) >= 200):\n","        training_set_artists.append(a)\n","\n","print(\"number of artists\",len(training_set_artists))\n","\n","print(\"\\nlist of artists...\\n\", training_set_artists)\n"]},{"cell_type":"code","execution_count":9,"metadata":{"_kg_hide-input":true,"_uuid":"374cf6e0025c7221bbd1973c88f3702158e38c3f","trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>artist</th>\n","      <th>filename</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>9</th>\n","      <td>d09f796f2b0aa11dffc88badd9806119</td>\n","      <td>99442.jpg</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>83e9823eb4868ca162fd3b7adff70096</td>\n","      <td>7486.jpg</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>83e9823eb4868ca162fd3b7adff70096</td>\n","      <td>35766.jpg</td>\n","    </tr>\n","    <tr>\n","      <th>33</th>\n","      <td>8e441c5899bf3d2f3b2c493e62fb92bf</td>\n","      <td>99733.jpg</td>\n","    </tr>\n","    <tr>\n","      <th>34</th>\n","      <td>8e441c5899bf3d2f3b2c493e62fb92bf</td>\n","      <td>73690.jpg</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                              artist   filename\n","9   d09f796f2b0aa11dffc88badd9806119  99442.jpg\n","18  83e9823eb4868ca162fd3b7adff70096   7486.jpg\n","19  83e9823eb4868ca162fd3b7adff70096  35766.jpg\n","33  8e441c5899bf3d2f3b2c493e62fb92bf  99733.jpg\n","34  8e441c5899bf3d2f3b2c493e62fb92bf  73690.jpg"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["t_df = train_df[train_df[\"artist\"].isin(training_set_artists)]\n","\n","t_df.head(5)"]},{"cell_type":"code","execution_count":10,"metadata":{"_kg_hide-input":true,"_uuid":"b44f0b775da104dd716f4601cc164e7c4284bcec","trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>artist</th>\n","      <th>filename</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>9</th>\n","      <td>d09f796f2b0aa11dffc88badd9806119</td>\n","      <td>99442.jpg</td>\n","    </tr>\n","    <tr>\n","      <th>33</th>\n","      <td>8e441c5899bf3d2f3b2c493e62fb92bf</td>\n","      <td>99733.jpg</td>\n","    </tr>\n","    <tr>\n","      <th>35</th>\n","      <td>8e441c5899bf3d2f3b2c493e62fb92bf</td>\n","      <td>93715.jpg</td>\n","    </tr>\n","    <tr>\n","      <th>108</th>\n","      <td>a6027a4ba71b61a55ea598379c9d508c</td>\n","      <td>95360.jpg</td>\n","    </tr>\n","    <tr>\n","      <th>122</th>\n","      <td>8cdd41002b7b5c5d112865054a7fe13e</td>\n","      <td>96372.jpg</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                               artist   filename\n","9    d09f796f2b0aa11dffc88badd9806119  99442.jpg\n","33   8e441c5899bf3d2f3b2c493e62fb92bf  99733.jpg\n","35   8e441c5899bf3d2f3b2c493e62fb92bf  93715.jpg\n","108  a6027a4ba71b61a55ea598379c9d508c  95360.jpg\n","122  8cdd41002b7b5c5d112865054a7fe13e  96372.jpg"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["t1_df = t_df[t_df['filename'].str.startswith('1')]\n","\n","t2_df = t_df[t_df['filename'].str.startswith('2')]\n","\n","t3_df = t_df[t_df['filename'].str.startswith('3')]\n","\n","t4_df = t_df[t_df['filename'].str.startswith('4')]\n","\n","t5_df = t_df[t_df['filename'].str.startswith('5')]\n","\n","t6_df = t_df[t_df['filename'].str.startswith('6')]\n","\n","t7_df = t_df[t_df['filename'].str.startswith('7')]\n","\n","t8_df = t_df[t_df['filename'].str.startswith('8')]\n","\n","t9_df = t_df[t_df['filename'].str.startswith('9')]\n","\n","all_train_dfs = [t1_df, t2_df, t3_df,\n","                t4_df, t5_df, t6_df,\n","                t7_df, t8_df, t9_df]\n","\n","t9_df.head(5)"]},{"cell_type":"code","execution_count":11,"metadata":{"_kg_hide-input":false,"_kg_hide-output":false,"_uuid":"9f35f9102dabe4fd4c05d9b4da88929811c574cd","trusted":true},"outputs":[],"source":["from tensorflow.keras.applications import ResNet50\n","from tensorflow.python.keras.models import Sequential\n","from tensorflow.python.keras.layers import Dense, Flatten, GlobalAveragePooling2D\n","\n","from tensorflow.keras.applications.resnet50 import preprocess_input\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n"]},{"cell_type":"markdown","metadata":{"_uuid":"30506b48fd6f5fd2636520b60baed80e20b8b944"},"source":["# specify the model that classifies 38 artists 🎨 🖌"]},{"cell_type":"code","execution_count":12,"metadata":{"_uuid":"e74625505706e025d7981c6712d21861f3ff6407","trusted":true},"outputs":[{"data":{"text/plain":["71"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["len(training_set_artists)"]},{"cell_type":"code","execution_count":14,"metadata":{"_uuid":"d3222704a8161b0530f4df9911acbbc54ce97039","trusted":true},"outputs":[],"source":["num_classes = len(training_set_artists) # one class per artist\n","weights_notop_path = '../input/resnet50/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5'\n","model_adam = Sequential()\n","model_adam.add(ResNet50(\n","  include_top=False,\n","  weights='imagenet',\n","  pooling='avg'\n","))\n","model_adam.add(Dense(\n","  num_classes,\n","  activation='softmax'\n","))\n","\n","model_adam.layers[0].trainable = False"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[],"source":["model_sgd = Sequential()\n","model_sgd.add(ResNet50(\n","  include_top=False,\n","  weights='imagenet',\n","  pooling='avg'\n","))\n","model_sgd.add(Dense(\n","  num_classes,\n","  activation='softmax'\n","))\n","\n","model_sgd.layers[0].trainable = False"]},{"cell_type":"markdown","metadata":{"_uuid":"b14546c60c000f6f763d7ef225c2d5bb9bad75ee"},"source":["# Compile Model"]},{"cell_type":"markdown","metadata":{},"source":["## Adam"]},{"cell_type":"code","execution_count":16,"metadata":{"_uuid":"431d98d4322666bf0995dd65e7370e8e8d3ff36e","trusted":true},"outputs":[],"source":["model_adam.compile(\n","  optimizer='adam', # lots of people reccommend Adam optimizer\n","  loss='categorical_crossentropy', # aka \"log loss\" -- the cost function to minimize \n","  # so 'optimizer' algorithm will minimize 'loss' function\n","  metrics=['accuracy'] # ask it to report % of correct predictions\n",")"]},{"cell_type":"markdown","metadata":{},"source":["**Observation**\n","para un problema de clasificación binaria, a menudo se utiliza la 'entropía cruzada binaria', mientras que la 'entropía cruzada categórica' se utiliza para la clasificación de clases múltiples.\n","https://www.sourcetrail.com/es/pit%C3%B3n/keras/modelo-compilar-keras/"]},{"cell_type":"markdown","metadata":{},"source":["## SGD"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[],"source":["model_sgd.compile(\n","  optimizer='sgd', # lots of people reccommend Adam optimizer\n","  loss='categorical_crossentropy', # aka \"log loss\" -- the cost function to minimize \n","  # so 'optimizer' algorithm will minimize 'loss' function\n","  metrics=['accuracy'] # ask it to report % of correct predictions\n",")"]},{"cell_type":"markdown","metadata":{"_uuid":"7e00f7674040ad997d2e3c67d8e61b7f214e3709"},"source":["# Setup the image data generator for each training directory "]},{"cell_type":"code","execution_count":18,"metadata":{"_uuid":"c8005d5e86576cebc2b0fa0034ca2baed91c6de1","trusted":true},"outputs":[],"source":["# model globals\n","IMAGE_SIZE = 224\n","BATCH_SIZE = 96\n","TEST_BATCH_SIZE = 17 # because test has 23817 images and factors of 23817 are 3*17*467\n","                     # it is important that this number evenly divides the total num images \n","VAL_SPLIT = 0.25"]},{"cell_type":"code","execution_count":19,"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"_uuid":"6d229aed54ae275e7cff6382f3500a4ad21e4701","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["defined setup_generators()\n"]}],"source":["def setup_generators(\n","    val_split, train_dataframe, train_dir,\n","    img_size, batch_size, my_seed, list_of_classes,\n","    test_dataframe, test_dir, test_batch_size\n","):\n","    print(\"-\"*20)\n","    if not preprocess_input:\n","          raise Exception(\"please do import call 'from tensorflow.python.keras.applications.resnet50 import preprocess_input'\")\n","\n","    # setup resnet50 preprocessing \n","    data_gen = ImageDataGenerator(\n","        preprocessing_function=preprocess_input,\n","        validation_split=val_split)\n","\n","    print(len(train_dataframe), \"images in\", train_dir, \"and validation_split =\", val_split)\n","    print(\"\\ntraining set ImageDataGenerator\")\n","    train_gen = data_gen.flow_from_dataframe(\n","        dataframe=train_dataframe.reset_index(), # call reset_index() so keras can start with index 0\n","        directory=train_dir,\n","        x_col='new_filename',\n","        y_col='artist',\n","        has_ext=True,\n","        target_size=(img_size, img_size),\n","        subset=\"training\",\n","        batch_size=batch_size,\n","        seed=my_seed,\n","        shuffle=True,\n","        class_mode='categorical',\n","        classes=list_of_classes\n","    )\n","\n","    print(\"\\nvalidation set ImageDataGenerator\")\n","    valid_gen = data_gen.flow_from_dataframe(\n","        dataframe=train_dataframe.reset_index(), # call reset_index() so keras can start with index 0\n","        directory=train_dir,\n","        x_col='new_filename',\n","        y_col='artist',\n","        has_ext=True,\n","        subset=\"validation\",\n","        batch_size=batch_size,\n","        seed=my_seed,\n","        shuffle=True,\n","        target_size=(img_size,img_size),\n","        class_mode='categorical',\n","        classes=list_of_classes\n","    )\n","\n","    test_data_gen = ImageDataGenerator(preprocessing_function=preprocess_input)\n","\n","    print(\"\\ntest set ImageDataGenerator\")\n","    test_gen = test_data_gen.flow_from_dataframe(\n","        dataframe=test_dataframe.reset_index(), # call reset_index() so keras can start with index 0\n","        directory=test_dir,\n","        x_col='new_filename',\n","        y_col=None,\n","        has_ext=True,\n","        batch_size=test_batch_size,\n","        seed=my_seed,\n","        shuffle=False, # dont shuffle test directory\n","        class_mode=None,\n","        target_size=(img_size,img_size)\n","    )\n","\n","    return (train_gen, valid_gen, test_gen)\n","\n","print(\"defined setup_generators()\")"]},{"cell_type":"code","execution_count":20,"metadata":{"_kg_hide-input":true,"_uuid":"b899ca31427b36e183abfbc897caa05ca6102e05","trusted":true},"outputs":[{"data":{"text/plain":["1397"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["# delete some unused dataframes to free some RAM for training\n","del df\n","del t_df\n","del t1_df\n","del t2_df\n","del t3_df\n","del t4_df\n","del t5_df\n","del t6_df\n","del t7_df\n","del t8_df\n","del t9_df\n","gc.collect()"]},{"cell_type":"code","execution_count":22,"metadata":{"_kg_hide-output":true,"_uuid":"906343b306f3d44981bc0693ed5185d8e2fdb446","trusted":true},"outputs":[{"ename":"NameError","evalue":"name 'test_df' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[22], line 9\u001b[0m\n\u001b[1;32m      4\u001b[0m i \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(TRAIN_DIRS)):\n\u001b[1;32m      6\u001b[0m     train_gens[i], valid_gens[i], test_gen \u001b[38;5;241m=\u001b[39m setup_generators(\n\u001b[1;32m      7\u001b[0m         train_dataframe\u001b[38;5;241m=\u001b[39mall_train_dfs[i], train_dir\u001b[38;5;241m=\u001b[39mTRAIN_DIRS[i],\n\u001b[1;32m      8\u001b[0m         val_split\u001b[38;5;241m=\u001b[39mVAL_SPLIT, img_size\u001b[38;5;241m=\u001b[39mIMAGE_SIZE, batch_size\u001b[38;5;241m=\u001b[39mBATCH_SIZE, my_seed\u001b[38;5;241m=\u001b[39mMY_SEED, \n\u001b[0;32m----> 9\u001b[0m         list_of_classes\u001b[38;5;241m=\u001b[39mtraining_set_artists, test_dataframe\u001b[38;5;241m=\u001b[39m\u001b[43mtest_df\u001b[49m, \n\u001b[1;32m     10\u001b[0m         test_dir\u001b[38;5;241m=\u001b[39mTEST_DIR, test_batch_size\u001b[38;5;241m=\u001b[39mTEST_BATCH_SIZE\n\u001b[1;32m     11\u001b[0m     )\n\u001b[1;32m     12\u001b[0m     i \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n","\u001b[0;31mNameError\u001b[0m: name 'test_df' is not defined"]}],"source":["train_gens = [None]*len(TRAIN_DIRS)\n","valid_gens = [None]*len(TRAIN_DIRS)\n","test_gen  = None # only 1 test_gen\n","i = 0\n","for i in range(0, len(TRAIN_DIRS)):\n","    train_gens[i], valid_gens[i], test_gen = setup_generators(\n","        train_dataframe=all_train_dfs[i], train_dir=TRAIN_DIRS[i],\n","        val_split=VAL_SPLIT, img_size=IMAGE_SIZE, batch_size=BATCH_SIZE, my_seed=MY_SEED, \n","        list_of_classes=training_set_artists, test_dataframe=test_df, \n","        test_dir=TEST_DIR, test_batch_size=TEST_BATCH_SIZE\n","    )\n","    i += 1"]},{"cell_type":"markdown","metadata":{"_uuid":"d7978eabacec7bf8c313d1fda177d876a2a38cc1"},"source":["# TRAINING TIME!  🎉 🎊 🎁"]},{"cell_type":"code","execution_count":23,"metadata":{"_uuid":"31f15a418cd7e0550700645090e006d3438c4f59","trusted":true},"outputs":[],"source":["MAX_EPOCHS = 5 * len(train_gens) # should be a multiple of 9 because need evenly train each train_dir\n","DIR_EPOCHS = 1 # fit each train_dir at least this many times before overfitting"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-output":true,"_uuid":"71704f10dbbf6803e03934be1f3ac8de05d878f4","trusted":true},"outputs":[],"source":["histories_adam = []\n","\n","e=0\n","while ( e < MAX_EPOCHS):\n","    for i in range(0, len(train_gens)):\n","        # train_gen.n = number of images for training\n","        STEP_SIZE_TRAIN = train_gens[i].n//train_gens[i].batch_size\n","        # train_gen.n = number of images for validation\n","        STEP_SIZE_VALID = valid_gens[i].n//valid_gens[i].batch_size\n","        print(\"STEP_SIZE_TRAIN\",STEP_SIZE_TRAIN)\n","        print(\"STEP_SIZE_VALID\",STEP_SIZE_VALID)\n","        histories_adam.append(\n","            model_adam.fit_generator(generator=train_gens[i],\n","                                steps_per_epoch=STEP_SIZE_TRAIN,\n","                                validation_data=valid_gens[i],\n","                                validation_steps=STEP_SIZE_VALID,\n","                                epochs=DIR_EPOCHS)\n","        )\n","        e+=1"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["histories_sgd = []\n","\n","e=0\n","while ( e < MAX_EPOCHS):\n","    for i in range(0, len(train_gens)):\n","        # train_gen.n = number of images for training\n","        STEP_SIZE_TRAIN = train_gens[i].n//train_gens[i].batch_size\n","        # train_gen.n = number of images for validation\n","        STEP_SIZE_VALID = valid_gens[i].n//valid_gens[i].batch_size\n","        print(\"STEP_SIZE_TRAIN\",STEP_SIZE_TRAIN)\n","        print(\"STEP_SIZE_VALID\",STEP_SIZE_VALID)\n","        histories_sgd.append(\n","            model_sgd.fit_generator(generator=train_gens[i],\n","                                steps_per_epoch=STEP_SIZE_TRAIN,\n","                                validation_data=valid_gens[i],\n","                                validation_steps=STEP_SIZE_VALID,\n","                                epochs=DIR_EPOCHS)\n","        )\n","        e+=1"]},{"cell_type":"markdown","metadata":{"_uuid":"3a05218bcf6f36b56519fd3091b182c2efd756a9"},"source":["# Evaluate the model 🧐 🤔"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true,"_uuid":"30f09ae79b59fbec2375dd5eadee5c1af61dbb03","trusted":true},"outputs":[],"source":["accuracies_adam = []\n","val_accuracies_adam = []\n","losses_adam = []\n","val_losses_adam = []\n","for hist in histories_adam:\n","    if hist:\n","        accuracies_adam += hist.history['acc']\n","        val_accuracies_adam += hist.history['val_acc']\n","        losses_adam += hist.history['loss']\n","        val_losses_adam += hist.history['val_loss']"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["accuracies_sgd = []\n","val_accuracies_sgd = []\n","losses_sgd = []\n","val_losses_sgd = []\n","for hist in histories_sgd:\n","    if hist:\n","        accuracies_sgd += hist.history['acc']\n","        val_accuracies_sgd += hist.history['val_acc']\n","        losses_sgd += hist.history['loss']\n","        val_losses_sgd += hist.history['val_loss']"]},{"cell_type":"markdown","metadata":{},"source":["## Plots\n","### Accuracies"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true,"_uuid":"b2b8b4d7f244b57cc3df0fba829fb73a93da8d23","trusted":true},"outputs":[],"source":["# Plot training & validation accuracy values\n","plt.plot(accuracies_adam, label = \"Adam Train\")\n","plt.plot(val_accuracies_adam, label = \"Adam Test\")\n","\n","plt.plot(accuracies_sgd, label = \"SGD Train\")\n","plt.plot(val_accuracies_sgd, label = \"SGD Test\")\n","\n","plt.title('Model accuracy')\n","plt.ylabel('Accuracy')\n","plt.xlabel('Epoch')\n","plt.legend()\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["### Loss values"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Plot training & validation loss values\n","plt.plot(losses_adam, label = \"Adam Train\")\n","plt.plot(val_losses_adam, label = \"Adam Test\")\n","\n","plt.plot(losses_sgd, label = \"SGD Train\")\n","plt.plot(val_losses_sgd, label = \"SGD Test\")\n","\n","plt.title('Model loss')\n","plt.ylabel('Loss')\n","plt.xlabel('Epoch')\n","plt.legend()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"15433eaf26bb11ff67095ba0cbe781b62453a62a","trusted":true},"outputs":[],"source":["import time\n","timestr = time.strftime(\"%Y%m%d-%H%M%S\") # e.g: 20181109-180140\n","model_adam.save('painters_adam_e45_'+timestr+'.h5')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["timestr = time.strftime(\"%Y%m%d-%H%M%S\") # e.g: 20181109-180140\n","model_sgd.save('painters_adam_e45_'+timestr+'.h5')"]},{"cell_type":"markdown","metadata":{"_uuid":"2fa3ebde72fb64279bc367da190783f2524d2bad"},"source":["# Predict the output 🔮 🎩"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"160deb675d28625a391b3760ffa105e2272bb023","trusted":true},"outputs":[],"source":["PRED_STEPS = len(test_gen) #100 # default would have been len(test_gen)"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"98425b4ae320934e1ef68b50ea34deac31c284ab","trusted":true},"outputs":[],"source":["# Need to reset the test_gen before calling predict_generator\n","# This is important because forgetting to reset the test_generator results in outputs with a weird order.\n","test_gen.reset()\n","pred_adam = model_adam.predict_generator(test_gen, verbose=1, steps=PRED_STEPS)"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-output":true,"_uuid":"3bcf77f568962e91f1245ed77b00c5746ad4b48e","trusted":true},"outputs":[],"source":["print(len(pred_adam),\"\\n\",pred_adam)"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"dfb50c45a54612d6b6a0210d3f2c00f999bc1b52","trusted":true},"outputs":[],"source":["predicted_class_indices_adam = np.argmax(pred_adam,axis=1)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def retrieve_results(predicted_class_indices, train_gens):\n","    print(len(predicted_class_indices),\"\\n\",predicted_class_indices)\n","    print(\"it has values ranging from \",min(predicted_class_indices),\"...to...\",max(predicted_class_indices))\n","    labels = (train_gens[0].class_indices)\n","    labels = dict((v,k) for k,v in labels.items())\n","    predictions = [labels[k] for k in predicted_class_indices]\n","    print(\"*\"*20+\"\\nclass_indices\\n\"+\"*\"*20+\"\\n\",train_gens[0].class_indices,\"\\n\")\n","    print(\"*\"*20+\"\\nlabels\\n\"+\"*\"*20+\"\\n\",labels,\"\\n\")\n","    print(\"*\"*20+\"\\npredictions has\", len(predictions),\"values that look like\",\"'\"+str(predictions[0])+\"' which is the first prediction and corresponds to this index of the classes:\",train_gens[0].class_indices[predictions[0]])\n","    # Save the results to a CSV file.\n","    filenames=test_gen.filenames[:len(predictions)] # because \"ValueError: arrays must all be same length\"\n","\n","    real_artists = []\n","    for f in filenames:\n","        real = test_df[test_df['new_filename'] == f].artist.get_values()[0]\n","        real_artists.append(real)\n","\n","    results=pd.DataFrame({\"Filename\":filenames,\n","                        \"Predictions\":predictions,\n","                        \"Real Values\":real_artists})\n","    results.to_csv(\"results.csv\",index=False)\n","\n","    return results"]},{"cell_type":"markdown","metadata":{},"source":["## Adam"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["results_adam = retrieve_results(predicted_class_indices_adam, train_gens)"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"4acad3f61b891c2551a657ca242e6ee267919343","trusted":true},"outputs":[],"source":["results_adam.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"69605197bb4b01b272bccab9291b49f17e80fe0a","trusted":true},"outputs":[],"source":["len(training_set_artists)"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"8b1cd478370459daba02120d7613350baadd0518","trusted":true},"outputs":[],"source":["print(training_set_artists)"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"598d6d1189366f72d179c1f88ac026dade7dc1de","trusted":true},"outputs":[],"source":["def testing_new_images(results, training_set_artists):  \n","    count = 0\n","    match = 0\n","    unexpected_count = 0\n","    unexpected_match = 0\n","    match_both_expected_unexpected = 0\n","\n","    for p, r in zip(results['Predictions'], results['Real Values']):\n","        if r in training_set_artists:\n","            count += 1\n","            if p == r:\n","                match += 1\n","        else:\n","            unexpected_count += 1\n","            if p == r:\n","                unexpected_match += 1\n","\n","    print(\"test accuracy on new images for TRAINED artsits\")\n","    acc = match/count\n","    print(match,\"/\",count,\"=\",\"{:.4f}\".format(acc))\n","\n","    print(\"test accuracy on new images for UNEXPECTED artsits\")\n","    u_acc = unexpected_match/unexpected_count\n","    print(unexpected_match,\"/\",unexpected_count,\"=\",\"{:.4f}\".format(u_acc))\n","\n","    print(\"test accuracy on new images\")\n","    total_match = match+unexpected_match\n","    total_count = count+unexpected_count\n","    total_acc = (total_match)/(total_count)\n","    print(total_match,\"/\",total_count,\"=\",\"{:.4f}\".format(total_acc))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["testing_new_images(results_adam, training_set_artists)"]},{"cell_type":"markdown","metadata":{},"source":["## SGD"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["test_gen.reset()\n","pred_sgd = model_sgd.predict_generator(test_gen, verbose=1, steps=PRED_STEPS)\n","print(len(pred_sgd),\"\\n\",pred_sgd)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["predicted_class_indices_sgd = np.argmax(pred_sgd,axis=1)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["results_sgd = retrieve_results(predicted_class_indices_sgd, train_gens)\n","results_sgd.head()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(len(training_set_artists))\n","print(training_set_artists)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["testing_new_images(results_sgd, training_set_artists)"]},{"cell_type":"markdown","metadata":{"_uuid":"b71eebdaf00b0fa1d0b1401d8e00dff4a7b5111e"},"source":["So, it seems like the model may have learned some interesting patterns related to the artists that it expects. \n","\n","**Questions to explore:**\n","* [What does the model actually \"see\"](https://arxiv.org/abs/1312.6034) in a painting by [Pablo Picasso](https://www.wikiart.org/en/pablo-picasso/) as opposed to [Vincent van Gogh](https://www.wikiart.org/en/vincent-van-gogh)?\n","* What would happen if we trained the model on the full artist dataset or at least on artists with over 200 paintings in the dataset?\n","* Can the accuracy be improved with techniques like data augmentation or with a custom convolutional neural network? How about doing transfer learning with different [pre-trained model](https://keras.io/applications)?\n","* How can the learning rate be tuned to improve the accuracy?\n","* Would a regularization technique like [dropout](https://machinelearningmastery.com/dropout-regularization-deep-learning-models-keras/) be helpful?\n","* This notebook uses the [Adam](https://keras.io/optimizers/#adam) optimizer... what if we tried RMSprop?\n","* How about using an [ensemble of models](https://machinelearningmastery.com/ensemble-machine-learning-algorithms-python-scikit-learn/)?"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"}},"nbformat":4,"nbformat_minor":1}
>>>>>>> c2091dfb0a0f04302e772c050cb12b5390fe03fc
