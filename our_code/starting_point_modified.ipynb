{"cells":[{"cell_type":"markdown","metadata":{"_uuid":"969bd0a45cfbe4f4804ac2f920de35cbbc7bf1a8"},"source":["# Overview\n","\n","Can a computer \"learn\" to classify artists by their paintings? \n","\n","ResNet50 is a good model for classifying ImageNet data. How about a set of 38 artists?\n","\n","We use transfer learning to re-train a ResNet50 model to identify one of 38 artists who have more than ~~300~~ ***200*** paintings in the dataset. \n","\n","This notebook is part of a project for CSC 480 taught by [Dr. Franz J. Kurfess](http://users.csc.calpoly.edu/~fkurfess/) at Cal Poly\n","\n","A web application is [in development](https://github.com/SomethingAboutImages/WebImageClassifier) to make use of the model that this notebook outputs. "]},{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":false,"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","scrolled":true,"trusted":true},"outputs":[],"source":["import os\n","os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","# %matplotlib inline\n","import matplotlib.pyplot as plt\n","from random import seed # for setting seed\n","import tensorflow\n","from IPython import sys_info\n","\n","import gc # garbage collection"]},{"cell_type":"code","execution_count":2,"metadata":{"_uuid":"4cd71d6411b0bb2bee9d5a9f2421f8310509e008","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["{'commit_hash': '3427ce7',\n"," 'commit_source': 'installation',\n"," 'default_encoding': 'utf-8',\n"," 'ipython_path': '/anaconda/envs/myenv/lib/python3.12/site-packages/IPython',\n"," 'ipython_version': '8.24.0',\n"," 'os_name': 'posix',\n"," 'platform': 'Linux-5.15.0-1063-azure-x86_64-with-glibc2.31',\n"," 'sys_executable': '/anaconda/envs/myenv/bin/python',\n"," 'sys_platform': 'linux',\n"," 'sys_version': '3.12.3 | packaged by conda-forge | (main, Apr 15 2024, '\n","                '18:38:13) [GCC 12.3.0]'}\n","Note: you may need to restart the kernel to use updated packages.\n"]}],"source":["MY_SEED = 42 # 480 could work too\n","seed(MY_SEED)\n","np.random.seed(MY_SEED)\n","tensorflow.random.set_seed(MY_SEED)\n","\n","print(sys_info())\n","# get module information\n","%pip freeze > frozen-requirements.txt\n","# append system information to file\n","with open(\"frozen-requirements.txt\", \"a\") as file:\n","    file.write(sys_info())"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: absl-py==2.1.0 in /anaconda/envs/myenv/lib/python3.12/site-packages (from -r /home/xnmaster/Project/XNAPproject-grup07/our_code/frozen-requirements.txt (line 1)) (2.1.0)\n","Requirement already satisfied: astunparse==1.6.3 in /anaconda/envs/myenv/lib/python3.12/site-packages (from -r /home/xnmaster/Project/XNAPproject-grup07/our_code/frozen-requirements.txt (line 3)) (1.6.3)\n","Requirement already satisfied: certifi==2024.2.2 in /anaconda/envs/myenv/lib/python3.12/site-packages (from -r /home/xnmaster/Project/XNAPproject-grup07/our_code/frozen-requirements.txt (line 4)) (2024.2.2)\n","Requirement already satisfied: charset-normalizer==3.3.2 in /anaconda/envs/myenv/lib/python3.12/site-packages (from -r /home/xnmaster/Project/XNAPproject-grup07/our_code/frozen-requirements.txt (line 5)) (3.3.2)\n","Requirement already satisfied: contourpy==1.2.1 in /anaconda/envs/myenv/lib/python3.12/site-packages (from -r /home/xnmaster/Project/XNAPproject-grup07/our_code/frozen-requirements.txt (line 7)) (1.2.1)\n","Requirement already satisfied: cycler==0.12.1 in /anaconda/envs/myenv/lib/python3.12/site-packages (from -r /home/xnmaster/Project/XNAPproject-grup07/our_code/frozen-requirements.txt (line 8)) (0.12.1)\n","Requirement already satisfied: flatbuffers==24.3.25 in /anaconda/envs/myenv/lib/python3.12/site-packages (from -r /home/xnmaster/Project/XNAPproject-grup07/our_code/frozen-requirements.txt (line 13)) (24.3.25)\n","Requirement already satisfied: fonttools==4.51.0 in /anaconda/envs/myenv/lib/python3.12/site-packages (from -r /home/xnmaster/Project/XNAPproject-grup07/our_code/frozen-requirements.txt (line 14)) (4.51.0)\n","Requirement already satisfied: gast==0.5.4 in /anaconda/envs/myenv/lib/python3.12/site-packages (from -r /home/xnmaster/Project/XNAPproject-grup07/our_code/frozen-requirements.txt (line 15)) (0.5.4)\n","Requirement already satisfied: google-pasta==0.2.0 in /anaconda/envs/myenv/lib/python3.12/site-packages (from -r /home/xnmaster/Project/XNAPproject-grup07/our_code/frozen-requirements.txt (line 16)) (0.2.0)\n","Requirement already satisfied: grpcio==1.63.0 in /anaconda/envs/myenv/lib/python3.12/site-packages (from -r /home/xnmaster/Project/XNAPproject-grup07/our_code/frozen-requirements.txt (line 17)) (1.63.0)\n","Requirement already satisfied: h5py==3.11.0 in /anaconda/envs/myenv/lib/python3.12/site-packages (from -r /home/xnmaster/Project/XNAPproject-grup07/our_code/frozen-requirements.txt (line 18)) (3.11.0)\n","Requirement already satisfied: idna==3.7 in /anaconda/envs/myenv/lib/python3.12/site-packages (from -r /home/xnmaster/Project/XNAPproject-grup07/our_code/frozen-requirements.txt (line 19)) (3.7)\n","Requirement already satisfied: keras==3.3.3 in /anaconda/envs/myenv/lib/python3.12/site-packages (from -r /home/xnmaster/Project/XNAPproject-grup07/our_code/frozen-requirements.txt (line 26)) (3.3.3)\n","Requirement already satisfied: kiwisolver==1.4.5 in /anaconda/envs/myenv/lib/python3.12/site-packages (from -r /home/xnmaster/Project/XNAPproject-grup07/our_code/frozen-requirements.txt (line 27)) (1.4.5)\n","Requirement already satisfied: libclang==18.1.1 in /anaconda/envs/myenv/lib/python3.12/site-packages (from -r /home/xnmaster/Project/XNAPproject-grup07/our_code/frozen-requirements.txt (line 28)) (18.1.1)\n","Requirement already satisfied: Markdown==3.6 in /anaconda/envs/myenv/lib/python3.12/site-packages (from -r /home/xnmaster/Project/XNAPproject-grup07/our_code/frozen-requirements.txt (line 29)) (3.6)\n","Requirement already satisfied: markdown-it-py==3.0.0 in /anaconda/envs/myenv/lib/python3.12/site-packages (from -r /home/xnmaster/Project/XNAPproject-grup07/our_code/frozen-requirements.txt (line 30)) (3.0.0)\n","Requirement already satisfied: MarkupSafe==2.1.5 in /anaconda/envs/myenv/lib/python3.12/site-packages (from -r /home/xnmaster/Project/XNAPproject-grup07/our_code/frozen-requirements.txt (line 31)) (2.1.5)\n","Requirement already satisfied: matplotlib==3.8.4 in /anaconda/envs/myenv/lib/python3.12/site-packages (from -r /home/xnmaster/Project/XNAPproject-grup07/our_code/frozen-requirements.txt (line 32)) (3.8.4)\n","Requirement already satisfied: mdurl==0.1.2 in /anaconda/envs/myenv/lib/python3.12/site-packages (from -r /home/xnmaster/Project/XNAPproject-grup07/our_code/frozen-requirements.txt (line 34)) (0.1.2)\n","Requirement already satisfied: ml-dtypes==0.3.2 in /anaconda/envs/myenv/lib/python3.12/site-packages (from -r /home/xnmaster/Project/XNAPproject-grup07/our_code/frozen-requirements.txt (line 35)) (0.3.2)\n","Requirement already satisfied: namex==0.0.8 in /anaconda/envs/myenv/lib/python3.12/site-packages (from -r /home/xnmaster/Project/XNAPproject-grup07/our_code/frozen-requirements.txt (line 36)) (0.0.8)\n","Requirement already satisfied: numpy==1.26.4 in /anaconda/envs/myenv/lib/python3.12/site-packages (from -r /home/xnmaster/Project/XNAPproject-grup07/our_code/frozen-requirements.txt (line 38)) (1.26.4)\n","Requirement already satisfied: nvidia-cublas-cu12==12.3.4.1 in /anaconda/envs/myenv/lib/python3.12/site-packages (from -r /home/xnmaster/Project/XNAPproject-grup07/our_code/frozen-requirements.txt (line 39)) (12.3.4.1)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.3.101 in /anaconda/envs/myenv/lib/python3.12/site-packages (from -r /home/xnmaster/Project/XNAPproject-grup07/our_code/frozen-requirements.txt (line 40)) (12.3.101)\n","Requirement already satisfied: nvidia-cuda-nvcc-cu12==12.3.107 in /anaconda/envs/myenv/lib/python3.12/site-packages (from -r /home/xnmaster/Project/XNAPproject-grup07/our_code/frozen-requirements.txt (line 41)) (12.3.107)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.3.107 in /anaconda/envs/myenv/lib/python3.12/site-packages (from -r /home/xnmaster/Project/XNAPproject-grup07/our_code/frozen-requirements.txt (line 42)) (12.3.107)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.3.101 in /anaconda/envs/myenv/lib/python3.12/site-packages (from -r /home/xnmaster/Project/XNAPproject-grup07/our_code/frozen-requirements.txt (line 43)) (12.3.101)\n","Requirement already satisfied: nvidia-cudnn-cu12==8.9.7.29 in /anaconda/envs/myenv/lib/python3.12/site-packages (from -r /home/xnmaster/Project/XNAPproject-grup07/our_code/frozen-requirements.txt (line 44)) (8.9.7.29)\n","Requirement already satisfied: nvidia-cufft-cu12==11.0.12.1 in /anaconda/envs/myenv/lib/python3.12/site-packages (from -r /home/xnmaster/Project/XNAPproject-grup07/our_code/frozen-requirements.txt (line 45)) (11.0.12.1)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.4.107 in /anaconda/envs/myenv/lib/python3.12/site-packages (from -r /home/xnmaster/Project/XNAPproject-grup07/our_code/frozen-requirements.txt (line 46)) (10.3.4.107)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.5.4.101 in /anaconda/envs/myenv/lib/python3.12/site-packages (from -r /home/xnmaster/Project/XNAPproject-grup07/our_code/frozen-requirements.txt (line 47)) (11.5.4.101)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.2.0.103 in /anaconda/envs/myenv/lib/python3.12/site-packages (from -r /home/xnmaster/Project/XNAPproject-grup07/our_code/frozen-requirements.txt (line 48)) (12.2.0.103)\n","Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /anaconda/envs/myenv/lib/python3.12/site-packages (from -r /home/xnmaster/Project/XNAPproject-grup07/our_code/frozen-requirements.txt (line 49)) (2.19.3)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.3.101 in /anaconda/envs/myenv/lib/python3.12/site-packages (from -r /home/xnmaster/Project/XNAPproject-grup07/our_code/frozen-requirements.txt (line 50)) (12.3.101)\n","Requirement already satisfied: opt-einsum==3.3.0 in /anaconda/envs/myenv/lib/python3.12/site-packages (from -r /home/xnmaster/Project/XNAPproject-grup07/our_code/frozen-requirements.txt (line 51)) (3.3.0)\n","Requirement already satisfied: optree==0.11.0 in /anaconda/envs/myenv/lib/python3.12/site-packages (from -r /home/xnmaster/Project/XNAPproject-grup07/our_code/frozen-requirements.txt (line 52)) (0.11.0)\n","Requirement already satisfied: pandas==2.2.2 in /anaconda/envs/myenv/lib/python3.12/site-packages (from -r /home/xnmaster/Project/XNAPproject-grup07/our_code/frozen-requirements.txt (line 54)) (2.2.2)\n","Requirement already satisfied: pillow==10.3.0 in /anaconda/envs/myenv/lib/python3.12/site-packages (from -r /home/xnmaster/Project/XNAPproject-grup07/our_code/frozen-requirements.txt (line 58)) (10.3.0)\n","Requirement already satisfied: protobuf==4.25.3 in /anaconda/envs/myenv/lib/python3.12/site-packages (from -r /home/xnmaster/Project/XNAPproject-grup07/our_code/frozen-requirements.txt (line 61)) (4.25.3)\n","Requirement already satisfied: pyparsing==3.1.2 in /anaconda/envs/myenv/lib/python3.12/site-packages (from -r /home/xnmaster/Project/XNAPproject-grup07/our_code/frozen-requirements.txt (line 66)) (3.1.2)\n","Requirement already satisfied: pytz==2024.1 in /anaconda/envs/myenv/lib/python3.12/site-packages (from -r /home/xnmaster/Project/XNAPproject-grup07/our_code/frozen-requirements.txt (line 68)) (2024.1)\n","Requirement already satisfied: requests==2.31.0 in /anaconda/envs/myenv/lib/python3.12/site-packages (from -r /home/xnmaster/Project/XNAPproject-grup07/our_code/frozen-requirements.txt (line 70)) (2.31.0)\n","Requirement already satisfied: rich==13.7.1 in /anaconda/envs/myenv/lib/python3.12/site-packages (from -r /home/xnmaster/Project/XNAPproject-grup07/our_code/frozen-requirements.txt (line 71)) (13.7.1)\n","Requirement already satisfied: setuptools==69.5.1 in /anaconda/envs/myenv/lib/python3.12/site-packages (from -r /home/xnmaster/Project/XNAPproject-grup07/our_code/frozen-requirements.txt (line 72)) (69.5.1)\n","Requirement already satisfied: tensorboard==2.16.2 in /anaconda/envs/myenv/lib/python3.12/site-packages (from -r /home/xnmaster/Project/XNAPproject-grup07/our_code/frozen-requirements.txt (line 75)) (2.16.2)\n","Requirement already satisfied: tensorboard-data-server==0.7.2 in /anaconda/envs/myenv/lib/python3.12/site-packages (from -r /home/xnmaster/Project/XNAPproject-grup07/our_code/frozen-requirements.txt (line 76)) (0.7.2)\n","Requirement already satisfied: tensorflow==2.16.1 in /anaconda/envs/myenv/lib/python3.12/site-packages (from -r /home/xnmaster/Project/XNAPproject-grup07/our_code/frozen-requirements.txt (line 77)) (2.16.1)\n","Requirement already satisfied: termcolor==2.4.0 in /anaconda/envs/myenv/lib/python3.12/site-packages (from -r /home/xnmaster/Project/XNAPproject-grup07/our_code/frozen-requirements.txt (line 78)) (2.4.0)\n","Requirement already satisfied: tzdata==2024.1 in /anaconda/envs/myenv/lib/python3.12/site-packages (from -r /home/xnmaster/Project/XNAPproject-grup07/our_code/frozen-requirements.txt (line 82)) (2024.1)\n","Requirement already satisfied: urllib3==2.2.1 in /anaconda/envs/myenv/lib/python3.12/site-packages (from -r /home/xnmaster/Project/XNAPproject-grup07/our_code/frozen-requirements.txt (line 83)) (2.2.1)\n","Requirement already satisfied: Werkzeug==3.0.3 in /anaconda/envs/myenv/lib/python3.12/site-packages (from -r /home/xnmaster/Project/XNAPproject-grup07/our_code/frozen-requirements.txt (line 85)) (3.0.3)\n","Requirement already satisfied: wheel==0.43.0 in /anaconda/envs/myenv/lib/python3.12/site-packages (from -r /home/xnmaster/Project/XNAPproject-grup07/our_code/frozen-requirements.txt (line 86)) (0.43.0)\n","Requirement already satisfied: wrapt==1.16.0 in /anaconda/envs/myenv/lib/python3.12/site-packages (from -r /home/xnmaster/Project/XNAPproject-grup07/our_code/frozen-requirements.txt (line 87)) (1.16.0)\n","Requirement already satisfied: six<2.0,>=1.6.1 in /anaconda/envs/myenv/lib/python3.12/site-packages (from astunparse==1.6.3->-r /home/xnmaster/Project/XNAPproject-grup07/our_code/frozen-requirements.txt (line 3)) (1.16.0)\n","Requirement already satisfied: packaging>=20.0 in /anaconda/envs/myenv/lib/python3.12/site-packages (from matplotlib==3.8.4->-r /home/xnmaster/Project/XNAPproject-grup07/our_code/frozen-requirements.txt (line 32)) (24.0)\n","Requirement already satisfied: python-dateutil>=2.7 in /anaconda/envs/myenv/lib/python3.12/site-packages (from matplotlib==3.8.4->-r /home/xnmaster/Project/XNAPproject-grup07/our_code/frozen-requirements.txt (line 32)) (2.9.0)\n","Requirement already satisfied: typing-extensions>=4.0.0 in /anaconda/envs/myenv/lib/python3.12/site-packages (from optree==0.11.0->-r /home/xnmaster/Project/XNAPproject-grup07/our_code/frozen-requirements.txt (line 52)) (4.11.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /anaconda/envs/myenv/lib/python3.12/site-packages (from rich==13.7.1->-r /home/xnmaster/Project/XNAPproject-grup07/our_code/frozen-requirements.txt (line 71)) (2.18.0)\n","Note: you may need to restart the kernel to use updated packages.\n"]}],"source":["%pip install -r '/home/xnmaster/Project/XNAPproject-grup07/our_code/frozen-requirements.txt' #\"C:\\Users\\Mercè\\Documents\\UAB\\XN\\Projecte\\XNAPproject-grup07\\our_code\\frozen-requirements.txt\""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# %pip install tensorflow[and-cuda]"]},{"cell_type":"code","execution_count":5,"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"_uuid":"6bab4e1e53b22a9af9908fbefaeaa6f0e8b1110d","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["[name: \"/device:CPU:0\"\n","device_type: \"CPU\"\n","memory_limit: 268435456\n","locality {\n","}\n","incarnation: 12718142983825646422\n","xla_global_id: -1\n","]\n"]}],"source":["from tensorflow.python.client import device_lib\n","# print out the CPUs and GPUs\n","print(device_lib.list_local_devices())"]},{"cell_type":"code","execution_count":30,"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"_uuid":"1caeac96229a1e6db1d07b316cbfe62e1ee858d7","trusted":true},"outputs":[],"source":["# https://stackoverflow.com/questions/25705773/image-cropping-tool-python\n","# because painting images are hella big\n","from PIL import Image\n","Image.MAX_IMAGE_PIXELS = None"]},{"cell_type":"code","execution_count":7,"metadata":{"_uuid":"ca219817e229ad5e947b9a53a6bc9626cc7e2e02","trusted":true},"outputs":[],"source":["# globals\n","\n","DATA_DIR = '/home/xnmaster/Project/input/' # r\"C:\\Users\\Mercè\\Documents\\UAB\\XN\\Projecte\\input\" \n","\n","TRAIN_1_DIR =  '/home/xnmaster/Project/input/train_1' # r\"C:\\Users\\Mercè\\Documents\\UAB\\XN\\Projecte\\input\\train_1\\train_1\"\n","# TRAIN_2_DIR = '../input/painters-train-part-1/train_2/train_2/'\n","# TRAIN_3_DIR = '../input/painters-train-part-1/train_3/train_3/'\n","\n","# TRAIN_4_DIR = '../input/painters-train-part-2/train_4/train_4/'\n","# TRAIN_5_DIR = '../input/painters-train-part-2/train_5/train_5/'\n","# TRAIN_6_DIR = '../input/painters-train-part-2/train_6/train_6/'\n","\n","# TRAIN_7_DIR = '../input/painters-train-part-3/train_7/train_7/'\n","# TRAIN_8_DIR = '../input/painters-train-part-3/train_8/train_8/'\n","# TRAIN_9_DIR = '../input/painters-train-part-3/train_9/train_9/'\n","\n","# TRAIN_DIRS = [TRAIN_1_DIR, TRAIN_2_DIR, TRAIN_3_DIR,\n","#              TRAIN_4_DIR, TRAIN_5_DIR, TRAIN_6_DIR,\n","#              TRAIN_7_DIR, TRAIN_8_DIR, TRAIN_9_DIR]\n","\n","TRAIN_DIRS = [TRAIN_1_DIR]\n","TEST_DIR = '/home/xnmaster/Project/input/test/' # r\"C:\\Users\\Mercè\\Documents\\UAB\\XN\\Projecte\\input\\test\\test\" "]},{"cell_type":"code","execution_count":8,"metadata":{"_kg_hide-input":true,"_uuid":"8946b27facacf6814c81f06c53d34f8be7e5c53f","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["df.shape (79433, 6)\n"]}],"source":["df = pd.read_csv(DATA_DIR + 'train_info/train_info.csv') # r'\\train_info\\train_info.csv'\n","print(\"df.shape\", df.shape)"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>filename</th>\n","      <th>artist</th>\n","      <th>title</th>\n","      <th>style</th>\n","      <th>genre</th>\n","      <th>date</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>102257.jpg</td>\n","      <td>5b39c876740bfc1cfaf544721c43cac3</td>\n","      <td>Uriel</td>\n","      <td>Color Field Painting</td>\n","      <td>abstract</td>\n","      <td>1955.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>75232.jpg</td>\n","      <td>5b39c876740bfc1cfaf544721c43cac3</td>\n","      <td>Vir Heroicus Sublimis</td>\n","      <td>Color Field Painting</td>\n","      <td>abstract</td>\n","      <td>1950.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>29855.jpg</td>\n","      <td>96e5bc98488ed589b9bf17ad9fd09371</td>\n","      <td>Night March of a Hundred Demons (left half)</td>\n","      <td>Yamato-e</td>\n","      <td>mythological painting</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>62252.jpg</td>\n","      <td>5b39c876740bfc1cfaf544721c43cac3</td>\n","      <td>Who’s Afraid of Red,  Yellow and Blue II</td>\n","      <td>Color Field Painting</td>\n","      <td>abstract</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>63861.jpg</td>\n","      <td>5b39c876740bfc1cfaf544721c43cac3</td>\n","      <td>Black Fire I</td>\n","      <td>Color Field Painting</td>\n","      <td>abstract</td>\n","      <td>1963.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["     filename                            artist  \\\n","0  102257.jpg  5b39c876740bfc1cfaf544721c43cac3   \n","1   75232.jpg  5b39c876740bfc1cfaf544721c43cac3   \n","2   29855.jpg  96e5bc98488ed589b9bf17ad9fd09371   \n","3   62252.jpg  5b39c876740bfc1cfaf544721c43cac3   \n","4   63861.jpg  5b39c876740bfc1cfaf544721c43cac3   \n","\n","                                         title                 style  \\\n","0                                        Uriel  Color Field Painting   \n","1                        Vir Heroicus Sublimis  Color Field Painting   \n","2  Night March of a Hundred Demons (left half)              Yamato-e   \n","3     Who’s Afraid of Red,  Yellow and Blue II  Color Field Painting   \n","4                                Black Fire I   Color Field Painting   \n","\n","                   genre    date  \n","0               abstract  1955.0  \n","1               abstract  1950.0  \n","2  mythological painting     NaN  \n","3               abstract     NaN  \n","4               abstract  1963.0  "]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["df.head()"]},{"cell_type":"code","execution_count":10,"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"_uuid":"8aa0abdf69b880c834752ab85206dfcb6fef38d9","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["         filename                            artist  \\\n","520     41945.jpg  c7410238d399d9f454123e59b059fdd2   \n","722    101947.jpg  c7410238d399d9f454123e59b059fdd2   \n","793     95347.jpg  be8c592032dde81ef7e4247e3c7b5beb   \n","7649    91033.jpg  be8c592032dde81ef7e4247e3c7b5beb   \n","15230   79499.jpg  95170250b9a5101b11db6d60acfc9f86   \n","35511   92899.jpg  6e995a98857a349071182cf6c713e35f   \n","75522    3917.jpg  f7b0b8b497d3e489bd836159807ba906   \n","\n","                                                   title         style  \\\n","520                                Landscape at Beaulieu        Cubism   \n","722                                     Glass and carafe        Cubism   \n","793                                Robin of Modern Times   Romanticism   \n","7649                                Thoughts of the Past   Romanticism   \n","15230                                     Special No. 32  Abstract Art   \n","35511  A landscape with travellers crossing a bridge ...       Baroque   \n","75522                                   Cows by a Stream      Tonalism   \n","\n","                   genre    date  \n","520            cityscape    1918  \n","722           still life    1917  \n","793       genre painting    1860  \n","7649   symbolic painting     NaN  \n","15230           abstract  1915.0  \n","35511          landscape    1622  \n","75522  literary painting     NaN  \n","Empty DataFrame\n","Columns: [filename, artist, title, style, genre, date]\n","Index: []\n","df.shape (79426, 6)\n"]}],"source":["# quick fix for corrupted files\n","list_of_corrupted = ['3917.jpg','18649.jpg','20153.jpg','41945.jpg',\n","'79499.jpg','91033.jpg','92899.jpg','95347.jpg',\n","'100532.jpg','101947.jpg']\n","# display the corrupted rows of dataset for context\n","corrupt_df = df[df[\"filename\"].isin(list_of_corrupted) == True]\n","print(corrupt_df.head(len(list_of_corrupted)))\n","\n","# completely get rid of them\n","df = df[df[\"filename\"].isin(list_of_corrupted) == False]\n","\n","# try to see if they are still there\n","print(df[df[\"filename\"].isin(list_of_corrupted) == True])\n","\n","print(\"df.shape\", df.shape)"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["test_df.shape (79426, 2)\n"]}],"source":["test_df = df[['artist', 'filename']]\n","print(\"test_df.shape\", test_df.shape)"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>artist</th>\n","      <th>filename</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>5b39c876740bfc1cfaf544721c43cac3</td>\n","      <td>102257.jpg</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>5b39c876740bfc1cfaf544721c43cac3</td>\n","      <td>75232.jpg</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>96e5bc98488ed589b9bf17ad9fd09371</td>\n","      <td>29855.jpg</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>5b39c876740bfc1cfaf544721c43cac3</td>\n","      <td>62252.jpg</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5b39c876740bfc1cfaf544721c43cac3</td>\n","      <td>63861.jpg</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                             artist    filename\n","0  5b39c876740bfc1cfaf544721c43cac3  102257.jpg\n","1  5b39c876740bfc1cfaf544721c43cac3   75232.jpg\n","2  96e5bc98488ed589b9bf17ad9fd09371   29855.jpg\n","3  5b39c876740bfc1cfaf544721c43cac3   62252.jpg\n","4  5b39c876740bfc1cfaf544721c43cac3   63861.jpg"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["test_df.head()"]},{"cell_type":"code","execution_count":13,"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_kg_hide-input":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["train_df.shape (79426, 2)\n","number of artists 71\n","\n","list of artists...\n"," ['d09f796f2b0aa11dffc88badd9806119', '83e9823eb4868ca162fd3b7adff70096', '8e441c5899bf3d2f3b2c493e62fb92bf', 'db1318d32df7428076e03513ebf762bb', '6460e3ba02dfa3b57ebf5d3d0823aa47', '82665201c4108381d854740ddcb86e67', '397c63db1c7b507d23abff3f8bb0fa18', '8cdd41002b7b5c5d112865054a7fe13e', 'a6027a4ba71b61a55ea598379c9d508c', '1a8d67dbb446bdc4298cc0be56932a38', 'c8041306a183cbaf39ff8cd707c9cc7f', 'c3e9d9ebe5f2900190bef9342c440bd9', 'e60882af79cababb03ddfa980a75448c', 'd8a3c897c506be7de91d8f892f14f934', '4a30943bf6dd5da55d12ccd14aaff0d8', 'bfb541e54ad5c7320e8f80e2a2163e93', '8a1a67964c0cbea29fc9801b5c42c553', '96e7b1bc8d52e18caf0af34fec2e9bcb', '5fc2ffdd3d24ab503edd9a271dc379bd', 'dd4989789d310581024ae2b9203d5439', '50591a7061fb340d875723f38e00cc3b', 'b874a616affcb766bb0e7a4f2a0803f0', '54e7b38b5c91716bd3ad99a0ab740a18', '234c8d1df0b49b512791078cf00cf352', '3cc9a44380296d93e68b71a27643c25f', 'c16781c4321948227193214b68477a5c', 'dc589f213ba7bd398714ac2796b7c0ab', 'b64b426fa2b080ad94a2e1c7f423413c', '10bc951c2eb4a2f05fa773bdaace4e3b', 'bc58ed3c3e7750f9644953020a39e867', 'b844978933b7ae43e32ce775494821eb', '4b0465826ffd6db797ea6f3a5898df79', 'c9380d13360b37f21cfd174d92a7247e', '481c5c92d55717167e01821144a54635', '6f80666437feea42f295cdc0f1eb4df9', 'de42ef05d5901837bbe974fdb3c30ba5', 'b36edf57ed623e40e433565053f5f6ca', 'aceaa52f487dd19129857232b2eeb3d5', '45f4183820ce1fa775f8a27d3120aad6', '0eeac4ecff259dc515be795e1a76019a', '68cbc428edbcf480cbbb9a0e66e7046d', 'c56bcab4b317984013ebef5d3c4b5906', 'f7e1cb7b67e7b154d9dca7d12879d7b0', 'e1587900e782de448f604b37cde0fdfd', '121fffad1eb6f7dff228b8a71b6aec72', '31dbc08b8d0a3196c5484c0c068b2bcc', '3f8dc381ccfe9d5cc88b75970262715b', '512fb34e01bd21a92e7ec1380577c985', '1e8267251976e6f3b771b00f32c5798b', 'ce3d8977aae5986601232aa58d15282a', '1468ab18764365ded902fc726aec2c89', '49bb8d79587c2172c6cd04dd705fd891', '40f86d376acde0d9862ce7493745bdae', '1950e9aa6ad878bc2a330880f77ae5a1', '129349585c3d1f312535b6619fc36bf7', 'bc0ddf03c667c5edb17982be481ef360', '7b016984b86b58f83977299591cf4e38', '3937af6d364e2f24d1cce16fe3916536', '62b4406512c45730d2c7c40f5e3d0d12', '3edc6a404b8c67b7dad1405d52228c96', '80687062449ff7454e2c8926be56f643', 'cc47068929413a16aa707faefbdf4b70', '9649a0013a798a8367d2c493e37468ec', '147b0f64f4c2848bc0ad7bc1cdf74afe', '5e560e9b2ae0c20cfc57b308742bc677', '5aabfc58470d01bb2362795a44a2603b', 'c31b03be3da5810b44ea4782d2f3b8a0', '861c29e13205420326f7443ea77de5c9', 'bd14ef3c1a25cf0c5368ccd92a3c5f04', 'ccb8b07e7e3d837b2cd08d3edaf009cd', '5ae394770a82dac7cea5d95ef6482a11']\n"]}],"source":["\n","# train_df = df[df[\"in_train\"] == True]\n","# test_df = df[df['in_train'] == False]\n","train_df = df[['artist', 'filename']]\n","# test_df = test_df[['artist', 'new_filename']]\n","\n","# print(\"test_df.shape\", test_df.shape)\n","print(\"train_df.shape\", train_df.shape)\n","\n","artists = {} # holds artist hash & the count\n","for a in train_df['artist']:\n","    if (a not in artists):\n","        artists[a] = 1\n","    else:\n","        artists[a] += 1\n","\n","training_set_artists = []\n","for a,count in artists.items():\n","    if(int(count) >= 200):\n","        training_set_artists.append(a)\n","\n","print(\"number of artists\",len(training_set_artists))\n","\n","print(\"\\nlist of artists...\\n\", training_set_artists)\n"]},{"cell_type":"code","execution_count":14,"metadata":{"_kg_hide-input":true,"_uuid":"374cf6e0025c7221bbd1973c88f3702158e38c3f","trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>artist</th>\n","      <th>filename</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>9</th>\n","      <td>d09f796f2b0aa11dffc88badd9806119</td>\n","      <td>99442.jpg</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>83e9823eb4868ca162fd3b7adff70096</td>\n","      <td>7486.jpg</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>83e9823eb4868ca162fd3b7adff70096</td>\n","      <td>35766.jpg</td>\n","    </tr>\n","    <tr>\n","      <th>33</th>\n","      <td>8e441c5899bf3d2f3b2c493e62fb92bf</td>\n","      <td>99733.jpg</td>\n","    </tr>\n","    <tr>\n","      <th>34</th>\n","      <td>8e441c5899bf3d2f3b2c493e62fb92bf</td>\n","      <td>73690.jpg</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                              artist   filename\n","9   d09f796f2b0aa11dffc88badd9806119  99442.jpg\n","18  83e9823eb4868ca162fd3b7adff70096   7486.jpg\n","19  83e9823eb4868ca162fd3b7adff70096  35766.jpg\n","33  8e441c5899bf3d2f3b2c493e62fb92bf  99733.jpg\n","34  8e441c5899bf3d2f3b2c493e62fb92bf  73690.jpg"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["t_df = train_df[train_df[\"artist\"].isin(training_set_artists)]\n","\n","t_df.head(5)"]},{"cell_type":"code","execution_count":15,"metadata":{"_kg_hide-input":true,"_uuid":"b44f0b775da104dd716f4601cc164e7c4284bcec","trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>artist</th>\n","      <th>filename</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>9</th>\n","      <td>d09f796f2b0aa11dffc88badd9806119</td>\n","      <td>99442.jpg</td>\n","    </tr>\n","    <tr>\n","      <th>33</th>\n","      <td>8e441c5899bf3d2f3b2c493e62fb92bf</td>\n","      <td>99733.jpg</td>\n","    </tr>\n","    <tr>\n","      <th>35</th>\n","      <td>8e441c5899bf3d2f3b2c493e62fb92bf</td>\n","      <td>93715.jpg</td>\n","    </tr>\n","    <tr>\n","      <th>108</th>\n","      <td>a6027a4ba71b61a55ea598379c9d508c</td>\n","      <td>95360.jpg</td>\n","    </tr>\n","    <tr>\n","      <th>122</th>\n","      <td>8cdd41002b7b5c5d112865054a7fe13e</td>\n","      <td>96372.jpg</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                               artist   filename\n","9    d09f796f2b0aa11dffc88badd9806119  99442.jpg\n","33   8e441c5899bf3d2f3b2c493e62fb92bf  99733.jpg\n","35   8e441c5899bf3d2f3b2c493e62fb92bf  93715.jpg\n","108  a6027a4ba71b61a55ea598379c9d508c  95360.jpg\n","122  8cdd41002b7b5c5d112865054a7fe13e  96372.jpg"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["t1_df = t_df[t_df['filename'].str.startswith('1')]\n","\n","t2_df = t_df[t_df['filename'].str.startswith('2')]\n","\n","t3_df = t_df[t_df['filename'].str.startswith('3')]\n","\n","t4_df = t_df[t_df['filename'].str.startswith('4')]\n","\n","t5_df = t_df[t_df['filename'].str.startswith('5')]\n","\n","t6_df = t_df[t_df['filename'].str.startswith('6')]\n","\n","t7_df = t_df[t_df['filename'].str.startswith('7')]\n","\n","t8_df = t_df[t_df['filename'].str.startswith('8')]\n","\n","t9_df = t_df[t_df['filename'].str.startswith('9')]\n","\n","all_train_dfs = [t1_df, t2_df, t3_df,\n","                t4_df, t5_df, t6_df,\n","                t7_df, t8_df, t9_df]\n","\n","t9_df.head(5)"]},{"cell_type":"code","execution_count":16,"metadata":{"_kg_hide-input":false,"_kg_hide-output":false,"_uuid":"9f35f9102dabe4fd4c05d9b4da88929811c574cd","trusted":true},"outputs":[],"source":["from tensorflow.keras.applications import ResNet50\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Flatten, GlobalAveragePooling2D\n","\n","from tensorflow.keras.applications.resnet50 import preprocess_input\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n"]},{"cell_type":"markdown","metadata":{"_uuid":"30506b48fd6f5fd2636520b60baed80e20b8b944"},"source":["# specify the model that classifies 38 artists 🎨 🖌"]},{"cell_type":"code","execution_count":17,"metadata":{"_uuid":"e74625505706e025d7981c6712d21861f3ff6407","trusted":true},"outputs":[{"data":{"text/plain":["71"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["len(training_set_artists)"]},{"cell_type":"code","execution_count":18,"metadata":{"_uuid":"d3222704a8161b0530f4df9911acbbc54ce97039","trusted":true},"outputs":[],"source":["num_classes = len(training_set_artists) # one class per artist\n","weights_notop_path = r\"C:\\Users\\Mercè\\Documents\\UAB\\XN\\Projecte\\resnet50\\resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\"\n","model_adam = Sequential()\n","\n","model_adam.add(ResNet50(\n","  include_top=False,\n","  weights='imagenet',\n","  pooling='avg'\n","))\n","model_adam.add(Dense(\n","  num_classes,\n","  activation='softmax'\n","))\n","\n","model_adam.layers[0].trainable = False"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[],"source":["model_sgd = Sequential()\n","\n","model_sgd.add(ResNet50(\n","  include_top=False,\n","  weights='imagenet',\n","  pooling='avg'\n","))\n","model_sgd.add(Dense(\n","  num_classes,\n","  activation='softmax'\n","))\n","\n","model_sgd.layers[0].trainable = False"]},{"cell_type":"markdown","metadata":{"_uuid":"b14546c60c000f6f763d7ef225c2d5bb9bad75ee"},"source":["# Compile Model"]},{"cell_type":"markdown","metadata":{},"source":["## Adam"]},{"cell_type":"code","execution_count":20,"metadata":{"_uuid":"431d98d4322666bf0995dd65e7370e8e8d3ff36e","trusted":true},"outputs":[],"source":["model_adam.compile(\n","  optimizer='adam', # lots of people reccommend Adam optimizer\n","  loss='categorical_crossentropy', # aka \"log loss\" -- the cost function to minimize \n","  # so 'optimizer' algorithm will minimize 'loss' function\n","  metrics=['accuracy'] # ask it to report % of correct predictions\n",")"]},{"cell_type":"markdown","metadata":{},"source":["**Observation**\n","para un problema de clasificación binaria, a menudo se utiliza la 'entropía cruzada binaria', mientras que la 'entropía cruzada categórica' se utiliza para la clasificación de clases múltiples.\n","https://www.sourcetrail.com/es/pit%C3%B3n/keras/modelo-compilar-keras/"]},{"cell_type":"markdown","metadata":{},"source":["## SGD"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[],"source":["model_sgd.compile(\n","  optimizer='sgd', # lots of people reccommend Adam optimizer\n","  loss='categorical_crossentropy', # aka \"log loss\" -- the cost function to minimize \n","  # so 'optimizer' algorithm will minimize 'loss' function\n","  metrics=['accuracy'] # ask it to report % of correct predictions\n",")"]},{"cell_type":"markdown","metadata":{"_uuid":"7e00f7674040ad997d2e3c67d8e61b7f214e3709"},"source":["# Setup the image data generator for each training directory "]},{"cell_type":"code","execution_count":22,"metadata":{"_uuid":"c8005d5e86576cebc2b0fa0034ca2baed91c6de1","trusted":true},"outputs":[],"source":["# model globals\n","IMAGE_SIZE = 224\n","BATCH_SIZE = 96\n","TEST_BATCH_SIZE = 17 # because test has 23817 images and factors of 23817 are 3*17*467\n","                     # it is important that this number evenly divides the total num images \n","VAL_SPLIT = 0.25"]},{"cell_type":"code","execution_count":23,"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"_uuid":"6d229aed54ae275e7cff6382f3500a4ad21e4701","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["defined setup_generators()\n"]}],"source":["def setup_generators(\n","    val_split, train_dataframe, train_dir,\n","    img_size, batch_size, my_seed, list_of_classes,\n","    test_dataframe, test_dir, test_batch_size\n","):\n","    print(\"-\"*20)\n","    if not preprocess_input:\n","          raise Exception(\"please do import call 'from tensorflow.python.keras.applications.resnet50 import preprocess_input'\")\n","\n","    # setup resnet50 preprocessing \n","    data_gen = ImageDataGenerator(\n","        preprocessing_function=preprocess_input,\n","        validation_split=val_split)\n","\n","    print(len(train_dataframe), \"images in\", train_dir, \"and validation_split =\", val_split)\n","    print(\"\\ntraining set ImageDataGenerator\")\n","    train_gen = data_gen.flow_from_dataframe(\n","        dataframe=train_dataframe.reset_index(), # call reset_index() so keras can start with index 0\n","        directory=train_dir,\n","        x_col='filename',\n","        y_col='artist',\n","        has_ext=True,\n","        target_size=(img_size, img_size),\n","        subset=\"training\",\n","        batch_size=batch_size,\n","        seed=my_seed,\n","        shuffle=True,\n","        class_mode='categorical',\n","        classes=list_of_classes\n","    )\n","\n","    print(\"\\nvalidation set ImageDataGenerator\")\n","    valid_gen = data_gen.flow_from_dataframe(\n","        dataframe=train_dataframe.reset_index(), # call reset_index() so keras can start with index 0\n","        directory=train_dir,\n","        x_col='filename',\n","        y_col='artist',\n","        has_ext=True,\n","        subset=\"validation\",\n","        batch_size=batch_size,\n","        seed=my_seed,\n","        shuffle=True,\n","        target_size=(img_size,img_size),\n","        class_mode='categorical',\n","        classes=list_of_classes\n","    )\n","\n","    test_data_gen = ImageDataGenerator(preprocessing_function=preprocess_input)\n","\n","    print(\"\\ntest set ImageDataGenerator\")\n","    test_gen = test_data_gen.flow_from_dataframe(\n","        dataframe=test_dataframe.reset_index(), # call reset_index() so keras can start with index 0\n","        directory=test_dir,\n","        x_col='filename',\n","        y_col=None,\n","        has_ext=True,\n","        batch_size=test_batch_size,\n","        seed=my_seed,\n","        shuffle=False, # dont shuffle test directory\n","        class_mode=None,\n","        target_size=(img_size,img_size)\n","    )\n","\n","    return (train_gen, valid_gen, test_gen)\n","\n","print(\"defined setup_generators()\")"]},{"cell_type":"code","execution_count":24,"metadata":{"_kg_hide-input":true,"_uuid":"b899ca31427b36e183abfbc897caa05ca6102e05","trusted":true},"outputs":[{"data":{"text/plain":["15"]},"execution_count":24,"metadata":{},"output_type":"execute_result"}],"source":["# delete some unused dataframes to free some RAM for training\n","del df\n","del t_df\n","del t1_df\n","del t2_df\n","del t3_df\n","del t4_df\n","del t5_df\n","del t6_df\n","del t7_df\n","del t8_df\n","del t9_df\n","gc.collect()"]},{"cell_type":"code","execution_count":25,"metadata":{"_kg_hide-output":true,"_uuid":"906343b306f3d44981bc0693ed5185d8e2fdb446","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["--------------------\n","3092 images in /home/xnmaster/Project/input/train_1 and validation_split = 0.25\n","\n","training set ImageDataGenerator\n","Found 1848 validated image filenames belonging to 71 classes.\n","\n","validation set ImageDataGenerator\n","Found 616 validated image filenames belonging to 71 classes.\n","\n","test set ImageDataGenerator\n"]},{"name":"stderr","output_type":"stream","text":["/anaconda/envs/myenv/lib/python3.12/site-packages/keras/src/legacy/preprocessing/image.py:920: UserWarning: Found 628 invalid image filename(s) in x_col=\"filename\". These filename(s) will be ignored.\n","  warnings.warn(\n","/anaconda/envs/myenv/lib/python3.12/site-packages/keras/src/legacy/preprocessing/image.py:920: UserWarning: Found 628 invalid image filename(s) in x_col=\"filename\". These filename(s) will be ignored.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["Found 0 validated image filenames.\n"]},{"name":"stderr","output_type":"stream","text":["/anaconda/envs/myenv/lib/python3.12/site-packages/keras/src/legacy/preprocessing/image.py:920: UserWarning: Found 79426 invalid image filename(s) in x_col=\"filename\". These filename(s) will be ignored.\n","  warnings.warn(\n"]}],"source":["train_gens = [None]*len(TRAIN_DIRS)\n","valid_gens = [None]*len(TRAIN_DIRS)\n","test_gen  = None # only 1 test_gen\n","i = 0\n","for i in range(0, len(TRAIN_DIRS)):\n","    train_gens[i], valid_gens[i], test_gen = setup_generators(\n","        train_dataframe=all_train_dfs[i], train_dir=TRAIN_DIRS[i],\n","        val_split=VAL_SPLIT, img_size=IMAGE_SIZE, batch_size=BATCH_SIZE, my_seed=MY_SEED, \n","        list_of_classes=training_set_artists, test_dataframe=test_df, \n","        test_dir=TEST_DIR, test_batch_size=TEST_BATCH_SIZE\n","    )\n","    i += 1"]},{"cell_type":"markdown","metadata":{"_uuid":"d7978eabacec7bf8c313d1fda177d876a2a38cc1"},"source":["# TRAINING TIME!  🎉 🎊 🎁"]},{"cell_type":"code","execution_count":26,"metadata":{"_uuid":"31f15a418cd7e0550700645090e006d3438c4f59","trusted":true},"outputs":[],"source":["MAX_EPOCHS = 5 * len(train_gens) # should be a multiple of 9 because need evenly train each train_dir\n","DIR_EPOCHS = 1 # fit each train_dir at least this many times before overfitting"]},{"cell_type":"code","execution_count":28,"metadata":{},"outputs":[],"source":["from PIL import ImageFile\n","ImageFile.LOAD_TRUNCATED_IMAGES = True"]},{"cell_type":"code","execution_count":31,"metadata":{"_kg_hide-output":true,"_uuid":"71704f10dbbf6803e03934be1f3ac8de05d878f4","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["STEP_SIZE_TRAIN 19\n","STEP_SIZE_VALID 6\n"]},{"ename":"UnidentifiedImageError","evalue":"cannot identify image file <_io.BytesIO object at 0x7f8f44814e50>","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mUnidentifiedImageError\u001b[0m                    Traceback (most recent call last)","Cell \u001b[0;32mIn[31], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSTEP_SIZE_TRAIN\u001b[39m\u001b[38;5;124m\"\u001b[39m,STEP_SIZE_TRAIN)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSTEP_SIZE_VALID\u001b[39m\u001b[38;5;124m\"\u001b[39m,STEP_SIZE_VALID)\n\u001b[1;32m     12\u001b[0m histories_adam\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m---> 13\u001b[0m     \u001b[43mmodel_adam\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_gens\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m                        \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mSTEP_SIZE_TRAIN\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalid_gens\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mSTEP_SIZE_VALID\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDIR_EPOCHS\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m )\n\u001b[1;32m     19\u001b[0m e\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n","File \u001b[0;32m/anaconda/envs/myenv/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n","File \u001b[0;32m/anaconda/envs/myenv/lib/python3.12/site-packages/PIL/Image.py:3339\u001b[0m, in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3337\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(message)\n\u001b[1;32m   3338\u001b[0m msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot identify image file \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (filename \u001b[38;5;28;01mif\u001b[39;00m filename \u001b[38;5;28;01melse\u001b[39;00m fp)\n\u001b[0;32m-> 3339\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m UnidentifiedImageError(msg)\n","\u001b[0;31mUnidentifiedImageError\u001b[0m: cannot identify image file <_io.BytesIO object at 0x7f8f44814e50>"]}],"source":["histories_adam = []\n","\n","e=0\n","while ( e < MAX_EPOCHS):\n","    for i in range(0, len(train_gens)):\n","        # train_gen.n = number of images for training\n","        STEP_SIZE_TRAIN = train_gens[i].n//train_gens[i].batch_size\n","        # train_gen.n = number of images for validation\n","        STEP_SIZE_VALID = valid_gens[i].n//valid_gens[i].batch_size\n","        print(\"STEP_SIZE_TRAIN\",STEP_SIZE_TRAIN)\n","        print(\"STEP_SIZE_VALID\",STEP_SIZE_VALID)\n","        histories_adam.append(\n","            model_adam.fit(train_gens[i],\n","                                steps_per_epoch=STEP_SIZE_TRAIN,\n","                                validation_data=valid_gens[i],\n","                                validation_steps=STEP_SIZE_VALID,\n","                                epochs=DIR_EPOCHS)\n","        )\n","        e+=1"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["histories_sgd = []\n","\n","e=0\n","while ( e < MAX_EPOCHS):\n","    for i in range(0, len(train_gens)):\n","        # train_gen.n = number of images for training\n","        STEP_SIZE_TRAIN = train_gens[i].n//train_gens[i].batch_size\n","        # train_gen.n = number of images for validation\n","        STEP_SIZE_VALID = valid_gens[i].n//valid_gens[i].batch_size\n","        print(\"STEP_SIZE_TRAIN\",STEP_SIZE_TRAIN)\n","        print(\"STEP_SIZE_VALID\",STEP_SIZE_VALID)\n","        histories_sgd.append(\n","            model_sgd.fit(train_gens[i],\n","                                steps_per_epoch=STEP_SIZE_TRAIN,\n","                                validation_data=valid_gens[i],\n","                                validation_steps=STEP_SIZE_VALID,\n","                                epochs=DIR_EPOCHS)\n","        )\n","        e+=1"]},{"cell_type":"markdown","metadata":{"_uuid":"3a05218bcf6f36b56519fd3091b182c2efd756a9"},"source":["# Evaluate the model 🧐 🤔"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true,"_uuid":"30f09ae79b59fbec2375dd5eadee5c1af61dbb03","trusted":true},"outputs":[],"source":["accuracies_adam = []\n","val_accuracies_adam = []\n","losses_adam = []\n","val_losses_adam = []\n","for hist in histories_adam:\n","    if hist:\n","        accuracies_adam += hist.history['acc']\n","        val_accuracies_adam += hist.history['val_acc']\n","        losses_adam += hist.history['loss']\n","        val_losses_adam += hist.history['val_loss']"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["accuracies_sgd = []\n","val_accuracies_sgd = []\n","losses_sgd = []\n","val_losses_sgd = []\n","for hist in histories_sgd:\n","    if hist:\n","        accuracies_sgd += hist.history['acc']\n","        val_accuracies_sgd += hist.history['val_acc']\n","        losses_sgd += hist.history['loss']\n","        val_losses_sgd += hist.history['val_loss']"]},{"cell_type":"markdown","metadata":{},"source":["## Plots\n","### Accuracies"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true,"_uuid":"b2b8b4d7f244b57cc3df0fba829fb73a93da8d23","trusted":true},"outputs":[],"source":["# Plot training & validation accuracy values\n","plt.plot(accuracies_adam, label = \"Adam Train\")\n","plt.plot(val_accuracies_adam, label = \"Adam Test\")\n","\n","plt.plot(accuracies_sgd, label = \"SGD Train\")\n","plt.plot(val_accuracies_sgd, label = \"SGD Test\")\n","\n","plt.title('Model accuracy')\n","plt.ylabel('Accuracy')\n","plt.xlabel('Epoch')\n","plt.legend()\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["### Loss values"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Plot training & validation loss values\n","plt.plot(losses_adam, label = \"Adam Train\")\n","plt.plot(val_losses_adam, label = \"Adam Test\")\n","\n","plt.plot(losses_sgd, label = \"SGD Train\")\n","plt.plot(val_losses_sgd, label = \"SGD Test\")\n","\n","plt.title('Model loss')\n","plt.ylabel('Loss')\n","plt.xlabel('Epoch')\n","plt.legend()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"15433eaf26bb11ff67095ba0cbe781b62453a62a","trusted":true},"outputs":[],"source":["import time\n","timestr = time.strftime(\"%Y%m%d-%H%M%S\") # e.g: 20181109-180140\n","model_adam.save('painters_adam_e45_'+timestr+'.h5')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["timestr = time.strftime(\"%Y%m%d-%H%M%S\") # e.g: 20181109-180140\n","model_sgd.save('painters_adam_e45_'+timestr+'.h5')"]},{"cell_type":"markdown","metadata":{"_uuid":"2fa3ebde72fb64279bc367da190783f2524d2bad"},"source":["# Predict the output 🔮 🎩"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"160deb675d28625a391b3760ffa105e2272bb023","trusted":true},"outputs":[],"source":["PRED_STEPS = len(test_gen) #100 # default would have been len(test_gen)"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"98425b4ae320934e1ef68b50ea34deac31c284ab","trusted":true},"outputs":[],"source":["# Need to reset the test_gen before calling predict_generator\n","# This is important because forgetting to reset the test_generator results in outputs with a weird order.\n","test_gen.reset()\n","pred_adam = model_adam.predict_generator(test_gen, verbose=1, steps=PRED_STEPS)"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-output":true,"_uuid":"3bcf77f568962e91f1245ed77b00c5746ad4b48e","trusted":true},"outputs":[],"source":["print(len(pred_adam),\"\\n\",pred_adam)"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"dfb50c45a54612d6b6a0210d3f2c00f999bc1b52","trusted":true},"outputs":[],"source":["predicted_class_indices_adam = np.argmax(pred_adam,axis=1)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def retrieve_results(predicted_class_indices, train_gens):\n","    print(len(predicted_class_indices),\"\\n\",predicted_class_indices)\n","    print(\"it has values ranging from \",min(predicted_class_indices),\"...to...\",max(predicted_class_indices))\n","    labels = (train_gens[0].class_indices)\n","    labels = dict((v,k) for k,v in labels.items())\n","    predictions = [labels[k] for k in predicted_class_indices]\n","    print(\"*\"*20+\"\\nclass_indices\\n\"+\"*\"*20+\"\\n\",train_gens[0].class_indices,\"\\n\")\n","    print(\"*\"*20+\"\\nlabels\\n\"+\"*\"*20+\"\\n\",labels,\"\\n\")\n","    print(\"*\"*20+\"\\npredictions has\", len(predictions),\"values that look like\",\"'\"+str(predictions[0])+\"' which is the first prediction and corresponds to this index of the classes:\",train_gens[0].class_indices[predictions[0]])\n","    # Save the results to a CSV file.\n","    filenames=test_gen.filenames[:len(predictions)] # because \"ValueError: arrays must all be same length\"\n","\n","    real_artists = []\n","    for f in filenames:\n","        real = test_df[test_df['new_filename'] == f].artist.get_values()[0]\n","        real_artists.append(real)\n","\n","    results=pd.DataFrame({\"Filename\":filenames,\n","                        \"Predictions\":predictions,\n","                        \"Real Values\":real_artists})\n","    results.to_csv(\"results.csv\",index=False)\n","\n","    return results"]},{"cell_type":"markdown","metadata":{},"source":["## Adam"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["results_adam = retrieve_results(predicted_class_indices_adam, train_gens)"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"4acad3f61b891c2551a657ca242e6ee267919343","trusted":true},"outputs":[],"source":["results_adam.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"69605197bb4b01b272bccab9291b49f17e80fe0a","trusted":true},"outputs":[],"source":["len(training_set_artists)"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"8b1cd478370459daba02120d7613350baadd0518","trusted":true},"outputs":[],"source":["print(training_set_artists)"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"598d6d1189366f72d179c1f88ac026dade7dc1de","trusted":true},"outputs":[],"source":["def testing_new_images(results, training_set_artists):  \n","    count = 0\n","    match = 0\n","    unexpected_count = 0\n","    unexpected_match = 0\n","    match_both_expected_unexpected = 0\n","\n","    for p, r in zip(results['Predictions'], results['Real Values']):\n","        if r in training_set_artists:\n","            count += 1\n","            if p == r:\n","                match += 1\n","        else:\n","            unexpected_count += 1\n","            if p == r:\n","                unexpected_match += 1\n","\n","    print(\"test accuracy on new images for TRAINED artsits\")\n","    acc = match/count\n","    print(match,\"/\",count,\"=\",\"{:.4f}\".format(acc))\n","\n","    print(\"test accuracy on new images for UNEXPECTED artsits\")\n","    u_acc = unexpected_match/unexpected_count\n","    print(unexpected_match,\"/\",unexpected_count,\"=\",\"{:.4f}\".format(u_acc))\n","\n","    print(\"test accuracy on new images\")\n","    total_match = match+unexpected_match\n","    total_count = count+unexpected_count\n","    total_acc = (total_match)/(total_count)\n","    print(total_match,\"/\",total_count,\"=\",\"{:.4f}\".format(total_acc))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["testing_new_images(results_adam, training_set_artists)"]},{"cell_type":"markdown","metadata":{},"source":["## SGD"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["test_gen.reset()\n","pred_sgd = model_sgd.predict_generator(test_gen, verbose=1, steps=PRED_STEPS)\n","print(len(pred_sgd),\"\\n\",pred_sgd)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["predicted_class_indices_sgd = np.argmax(pred_sgd,axis=1)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["results_sgd = retrieve_results(predicted_class_indices_sgd, train_gens)\n","results_sgd.head()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(len(training_set_artists))\n","print(training_set_artists)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["testing_new_images(results_sgd, training_set_artists)"]},{"cell_type":"markdown","metadata":{"_uuid":"b71eebdaf00b0fa1d0b1401d8e00dff4a7b5111e"},"source":["So, it seems like the model may have learned some interesting patterns related to the artists that it expects. \n","\n","**Questions to explore:**\n","* [What does the model actually \"see\"](https://arxiv.org/abs/1312.6034) in a painting by [Pablo Picasso](https://www.wikiart.org/en/pablo-picasso/) as opposed to [Vincent van Gogh](https://www.wikiart.org/en/vincent-van-gogh)?\n","* What would happen if we trained the model on the full artist dataset or at least on artists with over 200 paintings in the dataset?\n","* Can the accuracy be improved with techniques like data augmentation or with a custom convolutional neural network? How about doing transfer learning with different [pre-trained model](https://keras.io/applications)?\n","* How can the learning rate be tuned to improve the accuracy?\n","* Would a regularization technique like [dropout](https://machinelearningmastery.com/dropout-regularization-deep-learning-models-keras/) be helpful?\n","* This notebook uses the [Adam](https://keras.io/optimizers/#adam) optimizer... what if we tried RMSprop?\n","* How about using an [ensemble of models](https://machinelearningmastery.com/ensemble-machine-learning-algorithms-python-scikit-learn/)?"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.3"}},"nbformat":4,"nbformat_minor":1}
