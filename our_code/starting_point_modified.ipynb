{"cells":[{"cell_type":"markdown","metadata":{"_uuid":"969bd0a45cfbe4f4804ac2f920de35cbbc7bf1a8"},"source":["# Overview\n","\n","Can a computer \"learn\" to classify artists by their paintings? \n","\n","ResNet50 is a good model for classifying ImageNet data. How about a set of 38 artists?\n","\n","We use transfer learning to re-train a ResNet50 model to identify one of 38 artists who have more than ~~300~~ ***200*** paintings in the dataset. \n","\n","This notebook is part of a project for CSC 480 taught by [Dr. Franz J. Kurfess](http://users.csc.calpoly.edu/~fkurfess/) at Cal Poly\n","\n","A web application is [in development](https://github.com/SomethingAboutImages/WebImageClassifier) to make use of the model that this notebook outputs. "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":false,"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","scrolled":true,"trusted":true},"outputs":[],"source":["import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","# %matplotlib inline\n","import matplotlib.pyplot as plt\n","from random import seed # for setting seed\n","import tensorflow\n","from IPython import sys_info\n","\n","import gc # garbage collection"]},{"cell_type":"code","execution_count":2,"metadata":{"_uuid":"4cd71d6411b0bb2bee9d5a9f2421f8310509e008","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["{'commit_hash': '19f24dd8e',\n"," 'commit_source': 'installation',\n"," 'default_encoding': 'utf-8',\n"," 'ipython_path': 'C:\\\\Users\\\\Merc√®\\\\anaconda3\\\\Lib\\\\site-packages\\\\IPython',\n"," 'ipython_version': '8.20.0',\n"," 'os_name': 'nt',\n"," 'platform': 'Windows-10-10.0.22631-SP0',\n"," 'sys_executable': 'c:\\\\Users\\\\Merc√®\\\\anaconda3\\\\python.exe',\n"," 'sys_platform': 'win32',\n"," 'sys_version': '3.11.7 | packaged by Anaconda, Inc. | (main, Dec 15 2023, '\n","                '18:05:47) [MSC v.1916 64 bit (AMD64)]'}\n","Note: you may need to restart the kernel to use updated packages.\n"]}],"source":["MY_SEED = 42 # 480 could work too\n","seed(MY_SEED)\n","np.random.seed(MY_SEED)\n","tensorflow.random.set_seed(MY_SEED)\n","\n","print(sys_info())\n","# get module information\n","%pip freeze > frozen-requirements.txt\n","# append system information to file\n","with open(\"frozen-requirements.txt\", \"a\") as file:\n","    file.write(sys_info())"]},{"cell_type":"code","execution_count":3,"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"_uuid":"6bab4e1e53b22a9af9908fbefaeaa6f0e8b1110d","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["[name: \"/device:CPU:0\"\n","device_type: \"CPU\"\n","memory_limit: 268435456\n","locality {\n","}\n","incarnation: 471354476611181453\n","xla_global_id: -1\n","]\n"]}],"source":["from tensorflow.python.client import device_lib\n","# print out the CPUs and GPUs\n","print(device_lib.list_local_devices())"]},{"cell_type":"code","execution_count":4,"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"_uuid":"1caeac96229a1e6db1d07b316cbfe62e1ee858d7","trusted":true},"outputs":[],"source":["# https://stackoverflow.com/questions/25705773/image-cropping-tool-python\n","# because painting images are hella big\n","from PIL import Image\n","Image.MAX_IMAGE_PIXELS = None"]},{"cell_type":"code","execution_count":5,"metadata":{"_uuid":"ca219817e229ad5e947b9a53a6bc9626cc7e2e02","trusted":true},"outputs":[],"source":["# globals\n","\n","DATA_DIR = r\"C:\\Users\\Merc√®\\Documents\\UAB\\XN\\Projecte\\input\" # '/home/xnmaster/Project/input/'\n","\n","TRAIN_1_DIR =  r\"C:\\Users\\Merc√®\\Documents\\UAB\\XN\\Projecte\\input\\train_1\\train_1\" # '/home/xnmaster/Project/input/train_1'\n","# TRAIN_2_DIR = '../input/painters-train-part-1/train_2/train_2/'\n","# TRAIN_3_DIR = '../input/painters-train-part-1/train_3/train_3/'\n","\n","# TRAIN_4_DIR = '../input/painters-train-part-2/train_4/train_4/'\n","# TRAIN_5_DIR = '../input/painters-train-part-2/train_5/train_5/'\n","# TRAIN_6_DIR = '../input/painters-train-part-2/train_6/train_6/'\n","\n","# TRAIN_7_DIR = '../input/painters-train-part-3/train_7/train_7/'\n","# TRAIN_8_DIR = '../input/painters-train-part-3/train_8/train_8/'\n","# TRAIN_9_DIR = '../input/painters-train-part-3/train_9/train_9/'\n","\n","# TRAIN_DIRS = [TRAIN_1_DIR, TRAIN_2_DIR, TRAIN_3_DIR,\n","#              TRAIN_4_DIR, TRAIN_5_DIR, TRAIN_6_DIR,\n","#              TRAIN_7_DIR, TRAIN_8_DIR, TRAIN_9_DIR]\n","\n","TRAIN_DIRS = [TRAIN_1_DIR]\n","TEST_DIR = r\"C:\\Users\\Merc√®\\Documents\\UAB\\XN\\Projecte\\input\\test\\test\" # '/home/xnmaster/Project/input/test/'"]},{"cell_type":"code","execution_count":6,"metadata":{"_kg_hide-input":true,"_uuid":"8946b27facacf6814c81f06c53d34f8be7e5c53f","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["df.shape (79433, 6)\n"]}],"source":["df = pd.read_csv(DATA_DIR + r'\\train_info\\train_info.csv')\n","print(\"df.shape\", df.shape)"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>filename</th>\n","      <th>artist</th>\n","      <th>title</th>\n","      <th>style</th>\n","      <th>genre</th>\n","      <th>date</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>102257.jpg</td>\n","      <td>5b39c876740bfc1cfaf544721c43cac3</td>\n","      <td>Uriel</td>\n","      <td>Color Field Painting</td>\n","      <td>abstract</td>\n","      <td>1955.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>75232.jpg</td>\n","      <td>5b39c876740bfc1cfaf544721c43cac3</td>\n","      <td>Vir Heroicus Sublimis</td>\n","      <td>Color Field Painting</td>\n","      <td>abstract</td>\n","      <td>1950.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>29855.jpg</td>\n","      <td>96e5bc98488ed589b9bf17ad9fd09371</td>\n","      <td>Night March of a Hundred Demons (left half)</td>\n","      <td>Yamato-e</td>\n","      <td>mythological painting</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>62252.jpg</td>\n","      <td>5b39c876740bfc1cfaf544721c43cac3</td>\n","      <td>Who‚Äôs Afraid of Red,  Yellow and Blue II</td>\n","      <td>Color Field Painting</td>\n","      <td>abstract</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>63861.jpg</td>\n","      <td>5b39c876740bfc1cfaf544721c43cac3</td>\n","      <td>Black Fire I</td>\n","      <td>Color Field Painting</td>\n","      <td>abstract</td>\n","      <td>1963.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["     filename                            artist  \\\n","0  102257.jpg  5b39c876740bfc1cfaf544721c43cac3   \n","1   75232.jpg  5b39c876740bfc1cfaf544721c43cac3   \n","2   29855.jpg  96e5bc98488ed589b9bf17ad9fd09371   \n","3   62252.jpg  5b39c876740bfc1cfaf544721c43cac3   \n","4   63861.jpg  5b39c876740bfc1cfaf544721c43cac3   \n","\n","                                         title                 style  \\\n","0                                        Uriel  Color Field Painting   \n","1                        Vir Heroicus Sublimis  Color Field Painting   \n","2  Night March of a Hundred Demons (left half)              Yamato-e   \n","3     Who‚Äôs Afraid of Red,  Yellow and Blue II  Color Field Painting   \n","4                                Black Fire I   Color Field Painting   \n","\n","                   genre    date  \n","0               abstract  1955.0  \n","1               abstract  1950.0  \n","2  mythological painting     NaN  \n","3               abstract     NaN  \n","4               abstract  1963.0  "]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["df.head()"]},{"cell_type":"code","execution_count":9,"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"_uuid":"8aa0abdf69b880c834752ab85206dfcb6fef38d9","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["         filename                            artist  \\\n","520     41945.jpg  c7410238d399d9f454123e59b059fdd2   \n","722    101947.jpg  c7410238d399d9f454123e59b059fdd2   \n","793     95347.jpg  be8c592032dde81ef7e4247e3c7b5beb   \n","7649    91033.jpg  be8c592032dde81ef7e4247e3c7b5beb   \n","15230   79499.jpg  95170250b9a5101b11db6d60acfc9f86   \n","35511   92899.jpg  6e995a98857a349071182cf6c713e35f   \n","75522    3917.jpg  f7b0b8b497d3e489bd836159807ba906   \n","\n","                                                   title         style  \\\n","520                                Landscape¬†at¬†Beaulieu        Cubism   \n","722                                     Glass¬†and¬†carafe        Cubism   \n","793                                Robin of Modern Times   Romanticism   \n","7649                                Thoughts of the Past   Romanticism   \n","15230                                     Special No. 32  Abstract Art   \n","35511  A landscape with travellers crossing a bridge ...       Baroque   \n","75522                                   Cows by a Stream      Tonalism   \n","\n","                   genre    date  \n","520            cityscape    1918  \n","722           still life    1917  \n","793       genre painting    1860  \n","7649   symbolic painting     NaN  \n","15230           abstract  1915.0  \n","35511          landscape    1622  \n","75522  literary painting     NaN  \n","Empty DataFrame\n","Columns: [filename, artist, title, style, genre, date]\n","Index: []\n","df.shape (79426, 6)\n"]}],"source":["# quick fix for corrupted files\n","list_of_corrupted = ['3917.jpg','18649.jpg','20153.jpg','41945.jpg',\n","'79499.jpg','91033.jpg','92899.jpg','95347.jpg',\n","'100532.jpg','101947.jpg']\n","# display the corrupted rows of dataset for context\n","corrupt_df = df[df[\"filename\"].isin(list_of_corrupted) == True]\n","print(corrupt_df.head(len(list_of_corrupted)))\n","\n","# completely get rid of them\n","df = df[df[\"filename\"].isin(list_of_corrupted) == False]\n","\n","# try to see if they are still there\n","print(df[df[\"filename\"].isin(list_of_corrupted) == True])\n","\n","print(\"df.shape\", df.shape)"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["test_df.shape (79426, 2)\n"]}],"source":["test_df = df[['artist', 'filename']]\n","print(\"test_df.shape\", test_df.shape)"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>artist</th>\n","      <th>filename</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>5b39c876740bfc1cfaf544721c43cac3</td>\n","      <td>102257.jpg</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>5b39c876740bfc1cfaf544721c43cac3</td>\n","      <td>75232.jpg</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>96e5bc98488ed589b9bf17ad9fd09371</td>\n","      <td>29855.jpg</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>5b39c876740bfc1cfaf544721c43cac3</td>\n","      <td>62252.jpg</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5b39c876740bfc1cfaf544721c43cac3</td>\n","      <td>63861.jpg</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                             artist    filename\n","0  5b39c876740bfc1cfaf544721c43cac3  102257.jpg\n","1  5b39c876740bfc1cfaf544721c43cac3   75232.jpg\n","2  96e5bc98488ed589b9bf17ad9fd09371   29855.jpg\n","3  5b39c876740bfc1cfaf544721c43cac3   62252.jpg\n","4  5b39c876740bfc1cfaf544721c43cac3   63861.jpg"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["test_df.head()"]},{"cell_type":"code","execution_count":12,"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_kg_hide-input":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["train_df.shape (79426, 2)\n","number of artists 71\n","\n","list of artists...\n"," ['d09f796f2b0aa11dffc88badd9806119', '83e9823eb4868ca162fd3b7adff70096', '8e441c5899bf3d2f3b2c493e62fb92bf', 'db1318d32df7428076e03513ebf762bb', '6460e3ba02dfa3b57ebf5d3d0823aa47', '82665201c4108381d854740ddcb86e67', '397c63db1c7b507d23abff3f8bb0fa18', '8cdd41002b7b5c5d112865054a7fe13e', 'a6027a4ba71b61a55ea598379c9d508c', '1a8d67dbb446bdc4298cc0be56932a38', 'c8041306a183cbaf39ff8cd707c9cc7f', 'c3e9d9ebe5f2900190bef9342c440bd9', 'e60882af79cababb03ddfa980a75448c', 'd8a3c897c506be7de91d8f892f14f934', '4a30943bf6dd5da55d12ccd14aaff0d8', 'bfb541e54ad5c7320e8f80e2a2163e93', '8a1a67964c0cbea29fc9801b5c42c553', '96e7b1bc8d52e18caf0af34fec2e9bcb', '5fc2ffdd3d24ab503edd9a271dc379bd', 'dd4989789d310581024ae2b9203d5439', '50591a7061fb340d875723f38e00cc3b', 'b874a616affcb766bb0e7a4f2a0803f0', '54e7b38b5c91716bd3ad99a0ab740a18', '234c8d1df0b49b512791078cf00cf352', '3cc9a44380296d93e68b71a27643c25f', 'c16781c4321948227193214b68477a5c', 'dc589f213ba7bd398714ac2796b7c0ab', 'b64b426fa2b080ad94a2e1c7f423413c', '10bc951c2eb4a2f05fa773bdaace4e3b', 'bc58ed3c3e7750f9644953020a39e867', 'b844978933b7ae43e32ce775494821eb', '4b0465826ffd6db797ea6f3a5898df79', 'c9380d13360b37f21cfd174d92a7247e', '481c5c92d55717167e01821144a54635', '6f80666437feea42f295cdc0f1eb4df9', 'de42ef05d5901837bbe974fdb3c30ba5', 'b36edf57ed623e40e433565053f5f6ca', 'aceaa52f487dd19129857232b2eeb3d5', '45f4183820ce1fa775f8a27d3120aad6', '0eeac4ecff259dc515be795e1a76019a', '68cbc428edbcf480cbbb9a0e66e7046d', 'c56bcab4b317984013ebef5d3c4b5906', 'f7e1cb7b67e7b154d9dca7d12879d7b0', 'e1587900e782de448f604b37cde0fdfd', '121fffad1eb6f7dff228b8a71b6aec72', '31dbc08b8d0a3196c5484c0c068b2bcc', '3f8dc381ccfe9d5cc88b75970262715b', '512fb34e01bd21a92e7ec1380577c985', '1e8267251976e6f3b771b00f32c5798b', 'ce3d8977aae5986601232aa58d15282a', '1468ab18764365ded902fc726aec2c89', '49bb8d79587c2172c6cd04dd705fd891', '40f86d376acde0d9862ce7493745bdae', '1950e9aa6ad878bc2a330880f77ae5a1', '129349585c3d1f312535b6619fc36bf7', 'bc0ddf03c667c5edb17982be481ef360', '7b016984b86b58f83977299591cf4e38', '3937af6d364e2f24d1cce16fe3916536', '62b4406512c45730d2c7c40f5e3d0d12', '3edc6a404b8c67b7dad1405d52228c96', '80687062449ff7454e2c8926be56f643', 'cc47068929413a16aa707faefbdf4b70', '9649a0013a798a8367d2c493e37468ec', '147b0f64f4c2848bc0ad7bc1cdf74afe', '5e560e9b2ae0c20cfc57b308742bc677', '5aabfc58470d01bb2362795a44a2603b', 'c31b03be3da5810b44ea4782d2f3b8a0', '861c29e13205420326f7443ea77de5c9', 'bd14ef3c1a25cf0c5368ccd92a3c5f04', 'ccb8b07e7e3d837b2cd08d3edaf009cd', '5ae394770a82dac7cea5d95ef6482a11']\n"]}],"source":["\n","# train_df = df[df[\"in_train\"] == True]\n","# test_df = df[df['in_train'] == False]\n","train_df = df[['artist', 'filename']]\n","# test_df = test_df[['artist', 'new_filename']]\n","\n","# print(\"test_df.shape\", test_df.shape)\n","print(\"train_df.shape\", train_df.shape)\n","\n","artists = {} # holds artist hash & the count\n","for a in train_df['artist']:\n","    if (a not in artists):\n","        artists[a] = 1\n","    else:\n","        artists[a] += 1\n","\n","training_set_artists = []\n","for a,count in artists.items():\n","    if(int(count) >= 200):\n","        training_set_artists.append(a)\n","\n","print(\"number of artists\",len(training_set_artists))\n","\n","print(\"\\nlist of artists...\\n\", training_set_artists)\n"]},{"cell_type":"code","execution_count":13,"metadata":{"_kg_hide-input":true,"_uuid":"374cf6e0025c7221bbd1973c88f3702158e38c3f","trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>artist</th>\n","      <th>filename</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>9</th>\n","      <td>d09f796f2b0aa11dffc88badd9806119</td>\n","      <td>99442.jpg</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>83e9823eb4868ca162fd3b7adff70096</td>\n","      <td>7486.jpg</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>83e9823eb4868ca162fd3b7adff70096</td>\n","      <td>35766.jpg</td>\n","    </tr>\n","    <tr>\n","      <th>33</th>\n","      <td>8e441c5899bf3d2f3b2c493e62fb92bf</td>\n","      <td>99733.jpg</td>\n","    </tr>\n","    <tr>\n","      <th>34</th>\n","      <td>8e441c5899bf3d2f3b2c493e62fb92bf</td>\n","      <td>73690.jpg</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                              artist   filename\n","9   d09f796f2b0aa11dffc88badd9806119  99442.jpg\n","18  83e9823eb4868ca162fd3b7adff70096   7486.jpg\n","19  83e9823eb4868ca162fd3b7adff70096  35766.jpg\n","33  8e441c5899bf3d2f3b2c493e62fb92bf  99733.jpg\n","34  8e441c5899bf3d2f3b2c493e62fb92bf  73690.jpg"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["t_df = train_df[train_df[\"artist\"].isin(training_set_artists)]\n","\n","t_df.head(5)"]},{"cell_type":"code","execution_count":14,"metadata":{"_kg_hide-input":true,"_uuid":"b44f0b775da104dd716f4601cc164e7c4284bcec","trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>artist</th>\n","      <th>filename</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>9</th>\n","      <td>d09f796f2b0aa11dffc88badd9806119</td>\n","      <td>99442.jpg</td>\n","    </tr>\n","    <tr>\n","      <th>33</th>\n","      <td>8e441c5899bf3d2f3b2c493e62fb92bf</td>\n","      <td>99733.jpg</td>\n","    </tr>\n","    <tr>\n","      <th>35</th>\n","      <td>8e441c5899bf3d2f3b2c493e62fb92bf</td>\n","      <td>93715.jpg</td>\n","    </tr>\n","    <tr>\n","      <th>108</th>\n","      <td>a6027a4ba71b61a55ea598379c9d508c</td>\n","      <td>95360.jpg</td>\n","    </tr>\n","    <tr>\n","      <th>122</th>\n","      <td>8cdd41002b7b5c5d112865054a7fe13e</td>\n","      <td>96372.jpg</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                               artist   filename\n","9    d09f796f2b0aa11dffc88badd9806119  99442.jpg\n","33   8e441c5899bf3d2f3b2c493e62fb92bf  99733.jpg\n","35   8e441c5899bf3d2f3b2c493e62fb92bf  93715.jpg\n","108  a6027a4ba71b61a55ea598379c9d508c  95360.jpg\n","122  8cdd41002b7b5c5d112865054a7fe13e  96372.jpg"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["t1_df = t_df[t_df['filename'].str.startswith('1')]\n","\n","t2_df = t_df[t_df['filename'].str.startswith('2')]\n","\n","t3_df = t_df[t_df['filename'].str.startswith('3')]\n","\n","t4_df = t_df[t_df['filename'].str.startswith('4')]\n","\n","t5_df = t_df[t_df['filename'].str.startswith('5')]\n","\n","t6_df = t_df[t_df['filename'].str.startswith('6')]\n","\n","t7_df = t_df[t_df['filename'].str.startswith('7')]\n","\n","t8_df = t_df[t_df['filename'].str.startswith('8')]\n","\n","t9_df = t_df[t_df['filename'].str.startswith('9')]\n","\n","all_train_dfs = [t1_df, t2_df, t3_df,\n","                t4_df, t5_df, t6_df,\n","                t7_df, t8_df, t9_df]\n","\n","t9_df.head(5)"]},{"cell_type":"code","execution_count":24,"metadata":{"_kg_hide-input":false,"_kg_hide-output":false,"_uuid":"9f35f9102dabe4fd4c05d9b4da88929811c574cd","trusted":true},"outputs":[],"source":["from tensorflow.keras.applications import ResNet50\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Flatten, GlobalAveragePooling2D\n","\n","from tensorflow.keras.applications.resnet50 import preprocess_input\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n"]},{"cell_type":"markdown","metadata":{"_uuid":"30506b48fd6f5fd2636520b60baed80e20b8b944"},"source":["# specify the model that classifies 38 artists üé® üñå"]},{"cell_type":"code","execution_count":16,"metadata":{"_uuid":"e74625505706e025d7981c6712d21861f3ff6407","trusted":true},"outputs":[{"data":{"text/plain":["71"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["len(training_set_artists)"]},{"cell_type":"code","execution_count":36,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: absl-py==2.1.0 in c:\\users\\merc√®\\anaconda3\\lib\\site-packages (from -r C:\\Users\\Merc√®\\Documents\\UAB\\XN\\Projecte\\XNAPproject-grup07\\our_code\\frozen-requirements.txt (line 1)) (2.1.0)\n","Requirement already satisfied: appdirs==1.4.4 in c:\\users\\merc√®\\anaconda3\\lib\\site-packages (from -r C:\\Users\\Merc√®\\Documents\\UAB\\XN\\Projecte\\XNAPproject-grup07\\our_code\\frozen-requirements.txt (line 15)) (1.4.4)\n","Requirement already satisfied: astunparse==1.6.3 in c:\\users\\merc√®\\anaconda3\\lib\\site-packages (from -r C:\\Users\\Merc√®\\Documents\\UAB\\XN\\Projecte\\XNAPproject-grup07\\our_code\\frozen-requirements.txt (line 23)) (1.6.3)\n","Requirement already satisfied: atomicwrites==1.4.0 in c:\\users\\merc√®\\anaconda3\\lib\\site-packages (from -r C:\\Users\\Merc√®\\Documents\\UAB\\XN\\Projecte\\XNAPproject-grup07\\our_code\\frozen-requirements.txt (line 25)) (1.4.0)\n","Requirement already satisfied: backports.weakref==1.0.post1 in c:\\users\\merc√®\\anaconda3\\lib\\site-packages (from -r C:\\Users\\Merc√®\\Documents\\UAB\\XN\\Projecte\\XNAPproject-grup07\\our_code\\frozen-requirements.txt (line 32)) (1.0.post1)\n","Requirement already satisfied: clyent==1.2.2 in c:\\users\\merc√®\\anaconda3\\lib\\site-packages (from -r C:\\Users\\Merc√®\\Documents\\UAB\\XN\\Projecte\\XNAPproject-grup07\\our_code\\frozen-requirements.txt (line 51)) (1.2.2)\n","Requirement already satisfied: conda-repo-cli==1.0.75 in c:\\users\\merc√®\\anaconda3\\lib\\site-packages (from -r C:\\Users\\Merc√®\\Documents\\UAB\\XN\\Projecte\\XNAPproject-grup07\\our_code\\frozen-requirements.txt (line 61)) (1.0.75)\n","Requirement already satisfied: conda-verify==3.4.2 in c:\\users\\merc√®\\anaconda3\\lib\\site-packages (from -r C:\\Users\\Merc√®\\Documents\\UAB\\XN\\Projecte\\XNAPproject-grup07\\our_code\\frozen-requirements.txt (line 63)) (3.4.2)\n","Requirement already satisfied: et-xmlfile==1.1.0 in c:\\users\\merc√®\\anaconda3\\lib\\site-packages (from -r C:\\Users\\Merc√®\\Documents\\UAB\\XN\\Projecte\\XNAPproject-grup07\\our_code\\frozen-requirements.txt (line 85)) (1.1.0)\n","Requirement already satisfied: flatbuffers==24.3.25 in c:\\users\\merc√®\\anaconda3\\lib\\site-packages (from -r C:\\Users\\Merc√®\\Documents\\UAB\\XN\\Projecte\\XNAPproject-grup07\\our_code\\frozen-requirements.txt (line 91)) (24.3.25)\n","Requirement already satisfied: fonttools==4.25.0 in c:\\users\\merc√®\\anaconda3\\lib\\site-packages (from -r C:\\Users\\Merc√®\\Documents\\UAB\\XN\\Projecte\\XNAPproject-grup07\\our_code\\frozen-requirements.txt (line 92)) (4.25.0)\n","Requirement already satisfied: gast==0.5.4 in c:\\users\\merc√®\\anaconda3\\lib\\site-packages (from -r C:\\Users\\Merc√®\\Documents\\UAB\\XN\\Projecte\\XNAPproject-grup07\\our_code\\frozen-requirements.txt (line 96)) (0.5.4)\n","Requirement already satisfied: google-pasta==0.2.0 in c:\\users\\merc√®\\anaconda3\\lib\\site-packages (from -r C:\\Users\\Merc√®\\Documents\\UAB\\XN\\Projecte\\XNAPproject-grup07\\our_code\\frozen-requirements.txt (line 101)) (0.2.0)\n","Requirement already satisfied: grpcio==1.63.0 in c:\\users\\merc√®\\anaconda3\\lib\\site-packages (from -r C:\\Users\\Merc√®\\Documents\\UAB\\XN\\Projecte\\XNAPproject-grup07\\our_code\\frozen-requirements.txt (line 103)) (1.63.0)\n","Requirement already satisfied: h5py==3.11.0 in c:\\users\\merc√®\\anaconda3\\lib\\site-packages (from -r C:\\Users\\Merc√®\\Documents\\UAB\\XN\\Projecte\\XNAPproject-grup07\\our_code\\frozen-requirements.txt (line 104)) (3.11.0)\n","Requirement already satisfied: inflection==0.5.1 in c:\\users\\merc√®\\anaconda3\\lib\\site-packages (from -r C:\\Users\\Merc√®\\Documents\\UAB\\XN\\Projecte\\XNAPproject-grup07\\our_code\\frozen-requirements.txt (line 116)) (0.5.1)\n","Requirement already satisfied: jsonpointer==2.1 in c:\\users\\merc√®\\anaconda3\\lib\\site-packages (from -r C:\\Users\\Merc√®\\Documents\\UAB\\XN\\Projecte\\XNAPproject-grup07\\our_code\\frozen-requirements.txt (line 136)) (2.1)\n","Requirement already satisfied: keras==3.3.3 in c:\\users\\merc√®\\anaconda3\\lib\\site-packages (from -r C:\\Users\\Merc√®\\Documents\\UAB\\XN\\Projecte\\XNAPproject-grup07\\our_code\\frozen-requirements.txt (line 151)) (3.3.3)\n","Requirement already satisfied: libclang==18.1.1 in c:\\users\\merc√®\\anaconda3\\lib\\site-packages (from -r C:\\Users\\Merc√®\\Documents\\UAB\\XN\\Projecte\\XNAPproject-grup07\\our_code\\frozen-requirements.txt (line 158)) (18.1.1)\n","Requirement already satisfied: mkl-service==2.4.0 in c:\\users\\merc√®\\anaconda3\\lib\\site-packages (from -r C:\\Users\\Merc√®\\Documents\\UAB\\XN\\Projecte\\XNAPproject-grup07\\our_code\\frozen-requirements.txt (line 178)) (2.4.0)\n","Requirement already satisfied: ml-dtypes==0.3.2 in c:\\users\\merc√®\\anaconda3\\lib\\site-packages (from -r C:\\Users\\Merc√®\\Documents\\UAB\\XN\\Projecte\\XNAPproject-grup07\\our_code\\frozen-requirements.txt (line 179)) (0.3.2)\n","Requirement already satisfied: munkres==1.1.4 in c:\\users\\merc√®\\anaconda3\\lib\\site-packages (from -r C:\\Users\\Merc√®\\Documents\\UAB\\XN\\Projecte\\XNAPproject-grup07\\our_code\\frozen-requirements.txt (line 185)) (1.1.4)\n","Requirement already satisfied: namex==0.0.8 in c:\\users\\merc√®\\anaconda3\\lib\\site-packages (from -r C:\\Users\\Merc√®\\Documents\\UAB\\XN\\Projecte\\XNAPproject-grup07\\our_code\\frozen-requirements.txt (line 188)) (0.0.8)\n","Requirement already satisfied: openpyxl==3.0.10 in c:\\users\\merc√®\\anaconda3\\lib\\site-packages (from -r C:\\Users\\Merc√®\\Documents\\UAB\\XN\\Projecte\\XNAPproject-grup07\\our_code\\frozen-requirements.txt (line 202)) (3.0.10)\n","Requirement already satisfied: opt-einsum==3.3.0 in c:\\users\\merc√®\\anaconda3\\lib\\site-packages (from -r C:\\Users\\Merc√®\\Documents\\UAB\\XN\\Projecte\\XNAPproject-grup07\\our_code\\frozen-requirements.txt (line 203)) (3.3.0)\n","Requirement already satisfied: optree==0.11.0 in c:\\users\\merc√®\\anaconda3\\lib\\site-packages (from -r C:\\Users\\Merc√®\\Documents\\UAB\\XN\\Projecte\\XNAPproject-grup07\\our_code\\frozen-requirements.txt (line 204)) (0.11.0)\n","Requirement already satisfied: patsy==0.5.3 in c:\\users\\merc√®\\anaconda3\\lib\\site-packages (from -r C:\\Users\\Merc√®\\Documents\\UAB\\XN\\Projecte\\XNAPproject-grup07\\our_code\\frozen-requirements.txt (line 217)) (0.5.3)\n","Requirement already satisfied: ply==3.11 in c:\\users\\merc√®\\anaconda3\\lib\\site-packages (from -r C:\\Users\\Merc√®\\Documents\\UAB\\XN\\Projecte\\XNAPproject-grup07\\our_code\\frozen-requirements.txt (line 226)) (3.11)\n","Requirement already satisfied: protobuf==3.20.3 in c:\\users\\merc√®\\anaconda3\\lib\\site-packages (from -r C:\\Users\\Merc√®\\Documents\\UAB\\XN\\Projecte\\XNAPproject-grup07\\our_code\\frozen-requirements.txt (line 230)) (3.20.3)\n","Requirement already satisfied: pyasn1-modules==0.2.8 in c:\\users\\merc√®\\anaconda3\\lib\\site-packages (from -r C:\\Users\\Merc√®\\Documents\\UAB\\XN\\Projecte\\XNAPproject-grup07\\our_code\\frozen-requirements.txt (line 237)) (0.2.8)\n","Requirement already satisfied: pycurl==7.45.2 in c:\\users\\merc√®\\anaconda3\\lib\\site-packages (from -r C:\\Users\\Merc√®\\Documents\\UAB\\XN\\Projecte\\XNAPproject-grup07\\our_code\\frozen-requirements.txt (line 242)) (7.45.2)\n","Requirement already satisfied: PyDispatcher==2.0.5 in c:\\users\\merc√®\\anaconda3\\lib\\site-packages (from -r C:\\Users\\Merc√®\\Documents\\UAB\\XN\\Projecte\\XNAPproject-grup07\\our_code\\frozen-requirements.txt (line 245)) (2.0.5)\n","Requirement already satisfied: pyls-spyder==0.4.0 in c:\\users\\merc√®\\anaconda3\\lib\\site-packages (from -r C:\\Users\\Merc√®\\Documents\\UAB\\XN\\Projecte\\XNAPproject-grup07\\our_code\\frozen-requirements.txt (line 253)) (0.4.0)\n","Requirement already satisfied: PyQt5==5.15.10 in c:\\users\\merc√®\\anaconda3\\lib\\site-packages (from -r C:\\Users\\Merc√®\\Documents\\UAB\\XN\\Projecte\\XNAPproject-grup07\\our_code\\frozen-requirements.txt (line 258)) (5.15.10)\n","Requirement already satisfied: PyQtWebEngine==5.15.6 in c:\\users\\merc√®\\anaconda3\\lib\\site-packages (from -r C:\\Users\\Merc√®\\Documents\\UAB\\XN\\Projecte\\XNAPproject-grup07\\our_code\\frozen-requirements.txt (line 260)) (5.15.6)\n","Requirement already satisfied: python-lsp-jsonrpc==1.0.0 in c:\\users\\merc√®\\anaconda3\\lib\\site-packages (from -r C:\\Users\\Merc√®\\Documents\\UAB\\XN\\Projecte\\XNAPproject-grup07\\our_code\\frozen-requirements.txt (line 267)) (1.0.0)\n","Requirement already satisfied: pywin32==305.1 in c:\\users\\merc√®\\anaconda3\\lib\\site-packages (from -r C:\\Users\\Merc√®\\Documents\\UAB\\XN\\Projecte\\XNAPproject-grup07\\our_code\\frozen-requirements.txt (line 275)) (305.1)\n","Requirement already satisfied: scipy==1.11.4 in c:\\users\\merc√®\\anaconda3\\lib\\site-packages (from -r C:\\Users\\Merc√®\\Documents\\UAB\\XN\\Projecte\\XNAPproject-grup07\\our_code\\frozen-requirements.txt (line 302)) (1.11.4)\n","Requirement already satisfied: tensorboard==2.16.2 in c:\\users\\merc√®\\anaconda3\\lib\\site-packages (from -r C:\\Users\\Merc√®\\Documents\\UAB\\XN\\Projecte\\XNAPproject-grup07\\our_code\\frozen-requirements.txt (line 334)) (2.16.2)\n","Requirement already satisfied: tensorboard-data-server==0.7.2 in c:\\users\\merc√®\\anaconda3\\lib\\site-packages (from -r C:\\Users\\Merc√®\\Documents\\UAB\\XN\\Projecte\\XNAPproject-grup07\\our_code\\frozen-requirements.txt (line 335)) (0.7.2)\n","Requirement already satisfied: tensorflow==2.16.1 in c:\\users\\merc√®\\anaconda3\\lib\\site-packages (from -r C:\\Users\\Merc√®\\Documents\\UAB\\XN\\Projecte\\XNAPproject-grup07\\our_code\\frozen-requirements.txt (line 336)) (2.16.1)\n","Requirement already satisfied: tensorflow-intel==2.16.1 in c:\\users\\merc√®\\anaconda3\\lib\\site-packages (from -r C:\\Users\\Merc√®\\Documents\\UAB\\XN\\Projecte\\XNAPproject-grup07\\our_code\\frozen-requirements.txt (line 337)) (2.16.1)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem==0.31.0 in c:\\users\\merc√®\\anaconda3\\lib\\site-packages (from -r C:\\Users\\Merc√®\\Documents\\UAB\\XN\\Projecte\\XNAPproject-grup07\\our_code\\frozen-requirements.txt (line 338)) (0.31.0)\n","Requirement already satisfied: termcolor==2.4.0 in c:\\users\\merc√®\\anaconda3\\lib\\site-packages (from -r C:\\Users\\Merc√®\\Documents\\UAB\\XN\\Projecte\\XNAPproject-grup07\\our_code\\frozen-requirements.txt (line 339)) (2.4.0)\n","Requirement already satisfied: typing_extensions==4.11.0 in c:\\users\\merc√®\\anaconda3\\lib\\site-packages (from -r C:\\Users\\Merc√®\\Documents\\UAB\\XN\\Projecte\\XNAPproject-grup07\\our_code\\frozen-requirements.txt (line 357)) (4.11.0)\n","Requirement already satisfied: webencodings==0.5.1 in c:\\users\\merc√®\\anaconda3\\lib\\site-packages (from -r C:\\Users\\Merc√®\\Documents\\UAB\\XN\\Projecte\\XNAPproject-grup07\\our_code\\frozen-requirements.txt (line 368)) (0.5.1)\n","Requirement already satisfied: zstandard==0.19.0 in c:\\users\\merc√®\\anaconda3\\lib\\site-packages (from -r C:\\Users\\Merc√®\\Documents\\UAB\\XN\\Projecte\\XNAPproject-grup07\\our_code\\frozen-requirements.txt (line 383)) (0.19.0)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\merc√®\\anaconda3\\lib\\site-packages (from astunparse==1.6.3->-r C:\\Users\\Merc√®\\Documents\\UAB\\XN\\Projecte\\XNAPproject-grup07\\our_code\\frozen-requirements.txt (line 23)) (0.41.2)\n","Requirement already satisfied: six<2.0,>=1.6.1 in c:\\users\\merc√®\\anaconda3\\lib\\site-packages (from astunparse==1.6.3->-r C:\\Users\\Merc√®\\Documents\\UAB\\XN\\Projecte\\XNAPproject-grup07\\our_code\\frozen-requirements.txt (line 23)) (1.16.0)\n","INFO: pip is looking at multiple versions of conda-repo-cli to determine which version is compatible with other requirements. This could take a while.\n","\n","The conflict is caused by:\n","    The user requested clyent==1.2.2\n","    conda-repo-cli 1.0.75 depends on clyent==1.2.1\n","\n","To fix this you could try to:\n","1. loosen the range of package versions you've specified\n","2. remove package versions to allow pip attempt to solve the dependency conflict\n","\n","Note: you may need to restart the kernel to use updated packages.\n"]},{"name":"stderr","output_type":"stream","text":["ERROR: Cannot install clyent==1.2.2 and conda-repo-cli==1.0.75 because these package versions have conflicting dependencies.\n","ERROR: ResolutionImpossible: for help visit https://pip.pypa.io/en/latest/topics/dependency-resolution/#dealing-with-dependency-conflicts\n"]}],"source":["%pip install -r \"C:\\Users\\Merc√®\\Documents\\UAB\\XN\\Projecte\\XNAPproject-grup07\\our_code\\frozen-requirements.txt\""]},{"cell_type":"code","execution_count":25,"metadata":{"_uuid":"d3222704a8161b0530f4df9911acbbc54ce97039","trusted":true},"outputs":[],"source":["num_classes = len(training_set_artists) # one class per artist\n","weights_notop_path = r\"C:\\Users\\Merc√®\\Documents\\UAB\\XN\\Projecte\\resnet50\\resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\"\n","model_adam = Sequential()\n","\n","model_adam.add(ResNet50(\n","  include_top=False,\n","  weights='imagenet',\n","  pooling='avg'\n","))\n","model_adam.add(Dense(\n","  num_classes,\n","  activation='softmax'\n","))\n","\n","model_adam.layers[0].trainable = False"]},{"cell_type":"code","execution_count":28,"metadata":{},"outputs":[{"ename":"TypeError","evalue":"The added layer must be an instance of class Layer. Found: <Functional name=resnet50, built=True>","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[1;32mIn[28], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m model_sgd \u001b[38;5;241m=\u001b[39m Sequential()\n\u001b[1;32m----> 2\u001b[0m model_sgd\u001b[38;5;241m.\u001b[39madd(ResNet50(\n\u001b[0;32m      3\u001b[0m   include_top\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m      4\u001b[0m   weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimagenet\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      5\u001b[0m   pooling\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mavg\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      6\u001b[0m ))\n\u001b[0;32m      7\u001b[0m model_sgd\u001b[38;5;241m.\u001b[39madd(Dense(\n\u001b[0;32m      8\u001b[0m   num_classes,\n\u001b[0;32m      9\u001b[0m   activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msoftmax\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     10\u001b[0m ))\n\u001b[0;32m     12\u001b[0m model_sgd\u001b[38;5;241m.\u001b[39mlayers[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mtrainable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n","File \u001b[1;32mc:\\Users\\Merc√®\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\trackable\\base.py:204\u001b[0m, in \u001b[0;36mno_automatic_dependency_tracking.<locals>._method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    202\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_self_setattr_tracking \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    203\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 204\u001b[0m   result \u001b[38;5;241m=\u001b[39m method(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    206\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_self_setattr_tracking \u001b[38;5;241m=\u001b[39m previous_value  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n","File \u001b[1;32mc:\\Users\\Merc√®\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:183\u001b[0m, in \u001b[0;36mSequential.add\u001b[1;34m(self, layer)\u001b[0m\n\u001b[0;32m    181\u001b[0m     layer \u001b[38;5;241m=\u001b[39m functional\u001b[38;5;241m.\u001b[39mModuleWrapper(layer)\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 183\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe added layer must be \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    184\u001b[0m                   \u001b[38;5;124m'\u001b[39m\u001b[38;5;124man instance of class Layer. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    185\u001b[0m                   \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFound: \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(layer))\n\u001b[0;32m    187\u001b[0m tf_utils\u001b[38;5;241m.\u001b[39massert_no_legacy_layers([layer])\n\u001b[0;32m    188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_layer_name_unique(layer):\n","\u001b[1;31mTypeError\u001b[0m: The added layer must be an instance of class Layer. Found: <Functional name=resnet50, built=True>"]}],"source":["model_sgd = Sequential()\n","model_sgd.add(ResNet50(\n","  include_top=False,\n","  weights='imagenet',\n","  pooling='avg'\n","))\n","model_sgd.add(Dense(\n","  num_classes,\n","  activation='softmax'\n","))\n","\n","model_sgd.layers[0].trainable = False"]},{"cell_type":"markdown","metadata":{"_uuid":"b14546c60c000f6f763d7ef225c2d5bb9bad75ee"},"source":["# Compile Model"]},{"cell_type":"markdown","metadata":{},"source":["## Adam"]},{"cell_type":"code","execution_count":26,"metadata":{"_uuid":"431d98d4322666bf0995dd65e7370e8e8d3ff36e","trusted":true},"outputs":[],"source":["model_adam.compile(\n","  optimizer='adam', # lots of people reccommend Adam optimizer\n","  loss='categorical_crossentropy', # aka \"log loss\" -- the cost function to minimize \n","  # so 'optimizer' algorithm will minimize 'loss' function\n","  metrics=['accuracy'] # ask it to report % of correct predictions\n",")"]},{"cell_type":"markdown","metadata":{},"source":["**Observation**\n","para un problema de clasificaci√≥n binaria, a menudo se utiliza la 'entrop√≠a cruzada binaria', mientras que la 'entrop√≠a cruzada categ√≥rica' se utiliza para la clasificaci√≥n de clases m√∫ltiples.\n","https://www.sourcetrail.com/es/pit%C3%B3n/keras/modelo-compilar-keras/"]},{"cell_type":"markdown","metadata":{},"source":["## SGD"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model_sgd.compile(\n","  optimizer='sgd', # lots of people reccommend Adam optimizer\n","  loss='categorical_crossentropy', # aka \"log loss\" -- the cost function to minimize \n","  # so 'optimizer' algorithm will minimize 'loss' function\n","  metrics=['accuracy'] # ask it to report % of correct predictions\n",")"]},{"cell_type":"markdown","metadata":{"_uuid":"7e00f7674040ad997d2e3c67d8e61b7f214e3709"},"source":["# Setup the image data generator for each training directory "]},{"cell_type":"code","execution_count":27,"metadata":{"_uuid":"c8005d5e86576cebc2b0fa0034ca2baed91c6de1","trusted":true},"outputs":[],"source":["# model globals\n","IMAGE_SIZE = 224\n","BATCH_SIZE = 96\n","TEST_BATCH_SIZE = 17 # because test has 23817 images and factors of 23817 are 3*17*467\n","                     # it is important that this number evenly divides the total num images \n","VAL_SPLIT = 0.25"]},{"cell_type":"code","execution_count":30,"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"_uuid":"6d229aed54ae275e7cff6382f3500a4ad21e4701","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["defined setup_generators()\n"]}],"source":["def setup_generators(\n","    val_split, train_dataframe, train_dir,\n","    img_size, batch_size, my_seed, list_of_classes,\n","    test_dataframe, test_dir, test_batch_size\n","):\n","    print(\"-\"*20)\n","    if not preprocess_input:\n","          raise Exception(\"please do import call 'from tensorflow.python.keras.applications.resnet50 import preprocess_input'\")\n","\n","    # setup resnet50 preprocessing \n","    data_gen = ImageDataGenerator(\n","        preprocessing_function=preprocess_input,\n","        validation_split=val_split)\n","\n","    print(len(train_dataframe), \"images in\", train_dir, \"and validation_split =\", val_split)\n","    print(\"\\ntraining set ImageDataGenerator\")\n","    train_gen = data_gen.flow_from_dataframe(\n","        dataframe=train_dataframe.reset_index(), # call reset_index() so keras can start with index 0\n","        directory=train_dir,\n","        x_col='filename',\n","        y_col='artist',\n","        has_ext=True,\n","        target_size=(img_size, img_size),\n","        subset=\"training\",\n","        batch_size=batch_size,\n","        seed=my_seed,\n","        shuffle=True,\n","        class_mode='categorical',\n","        classes=list_of_classes\n","    )\n","\n","    print(\"\\nvalidation set ImageDataGenerator\")\n","    valid_gen = data_gen.flow_from_dataframe(\n","        dataframe=train_dataframe.reset_index(), # call reset_index() so keras can start with index 0\n","        directory=train_dir,\n","        x_col='filename',\n","        y_col='artist',\n","        has_ext=True,\n","        subset=\"validation\",\n","        batch_size=batch_size,\n","        seed=my_seed,\n","        shuffle=True,\n","        target_size=(img_size,img_size),\n","        class_mode='categorical',\n","        classes=list_of_classes\n","    )\n","\n","    test_data_gen = ImageDataGenerator(preprocessing_function=preprocess_input)\n","\n","    print(\"\\ntest set ImageDataGenerator\")\n","    test_gen = test_data_gen.flow_from_dataframe(\n","        dataframe=test_dataframe.reset_index(), # call reset_index() so keras can start with index 0\n","        directory=test_dir,\n","        x_col='filename',\n","        y_col=None,\n","        has_ext=True,\n","        batch_size=test_batch_size,\n","        seed=my_seed,\n","        shuffle=False, # dont shuffle test directory\n","        class_mode=None,\n","        target_size=(img_size,img_size)\n","    )\n","\n","    return (train_gen, valid_gen, test_gen)\n","\n","print(\"defined setup_generators()\")"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true,"_uuid":"b899ca31427b36e183abfbc897caa05ca6102e05","trusted":true},"outputs":[],"source":["# delete some unused dataframes to free some RAM for training\n","del df\n","del t_df\n","del t1_df\n","del t2_df\n","del t3_df\n","del t4_df\n","del t5_df\n","del t6_df\n","del t7_df\n","del t8_df\n","del t9_df\n","gc.collect()"]},{"cell_type":"code","execution_count":31,"metadata":{"_kg_hide-output":true,"_uuid":"906343b306f3d44981bc0693ed5185d8e2fdb446","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["--------------------\n","3092 images in C:\\Users\\Merc√®\\Documents\\UAB\\XN\\Projecte\\input\\train_1\\train_1 and validation_split = 0.25\n","\n","training set ImageDataGenerator\n","Found 2319 validated image filenames belonging to 71 classes.\n","\n","validation set ImageDataGenerator\n","Found 773 validated image filenames belonging to 71 classes.\n","\n","test set ImageDataGenerator\n","Found 0 validated image filenames.\n"]},{"name":"stderr","output_type":"stream","text":["c:\\Users\\Merc√®\\anaconda3\\Lib\\site-packages\\keras\\src\\legacy\\preprocessing\\image.py:920: UserWarning: Found 79426 invalid image filename(s) in x_col=\"filename\". These filename(s) will be ignored.\n","  warnings.warn(\n"]}],"source":["train_gens = [None]*len(TRAIN_DIRS)\n","valid_gens = [None]*len(TRAIN_DIRS)\n","test_gen  = None # only 1 test_gen\n","i = 0\n","for i in range(0, len(TRAIN_DIRS)):\n","    train_gens[i], valid_gens[i], test_gen = setup_generators(\n","        train_dataframe=all_train_dfs[i], train_dir=TRAIN_DIRS[i],\n","        val_split=VAL_SPLIT, img_size=IMAGE_SIZE, batch_size=BATCH_SIZE, my_seed=MY_SEED, \n","        list_of_classes=training_set_artists, test_dataframe=test_df, \n","        test_dir=TEST_DIR, test_batch_size=TEST_BATCH_SIZE\n","    )\n","    i += 1"]},{"cell_type":"markdown","metadata":{"_uuid":"d7978eabacec7bf8c313d1fda177d876a2a38cc1"},"source":["# TRAINING TIME!  üéâ üéä üéÅ"]},{"cell_type":"code","execution_count":32,"metadata":{"_uuid":"31f15a418cd7e0550700645090e006d3438c4f59","trusted":true},"outputs":[],"source":["MAX_EPOCHS = 5 * len(train_gens) # should be a multiple of 9 because need evenly train each train_dir\n","DIR_EPOCHS = 1 # fit each train_dir at least this many times before overfitting"]},{"cell_type":"code","execution_count":36,"metadata":{"_kg_hide-output":true,"_uuid":"71704f10dbbf6803e03934be1f3ac8de05d878f4","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["STEP_SIZE_TRAIN 24\n","STEP_SIZE_VALID 8\n"]},{"name":"stderr","output_type":"stream","text":["c:\\Users\\Merc√®\\anaconda3\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n","  self._warn_if_super_not_called()\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.0655 - loss: 4.4635"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[1;32mIn[36], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSTEP_SIZE_TRAIN\u001b[39m\u001b[38;5;124m\"\u001b[39m,STEP_SIZE_TRAIN)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSTEP_SIZE_VALID\u001b[39m\u001b[38;5;124m\"\u001b[39m,STEP_SIZE_VALID)\n\u001b[0;32m     12\u001b[0m histories_adam\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m---> 13\u001b[0m     model_adam\u001b[38;5;241m.\u001b[39mfit(train_gens[i],\n\u001b[0;32m     14\u001b[0m                         steps_per_epoch\u001b[38;5;241m=\u001b[39mSTEP_SIZE_TRAIN,\n\u001b[0;32m     15\u001b[0m                         validation_data\u001b[38;5;241m=\u001b[39mvalid_gens[i],\n\u001b[0;32m     16\u001b[0m                         validation_steps\u001b[38;5;241m=\u001b[39mSTEP_SIZE_VALID,\n\u001b[0;32m     17\u001b[0m                         epochs\u001b[38;5;241m=\u001b[39mDIR_EPOCHS)\n\u001b[0;32m     18\u001b[0m )\n\u001b[0;32m     19\u001b[0m e\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n","File \u001b[1;32mc:\\Users\\Merc√®\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n","File \u001b[1;32mc:\\Users\\Merc√®\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:339\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[0;32m    328\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_eval_epoch_iterator\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    329\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_eval_epoch_iterator \u001b[38;5;241m=\u001b[39m TFEpochIterator(\n\u001b[0;32m    330\u001b[0m         x\u001b[38;5;241m=\u001b[39mval_x,\n\u001b[0;32m    331\u001b[0m         y\u001b[38;5;241m=\u001b[39mval_y,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    337\u001b[0m         shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    338\u001b[0m     )\n\u001b[1;32m--> 339\u001b[0m val_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluate(\n\u001b[0;32m    340\u001b[0m     x\u001b[38;5;241m=\u001b[39mval_x,\n\u001b[0;32m    341\u001b[0m     y\u001b[38;5;241m=\u001b[39mval_y,\n\u001b[0;32m    342\u001b[0m     sample_weight\u001b[38;5;241m=\u001b[39mval_sample_weight,\n\u001b[0;32m    343\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mvalidation_batch_size \u001b[38;5;129;01mor\u001b[39;00m batch_size,\n\u001b[0;32m    344\u001b[0m     steps\u001b[38;5;241m=\u001b[39mvalidation_steps,\n\u001b[0;32m    345\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39mcallbacks,\n\u001b[0;32m    346\u001b[0m     return_dict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    347\u001b[0m     _use_cached_eval_dataset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    348\u001b[0m )\n\u001b[0;32m    349\u001b[0m val_logs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    350\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m name: val \u001b[38;5;28;01mfor\u001b[39;00m name, val \u001b[38;5;129;01min\u001b[39;00m val_logs\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m    351\u001b[0m }\n\u001b[0;32m    352\u001b[0m epoch_logs\u001b[38;5;241m.\u001b[39mupdate(val_logs)\n","File \u001b[1;32mc:\\Users\\Merc√®\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n","File \u001b[1;32mc:\\Users\\Merc√®\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:425\u001b[0m, in \u001b[0;36mTensorFlowTrainer.evaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, return_dict, **kwargs)\u001b[0m\n\u001b[0;32m    423\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[0;32m    424\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_test_batch_begin(step)\n\u001b[1;32m--> 425\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest_function(iterator)\n\u001b[0;32m    426\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pythonify_logs(logs)\n\u001b[0;32m    427\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_test_batch_end(step, logs)\n","File \u001b[1;32mc:\\Users\\Merc√®\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n","File \u001b[1;32mc:\\Users\\Merc√®\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n","File \u001b[1;32mc:\\Users\\Merc√®\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m tracing_compilation\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[0;32m    879\u001b[0m     args, kwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config\n\u001b[0;32m    880\u001b[0m )\n\u001b[0;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[0;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n","File \u001b[1;32mc:\\Users\\Merc√®\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m function\u001b[38;5;241m.\u001b[39m_call_flat(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    140\u001b[0m     flat_inputs, captured_inputs\u001b[38;5;241m=\u001b[39mfunction\u001b[38;5;241m.\u001b[39mcaptured_inputs\n\u001b[0;32m    141\u001b[0m )\n","File \u001b[1;32mc:\\Users\\Merc√®\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inference_function\u001b[38;5;241m.\u001b[39mcall_preflattened(args)\n\u001b[0;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1324\u001b[0m     args,\n\u001b[0;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1326\u001b[0m     executing_eagerly)\n\u001b[0;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n","File \u001b[1;32mc:\\Users\\Merc√®\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall_flat(\u001b[38;5;241m*\u001b[39margs)\n\u001b[0;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n","File \u001b[1;32mc:\\Users\\Merc√®\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[0;32m    252\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname,\n\u001b[0;32m    253\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    254\u001b[0m         \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mflat_outputs),\n\u001b[0;32m    255\u001b[0m     )\n\u001b[0;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    261\u001b[0m     )\n","File \u001b[1;32mc:\\Users\\Merc√®\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1500\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1498\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1499\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1500\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute(\n\u001b[0;32m   1501\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1502\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   1503\u001b[0m       inputs\u001b[38;5;241m=\u001b[39mtensor_inputs,\n\u001b[0;32m   1504\u001b[0m       attrs\u001b[38;5;241m=\u001b[39mattrs,\n\u001b[0;32m   1505\u001b[0m       ctx\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1506\u001b[0m   )\n\u001b[0;32m   1507\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1508\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1509\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1510\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1514\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1515\u001b[0m   )\n","File \u001b[1;32mc:\\Users\\Merc√®\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n","\u001b[1;31mKeyboardInterrupt\u001b[0m: "]}],"source":["histories_adam = []\n","\n","e=0\n","while ( e < MAX_EPOCHS):\n","    for i in range(0, len(train_gens)):\n","        # train_gen.n = number of images for training\n","        STEP_SIZE_TRAIN = train_gens[i].n//train_gens[i].batch_size\n","        # train_gen.n = number of images for validation\n","        STEP_SIZE_VALID = valid_gens[i].n//valid_gens[i].batch_size\n","        print(\"STEP_SIZE_TRAIN\",STEP_SIZE_TRAIN)\n","        print(\"STEP_SIZE_VALID\",STEP_SIZE_VALID)\n","        histories_adam.append(\n","            model_adam.fit(train_gens[i],\n","                                steps_per_epoch=STEP_SIZE_TRAIN,\n","                                validation_data=valid_gens[i],\n","                                validation_steps=STEP_SIZE_VALID,\n","                                epochs=DIR_EPOCHS)\n","        )\n","        e+=1"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["histories_sgd = []\n","\n","e=0\n","while ( e < MAX_EPOCHS):\n","    for i in range(0, len(train_gens)):\n","        # train_gen.n = number of images for training\n","        STEP_SIZE_TRAIN = train_gens[i].n//train_gens[i].batch_size\n","        # train_gen.n = number of images for validation\n","        STEP_SIZE_VALID = valid_gens[i].n//valid_gens[i].batch_size\n","        print(\"STEP_SIZE_TRAIN\",STEP_SIZE_TRAIN)\n","        print(\"STEP_SIZE_VALID\",STEP_SIZE_VALID)\n","        histories_sgd.append(\n","            model_sgd.fit_generator(generator=train_gens[i],\n","                                steps_per_epoch=STEP_SIZE_TRAIN,\n","                                validation_data=valid_gens[i],\n","                                validation_steps=STEP_SIZE_VALID,\n","                                epochs=DIR_EPOCHS)\n","        )\n","        e+=1"]},{"cell_type":"markdown","metadata":{"_uuid":"3a05218bcf6f36b56519fd3091b182c2efd756a9"},"source":["# Evaluate the model üßê ü§î"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true,"_uuid":"30f09ae79b59fbec2375dd5eadee5c1af61dbb03","trusted":true},"outputs":[],"source":["accuracies_adam = []\n","val_accuracies_adam = []\n","losses_adam = []\n","val_losses_adam = []\n","for hist in histories_adam:\n","    if hist:\n","        accuracies_adam += hist.history['acc']\n","        val_accuracies_adam += hist.history['val_acc']\n","        losses_adam += hist.history['loss']\n","        val_losses_adam += hist.history['val_loss']"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["accuracies_sgd = []\n","val_accuracies_sgd = []\n","losses_sgd = []\n","val_losses_sgd = []\n","for hist in histories_sgd:\n","    if hist:\n","        accuracies_sgd += hist.history['acc']\n","        val_accuracies_sgd += hist.history['val_acc']\n","        losses_sgd += hist.history['loss']\n","        val_losses_sgd += hist.history['val_loss']"]},{"cell_type":"markdown","metadata":{},"source":["## Plots\n","### Accuracies"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true,"_uuid":"b2b8b4d7f244b57cc3df0fba829fb73a93da8d23","trusted":true},"outputs":[],"source":["# Plot training & validation accuracy values\n","plt.plot(accuracies_adam, label = \"Adam Train\")\n","plt.plot(val_accuracies_adam, label = \"Adam Test\")\n","\n","plt.plot(accuracies_sgd, label = \"SGD Train\")\n","plt.plot(val_accuracies_sgd, label = \"SGD Test\")\n","\n","plt.title('Model accuracy')\n","plt.ylabel('Accuracy')\n","plt.xlabel('Epoch')\n","plt.legend()\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["### Loss values"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Plot training & validation loss values\n","plt.plot(losses_adam, label = \"Adam Train\")\n","plt.plot(val_losses_adam, label = \"Adam Test\")\n","\n","plt.plot(losses_sgd, label = \"SGD Train\")\n","plt.plot(val_losses_sgd, label = \"SGD Test\")\n","\n","plt.title('Model loss')\n","plt.ylabel('Loss')\n","plt.xlabel('Epoch')\n","plt.legend()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"15433eaf26bb11ff67095ba0cbe781b62453a62a","trusted":true},"outputs":[],"source":["import time\n","timestr = time.strftime(\"%Y%m%d-%H%M%S\") # e.g: 20181109-180140\n","model_adam.save('painters_adam_e45_'+timestr+'.h5')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["timestr = time.strftime(\"%Y%m%d-%H%M%S\") # e.g: 20181109-180140\n","model_sgd.save('painters_adam_e45_'+timestr+'.h5')"]},{"cell_type":"markdown","metadata":{"_uuid":"2fa3ebde72fb64279bc367da190783f2524d2bad"},"source":["# Predict the output üîÆ üé©"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"160deb675d28625a391b3760ffa105e2272bb023","trusted":true},"outputs":[],"source":["PRED_STEPS = len(test_gen) #100 # default would have been len(test_gen)"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"98425b4ae320934e1ef68b50ea34deac31c284ab","trusted":true},"outputs":[],"source":["# Need to reset the test_gen before calling predict_generator\n","# This is important because forgetting to reset the test_generator results in outputs with a weird order.\n","test_gen.reset()\n","pred_adam = model_adam.predict_generator(test_gen, verbose=1, steps=PRED_STEPS)"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-output":true,"_uuid":"3bcf77f568962e91f1245ed77b00c5746ad4b48e","trusted":true},"outputs":[],"source":["print(len(pred_adam),\"\\n\",pred_adam)"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"dfb50c45a54612d6b6a0210d3f2c00f999bc1b52","trusted":true},"outputs":[],"source":["predicted_class_indices_adam = np.argmax(pred_adam,axis=1)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def retrieve_results(predicted_class_indices, train_gens):\n","    print(len(predicted_class_indices),\"\\n\",predicted_class_indices)\n","    print(\"it has values ranging from \",min(predicted_class_indices),\"...to...\",max(predicted_class_indices))\n","    labels = (train_gens[0].class_indices)\n","    labels = dict((v,k) for k,v in labels.items())\n","    predictions = [labels[k] for k in predicted_class_indices]\n","    print(\"*\"*20+\"\\nclass_indices\\n\"+\"*\"*20+\"\\n\",train_gens[0].class_indices,\"\\n\")\n","    print(\"*\"*20+\"\\nlabels\\n\"+\"*\"*20+\"\\n\",labels,\"\\n\")\n","    print(\"*\"*20+\"\\npredictions has\", len(predictions),\"values that look like\",\"'\"+str(predictions[0])+\"' which is the first prediction and corresponds to this index of the classes:\",train_gens[0].class_indices[predictions[0]])\n","    # Save the results to a CSV file.\n","    filenames=test_gen.filenames[:len(predictions)] # because \"ValueError: arrays must all be same length\"\n","\n","    real_artists = []\n","    for f in filenames:\n","        real = test_df[test_df['new_filename'] == f].artist.get_values()[0]\n","        real_artists.append(real)\n","\n","    results=pd.DataFrame({\"Filename\":filenames,\n","                        \"Predictions\":predictions,\n","                        \"Real Values\":real_artists})\n","    results.to_csv(\"results.csv\",index=False)\n","\n","    return results"]},{"cell_type":"markdown","metadata":{},"source":["## Adam"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["results_adam = retrieve_results(predicted_class_indices_adam, train_gens)"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"4acad3f61b891c2551a657ca242e6ee267919343","trusted":true},"outputs":[],"source":["results_adam.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"69605197bb4b01b272bccab9291b49f17e80fe0a","trusted":true},"outputs":[],"source":["len(training_set_artists)"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"8b1cd478370459daba02120d7613350baadd0518","trusted":true},"outputs":[],"source":["print(training_set_artists)"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"598d6d1189366f72d179c1f88ac026dade7dc1de","trusted":true},"outputs":[],"source":["def testing_new_images(results, training_set_artists):  \n","    count = 0\n","    match = 0\n","    unexpected_count = 0\n","    unexpected_match = 0\n","    match_both_expected_unexpected = 0\n","\n","    for p, r in zip(results['Predictions'], results['Real Values']):\n","        if r in training_set_artists:\n","            count += 1\n","            if p == r:\n","                match += 1\n","        else:\n","            unexpected_count += 1\n","            if p == r:\n","                unexpected_match += 1\n","\n","    print(\"test accuracy on new images for TRAINED artsits\")\n","    acc = match/count\n","    print(match,\"/\",count,\"=\",\"{:.4f}\".format(acc))\n","\n","    print(\"test accuracy on new images for UNEXPECTED artsits\")\n","    u_acc = unexpected_match/unexpected_count\n","    print(unexpected_match,\"/\",unexpected_count,\"=\",\"{:.4f}\".format(u_acc))\n","\n","    print(\"test accuracy on new images\")\n","    total_match = match+unexpected_match\n","    total_count = count+unexpected_count\n","    total_acc = (total_match)/(total_count)\n","    print(total_match,\"/\",total_count,\"=\",\"{:.4f}\".format(total_acc))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["testing_new_images(results_adam, training_set_artists)"]},{"cell_type":"markdown","metadata":{},"source":["## SGD"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["test_gen.reset()\n","pred_sgd = model_sgd.predict_generator(test_gen, verbose=1, steps=PRED_STEPS)\n","print(len(pred_sgd),\"\\n\",pred_sgd)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["predicted_class_indices_sgd = np.argmax(pred_sgd,axis=1)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["results_sgd = retrieve_results(predicted_class_indices_sgd, train_gens)\n","results_sgd.head()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(len(training_set_artists))\n","print(training_set_artists)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["testing_new_images(results_sgd, training_set_artists)"]},{"cell_type":"markdown","metadata":{"_uuid":"b71eebdaf00b0fa1d0b1401d8e00dff4a7b5111e"},"source":["So, it seems like the model may have learned some interesting patterns related to the artists that it expects. \n","\n","**Questions to explore:**\n","* [What does the model actually \"see\"](https://arxiv.org/abs/1312.6034) in a painting by [Pablo Picasso](https://www.wikiart.org/en/pablo-picasso/) as opposed to [Vincent van Gogh](https://www.wikiart.org/en/vincent-van-gogh)?\n","* What would happen if we trained the model on the full artist dataset or at least on artists with over 200 paintings in the dataset?\n","* Can the accuracy be improved with techniques like data augmentation or with a custom convolutional neural network? How about doing transfer learning with different [pre-trained model](https://keras.io/applications)?\n","* How can the learning rate be tuned to improve the accuracy?\n","* Would a regularization technique like [dropout](https://machinelearningmastery.com/dropout-regularization-deep-learning-models-keras/) be helpful?\n","* This notebook uses the [Adam](https://keras.io/optimizers/#adam) optimizer... what if we tried RMSprop?\n","* How about using an [ensemble of models](https://machinelearningmastery.com/ensemble-machine-learning-algorithms-python-scikit-learn/)?"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.7"}},"nbformat":4,"nbformat_minor":1}
