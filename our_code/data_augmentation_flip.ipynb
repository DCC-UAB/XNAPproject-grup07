{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Augmentation with flip at 3 different positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "# imatges originals:\n",
    "input_dir = \"../../train_1\" \n",
    "\n",
    "# where are we saving the images created:\n",
    "output_dir = \"../../train_1_flip\"\n",
    "\n",
    "# create the folder:\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# save all the original images:\n",
    "image_files = os.listdir(input_dir)\n",
    "\n",
    "for img_file in image_files:\n",
    "    img_path = os.path.join(input_dir, img_file)\n",
    "\n",
    "    # this reads the original image\n",
    "    img = cv2.imread(img_path)\n",
    "    # as we had some errors, we need to find out if it loaded correcty\n",
    "    if img is None:\n",
    "        print(\"No carrega correctament\", img_path)\n",
    "        continue\n",
    "\n",
    "    # horizontal\n",
    "    flipped_img_h = cv2.flip(img, 1)\n",
    "    cv2.imwrite(os.path.join(output_dir, f\"{img_file.split('.')[0]}_flipped_h.jpg\"), flipped_img_h)\n",
    "\n",
    "    # vertical\n",
    "    flipped_img_v = cv2.flip(img, 0)\n",
    "    cv2.imwrite(os.path.join(output_dir, f\"{img_file.split('.')[0]}_flipped_v.jpg\"), flipped_img_v)\n",
    "\n",
    "    # horizontal and vertical\n",
    "    flipped_img_hv = cv2.flip(img, -1)\n",
    "    cv2.imwrite(os.path.join(output_dir, f\"{img_file.split('.')[0]}_flipped_hv.jpg\"), flipped_img_hv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "Can a computer \"learn\" to classify artists by their paintings? \n",
    "\n",
    "ResNet50 is a good model for classifying ImageNet data. How about a set of 38 artists?\n",
    "\n",
    "We use transfer learning to re-train a ResNet50 model to identify one of 38 artists who have more than ~~300~~ ***200*** paintings in the dataset. \n",
    "\n",
    "This notebook is part of a project for CSC 480 taught by [Dr. Franz J. Kurfess](http://users.csc.calpoly.edu/~fkurfess/) at Cal Poly\n",
    "\n",
    "A web application is [in development](https://github.com/SomethingAboutImages/WebImageClassifier) to make use of the model that this notebook outputs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from random import seed # for setting seed\n",
    "import tensorflow\n",
    "from IPython import sys_info\n",
    "\n",
    "import gc # garbage collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MY_SEED = 42 # 480 could work too\n",
    "seed(MY_SEED)\n",
    "np.random.seed(MY_SEED)\n",
    "tensorflow.random.set_seed(MY_SEED)\n",
    "\n",
    "print(sys_info())\n",
    "# get module information\n",
    "!pip freeze > frozen-requirements.txt\n",
    "# append system information to file\n",
    "with open(\"frozen-requirements.txt\", \"a\") as file:\n",
    "    file.write(sys_info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "# print out the CPUs and GPUs\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/25705773/image-cropping-tool-python\n",
    "# because painting images are hella big\n",
    "from PIL import Image\n",
    "Image.MAX_IMAGE_PIXELS = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# globals\n",
    "\n",
    "# DATA_DIR = '../input/painters-train-part-1/'\n",
    "\n",
    "# TRAIN_1_DIR = '../input/painters-train-part-1/train_1/train_1/'\n",
    "# TRAIN_2_DIR = '../input/painters-train-part-1/train_2/train_2/'\n",
    "# TRAIN_3_DIR = '../input/painters-train-part-1/train_3/train_3/'\n",
    "\n",
    "# TRAIN_4_DIR = '../input/painters-train-part-2/train_4/train_4/'\n",
    "# TRAIN_5_DIR = '../input/painters-train-part-2/train_5/train_5/'\n",
    "# TRAIN_6_DIR = '../input/painters-train-part-2/train_6/train_6/'\n",
    "\n",
    "# TRAIN_7_DIR = '../input/painters-train-part-3/train_7/train_7/'\n",
    "# TRAIN_8_DIR = '../input/painters-train-part-3/train_8/train_8/'\n",
    "# TRAIN_9_DIR = '../input/painters-train-part-3/train_9/train_9/'\n",
    "\n",
    "TRAIN_DIRS = ['../../train_1_flip']\n",
    "\n",
    "TEST_DIR = '../input/painter-test/test/test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../all_data_info.csv')\n",
    "print(\"df.shape\", df.shape)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quick fix for corrupted files\n",
    "list_of_corrupted = ['3917.jpg','18649.jpg','20153.jpg','41945.jpg','79499.jpg','91033.jpg','92899.jpg','95347.jpg','100532.jpg','101947.jpg']\n",
    "\n",
    "# completely get rid of them\n",
    "df = df[df[\"new_filename\"].isin(list_of_corrupted) == False]\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = df[df[\"in_train\"] == True]\n",
    "test_df = df[df['in_train'] == False]\n",
    "train_df = train_df[['artist', 'new_filename']]\n",
    "test_df = test_df[['artist', 'new_filename']]\n",
    "\n",
    "print(\"test_df.shape\", test_df.shape)\n",
    "print(\"train_df.shape\", train_df.shape)\n",
    "\n",
    "artists = {} # holds artist hash & the count\n",
    "for a in train_df['artist']:\n",
    "    if (a not in artists):\n",
    "        artists[a] = 1\n",
    "    else:\n",
    "        artists[a] += 1\n",
    "# print(artists)\n",
    "\n",
    "training_set_artists = []\n",
    "for a, count in artists.items():\n",
    "    if(int(count) >= 200):\n",
    "        training_set_artists.append(a)\n",
    "\n",
    "print(\"\\nnumber of artists:\", len(training_set_artists))\n",
    "\n",
    "print(\"\\nlist of artists...\")\n",
    "print(training_set_artists)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_df = train_df[train_df[\"artist\"].isin(training_set_artists)]\n",
    "\n",
    "t_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1_df = t_df[t_df['new_filename'].str.startswith('1')]\n",
    "\n",
    "t2_df = t_df[t_df['new_filename'].str.startswith('2')]\n",
    "\n",
    "t3_df = t_df[t_df['new_filename'].str.startswith('3')]\n",
    "\n",
    "t4_df = t_df[t_df['new_filename'].str.startswith('4')]\n",
    "\n",
    "t5_df = t_df[t_df['new_filename'].str.startswith('5')]\n",
    "\n",
    "t6_df = t_df[t_df['new_filename'].str.startswith('6')]\n",
    "\n",
    "t7_df = t_df[t_df['new_filename'].str.startswith('7')]\n",
    "\n",
    "t8_df = t_df[t_df['new_filename'].str.startswith('8')]\n",
    "\n",
    "t9_df = t_df[t_df['new_filename'].str.startswith('9')]\n",
    "\n",
    "all_train_dfs = [t1_df, t2_df, t3_df,\n",
    "                t4_df, t5_df, t6_df,\n",
    "                t7_df, t8_df, t9_df]\n",
    "\n",
    "t9_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications import ResNet50\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense, Flatten, GlobalAveragePooling2D\n",
    "\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# specify the model that classifies 38 artists üé® üñå"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(training_set_artists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(training_set_artists) # one class per artist\n",
    "weights_notop_path = '../input/resnet50/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
    "model = Sequential()\n",
    "model.add(ResNet50(\n",
    "  include_top=False,\n",
    "  weights=weights_notop_path,\n",
    "  pooling='avg'\n",
    "))\n",
    "model.add(Dense(\n",
    "  num_classes,\n",
    "  activation='softmax'\n",
    "))\n",
    "\n",
    "model.layers[0].trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compile Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "  optimizer='adam', # lots of people reccommend Adam optimizer\n",
    "  loss='categorical_crossentropy', # aka \"log loss\" -- the cost function to minimize \n",
    "  # so 'optimizer' algorithm will minimize 'loss' function\n",
    "  metrics=['accuracy'] # ask it to report % of correct predictions\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#¬†setup the image data generator for each training directory "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model globals\n",
    "IMAGE_SIZE = 224\n",
    "BATCH_SIZE = 96\n",
    "TEST_BATCH_SIZE = 17 # because test has 23817 images and factors of 23817 are 3*17*467\n",
    "                     # it is important that this number evenly divides the total num images \n",
    "VAL_SPLIT = 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_generators(\n",
    "    val_split, train_dataframe, train_dir,\n",
    "    img_size, batch_size, my_seed, list_of_classes,\n",
    "    test_dataframe, test_dir, test_batch_size\n",
    "):\n",
    "    print(\"-\"*20)\n",
    "    if not preprocess_input:\n",
    "          raise Exception(\"please do import call 'from tensorflow.python.keras.applications.resnet50 import preprocess_input'\")\n",
    "\n",
    "    # setup resnet50 preprocessing \n",
    "    data_gen = ImageDataGenerator(\n",
    "        preprocessing_function=preprocess_input,\n",
    "        validation_split=val_split)\n",
    "\n",
    "    print(len(train_dataframe), \"images in\", train_dir, \"and validation_split =\", val_split)\n",
    "    print(\"\\ntraining set ImageDataGenerator\")\n",
    "    train_gen = data_gen.flow_from_dataframe(\n",
    "        dataframe=train_dataframe.reset_index(), # call reset_index() so keras can start with index 0\n",
    "        directory=train_dir,\n",
    "        x_col='new_filename',\n",
    "        y_col='artist',\n",
    "        has_ext=True,\n",
    "        target_size=(img_size, img_size),\n",
    "        subset=\"training\",\n",
    "        batch_size=batch_size,\n",
    "        seed=my_seed,\n",
    "        shuffle=True,\n",
    "        class_mode='categorical',\n",
    "        classes=list_of_classes\n",
    "    )\n",
    "\n",
    "    print(\"\\nvalidation set ImageDataGenerator\")\n",
    "    valid_gen = data_gen.flow_from_dataframe(\n",
    "        dataframe=train_dataframe.reset_index(), # call reset_index() so keras can start with index 0\n",
    "        directory=train_dir,\n",
    "        x_col='new_filename',\n",
    "        y_col='artist',\n",
    "        has_ext=True,\n",
    "        subset=\"validation\",\n",
    "        batch_size=batch_size,\n",
    "        seed=my_seed,\n",
    "        shuffle=True,\n",
    "        target_size=(img_size,img_size),\n",
    "        class_mode='categorical',\n",
    "        classes=list_of_classes\n",
    "    )\n",
    "\n",
    "    test_data_gen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "    print(\"\\ntest set ImageDataGenerator\")\n",
    "    test_gen = test_data_gen.flow_from_dataframe(\n",
    "        dataframe=test_dataframe.reset_index(), # call reset_index() so keras can start with index 0\n",
    "        directory=test_dir,\n",
    "        x_col='new_filename',\n",
    "        y_col=None,\n",
    "        has_ext=True,\n",
    "        batch_size=test_batch_size,\n",
    "        seed=my_seed,\n",
    "        shuffle=False, # dont shuffle test directory\n",
    "        class_mode=None,\n",
    "        target_size=(img_size,img_size)\n",
    "    )\n",
    "\n",
    "    return (train_gen, valid_gen, test_gen)\n",
    "\n",
    "print(\"defined setup_generators()\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete some unused dataframes to free some RAM for training\n",
    "del df\n",
    "del t_df\n",
    "del t1_df\n",
    "del t2_df\n",
    "del t3_df\n",
    "del t4_df\n",
    "del t5_df\n",
    "del t6_df\n",
    "del t7_df\n",
    "del t8_df\n",
    "del t9_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gens = [None]*len(TRAIN_DIRS)\n",
    "valid_gens = [None]*len(TRAIN_DIRS)\n",
    "test_gen  = None # only 1 test_gen\n",
    "i = 0\n",
    "for i in range(0, len(TRAIN_DIRS)):\n",
    "    train_gens[i], valid_gens[i], test_gen = setup_generators(\n",
    "        train_dataframe=all_train_dfs[i], train_dir=TRAIN_DIRS[i],\n",
    "        val_split=VAL_SPLIT, img_size=IMAGE_SIZE, batch_size=BATCH_SIZE, my_seed=MY_SEED, \n",
    "        list_of_classes=training_set_artists, test_dataframe=test_df, \n",
    "        test_dir=TEST_DIR, test_batch_size=TEST_BATCH_SIZE\n",
    "    )\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAINING TIME!  üéâ üéä üéÅ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_EPOCHS = 5 * len(train_gens) # should be a multiple of 9 because need evenly train each train_dir\n",
    "DIR_EPOCHS = 1 # fit each train_dir at least this many times before overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histories = []\n",
    "\n",
    "e=0\n",
    "while ( e < MAX_EPOCHS):\n",
    "    for i in range(0, len(train_gens)):\n",
    "        # train_gen.n = number of images for training\n",
    "        STEP_SIZE_TRAIN = train_gens[i].n//train_gens[i].batch_size\n",
    "        # train_gen.n = number of images for validation\n",
    "        STEP_SIZE_VALID = valid_gens[i].n//valid_gens[i].batch_size\n",
    "        print(\"STEP_SIZE_TRAIN\",STEP_SIZE_TRAIN)\n",
    "        print(\"STEP_SIZE_VALID\",STEP_SIZE_VALID)\n",
    "        histories.append(\n",
    "            model.fit_generator(generator=train_gens[i],\n",
    "                                steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "                                validation_data=valid_gens[i],\n",
    "                                validation_steps=STEP_SIZE_VALID,\n",
    "                                epochs=DIR_EPOCHS)\n",
    "        )\n",
    "        e+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the model üßê ü§î"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies = []\n",
    "val_accuracies = []\n",
    "losses = []\n",
    "val_losses = []\n",
    "for hist in histories:\n",
    "    if hist:\n",
    "        accuracies += hist.history['acc']\n",
    "        val_accuracies += hist.history['val_acc']\n",
    "        losses += hist.history['loss']\n",
    "        val_losses += hist.history['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training & validation accuracy values\n",
    "plt.plot(accuracies)\n",
    "plt.plot(val_accuracies)\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.plot(losses)\n",
    "plt.plot(val_losses)\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "timestr = time.strftime(\"%Y%m%d-%H%M%S\") # e.g: 20181109-180140\n",
    "model.save('painters_adam_e45_'+timestr+'.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict the output üîÆ üé©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRED_STEPS = len(test_gen) #100 # default would have been len(test_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to reset the test_gen before calling predict_generator\n",
    "# This is important because forgetting to reset the test_generator results in outputs with a weird order.\n",
    "test_gen.reset()\n",
    "pred=model.predict_generator(test_gen, verbose=1, steps=PRED_STEPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(pred),\"\\n\",pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_class_indices=np.argmax(pred,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(predicted_class_indices),\"\\n\",predicted_class_indices)\n",
    "print(\"it has values ranging from \",min(predicted_class_indices),\"...to...\",max(predicted_class_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = (train_gens[0].class_indices)\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "predictions = [labels[k] for k in predicted_class_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"*\"*20+\"\\nclass_indices\\n\"+\"*\"*20+\"\\n\",train_gens[0].class_indices,\"\\n\")\n",
    "print(\"*\"*20+\"\\nlabels\\n\"+\"*\"*20+\"\\n\",labels,\"\\n\")\n",
    "print(\"*\"*20+\"\\npredictions has\", len(predictions),\"values that look like\",\"'\"+str(predictions[0])+\"' which is the first prediction and corresponds to this index of the classes:\",train_gens[0].class_indices[predictions[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the results to a CSV file.\n",
    "filenames=test_gen.filenames[:len(predictions)] # because \"ValueError: arrays must all be same length\"\n",
    "\n",
    "real_artists = []\n",
    "for f in filenames:\n",
    "    real = test_df[test_df['new_filename'] == f].artist.get_values()[0]\n",
    "    real_artists.append(real)\n",
    "\n",
    "results=pd.DataFrame({\"Filename\":filenames,\n",
    "                      \"Predictions\":predictions,\n",
    "                      \"Real Values\":real_artists})\n",
    "results.to_csv(\"results.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(training_set_artists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(training_set_artists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "match = 0\n",
    "unexpected_count = 0\n",
    "unexpected_match = 0\n",
    "match_both_expected_unexpected = 0\n",
    "\n",
    "for p, r in zip(results['Predictions'], results['Real Values']):\n",
    "    if r in training_set_artists:\n",
    "        count += 1\n",
    "        if p == r:\n",
    "            match += 1\n",
    "    else:\n",
    "        unexpected_count += 1\n",
    "        if p == r:\n",
    "            unexpected_match += 1\n",
    "\n",
    "print(\"test accuracy on new images for TRAINED artsits\")\n",
    "acc = match/count\n",
    "print(match,\"/\",count,\"=\",\"{:.4f}\".format(acc))\n",
    "\n",
    "print(\"test accuracy on new images for UNEXPECTED artsits\")\n",
    "u_acc = unexpected_match/unexpected_count\n",
    "print(unexpected_match,\"/\",unexpected_count,\"=\",\"{:.4f}\".format(u_acc))\n",
    "\n",
    "print(\"test accuracy on new images\")\n",
    "total_match = match+unexpected_match\n",
    "total_count = count+unexpected_count\n",
    "total_acc = (total_match)/(total_count)\n",
    "print(total_match,\"/\",total_count,\"=\",\"{:.4f}\".format(total_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, it seems like the model may have learned some interesting patterns related to the artists that it expects. \n",
    "\n",
    "**Questions to explore:**\n",
    "* [What does the model actually \"see\"](https://arxiv.org/abs/1312.6034) in a painting by [Pablo Picasso](https://www.wikiart.org/en/pablo-picasso/) as opposed to [Vincent van Gogh](https://www.wikiart.org/en/vincent-van-gogh)?\n",
    "* What would happen if we trained the model on the full artist dataset or at least on artists with over 200 paintings in the dataset?\n",
    "* Can the accuracy be improved with techniques like data augmentation or with a custom convolutional neural network? How about doing transfer learning with different [pre-trained model](https://keras.io/applications)?\n",
    "* How can the learning rate be tuned to improve the accuracy?\n",
    "* Would a regularization technique like [dropout](https://machinelearningmastery.com/dropout-regularization-deep-learning-models-keras/) be helpful?\n",
    "* This notebook uses the [Adam](https://keras.io/optimizers/#adam) optimizer... what if we tried RMSprop?\n",
    "* How about using an [ensemble of models](https://machinelearningmastery.com/ensemble-machine-learning-algorithms-python-scikit-learn/)?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
