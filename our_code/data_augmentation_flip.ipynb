{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Augmentation with flip at 3 different positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No se pudo cargar la imagen ../../train_1\\121.jpg\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "# imatges originals:\n",
    "input_dir = \"../../train_1\" \n",
    "\n",
    "# where are we saving the images created:\n",
    "output_dir = \"../../train_1_flip\"\n",
    "\n",
    "# create the folder:\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# save all the original images:\n",
    "image_files = os.listdir(input_dir)\n",
    "\n",
    "for img_file in image_files:\n",
    "    img_path = os.path.join(input_dir, img_file)\n",
    "\n",
    "    # this reads the original image\n",
    "    img = cv2.imread(img_path)\n",
    "    # as we had some errors, we need to find out if it loaded correcty\n",
    "    if img is None:\n",
    "        print(\"No carrega correctament\", img_path)\n",
    "        continue\n",
    "\n",
    "    # horizontal\n",
    "    flipped_img_h = cv2.flip(img, 1)\n",
    "    cv2.imwrite(os.path.join(output_dir, f\"{img_file.split('.')[0]}_flipped_h.jpg\"), flipped_img_h)\n",
    "\n",
    "    # vertical\n",
    "    flipped_img_v = cv2.flip(img, 0)\n",
    "    cv2.imwrite(os.path.join(output_dir, f\"{img_file.split('.')[0]}_flipped_v.jpg\"), flipped_img_v)\n",
    "\n",
    "    # horizontal and vertical\n",
    "    flipped_img_hv = cv2.flip(img, -1)\n",
    "    cv2.imwrite(os.path.join(output_dir, f\"{img_file.split('.')[0]}_flipped_hv.jpg\"), flipped_img_hv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "Can a computer \"learn\" to classify artists by their paintings? \n",
    "\n",
    "ResNet50 is a good model for classifying ImageNet data. How about a set of 38 artists?\n",
    "\n",
    "We use transfer learning to re-train a ResNet50 model to identify one of 38 artists who have more than ~~300~~ ***200*** paintings in the dataset. \n",
    "\n",
    "This notebook is part of a project for CSC 480 taught by [Dr. Franz J. Kurfess](http://users.csc.calpoly.edu/~fkurfess/) at Cal Poly\n",
    "\n",
    "A web application is [in development](https://github.com/SomethingAboutImages/WebImageClassifier) to make use of the model that this notebook outputs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from random import seed # for setting seed\n",
    "import tensorflow\n",
    "from IPython import sys_info\n",
    "\n",
    "import gc # garbage collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'commit_hash': '928881c53',\n",
      " 'commit_source': 'installation',\n",
      " 'default_encoding': 'utf-8',\n",
      " 'ipython_path': 'C:\\\\Users\\\\aluce\\\\AppData\\\\Local\\\\Packages\\\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\\\LocalCache\\\\local-packages\\\\Python39\\\\site-packages\\\\IPython',\n",
      " 'ipython_version': '8.18.0',\n",
      " 'os_name': 'nt',\n",
      " 'platform': 'Windows-10-10.0.22621-SP0',\n",
      " 'sys_executable': 'C:\\\\Users\\\\aluce\\\\AppData\\\\Local\\\\Microsoft\\\\WindowsApps\\\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\\\python.exe',\n",
      " 'sys_platform': 'win32',\n",
      " 'sys_version': '3.9.13 (tags/v3.9.13:6de2ca5, May 17 2022, 16:36:42) [MSC '\n",
      "                'v.1929 64 bit (AMD64)]'}\n"
     ]
    }
   ],
   "source": [
    "MY_SEED = 42 # 480 could work too\n",
    "seed(MY_SEED)\n",
    "np.random.seed(MY_SEED)\n",
    "tensorflow.random.set_seed(MY_SEED)\n",
    "\n",
    "print(sys_info())\n",
    "# get module information\n",
    "!pip freeze > frozen-requirements.txt\n",
    "# append system information to file\n",
    "with open(\"frozen-requirements.txt\", \"a\") as file:\n",
    "    file.write(sys_info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 15983860916304033431\n",
      "xla_global_id: -1\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "# print out the CPUs and GPUs\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/25705773/image-cropping-tool-python\n",
    "# because painting images are hella big\n",
    "from PIL import Image\n",
    "Image.MAX_IMAGE_PIXELS = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# globals\n",
    "\n",
    "# DATA_DIR = '../input/painters-train-part-1/'\n",
    "\n",
    "# TRAIN_1_DIR = '../input/painters-train-part-1/train_1/train_1/'\n",
    "# TRAIN_2_DIR = '../input/painters-train-part-1/train_2/train_2/'\n",
    "# TRAIN_3_DIR = '../input/painters-train-part-1/train_3/train_3/'\n",
    "\n",
    "# TRAIN_4_DIR = '../input/painters-train-part-2/train_4/train_4/'\n",
    "# TRAIN_5_DIR = '../input/painters-train-part-2/train_5/train_5/'\n",
    "# TRAIN_6_DIR = '../input/painters-train-part-2/train_6/train_6/'\n",
    "\n",
    "# TRAIN_7_DIR = '../input/painters-train-part-3/train_7/train_7/'\n",
    "# TRAIN_8_DIR = '../input/painters-train-part-3/train_8/train_8/'\n",
    "# TRAIN_9_DIR = '../input/painters-train-part-3/train_9/train_9/'\n",
    "\n",
    "TRAIN_DIRS = ['../../train_1_flip']\n",
    "\n",
    "TEST_DIR = '../input/painter-test/test/test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df.shape (103250, 12)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>date</th>\n",
       "      <th>genre</th>\n",
       "      <th>pixelsx</th>\n",
       "      <th>pixelsy</th>\n",
       "      <th>size_bytes</th>\n",
       "      <th>source</th>\n",
       "      <th>style</th>\n",
       "      <th>title</th>\n",
       "      <th>artist_group</th>\n",
       "      <th>in_train</th>\n",
       "      <th>new_filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Barnett Newman</td>\n",
       "      <td>1955.0</td>\n",
       "      <td>abstract</td>\n",
       "      <td>15530.0</td>\n",
       "      <td>6911.0</td>\n",
       "      <td>9201912.0</td>\n",
       "      <td>wikiart</td>\n",
       "      <td>Color Field Painting</td>\n",
       "      <td>Uriel</td>\n",
       "      <td>train_only</td>\n",
       "      <td>True</td>\n",
       "      <td>102257.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Barnett Newman</td>\n",
       "      <td>1950.0</td>\n",
       "      <td>abstract</td>\n",
       "      <td>14559.0</td>\n",
       "      <td>6866.0</td>\n",
       "      <td>8867532.0</td>\n",
       "      <td>wikiart</td>\n",
       "      <td>Color Field Painting</td>\n",
       "      <td>Vir Heroicus Sublimis</td>\n",
       "      <td>train_only</td>\n",
       "      <td>True</td>\n",
       "      <td>75232.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kiri nichol</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9003.0</td>\n",
       "      <td>9004.0</td>\n",
       "      <td>1756681.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Neoplasticism</td>\n",
       "      <td>NaN</td>\n",
       "      <td>test_only</td>\n",
       "      <td>False</td>\n",
       "      <td>32145.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>kiri nichol</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9003.0</td>\n",
       "      <td>9004.0</td>\n",
       "      <td>1942046.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Neoplasticism</td>\n",
       "      <td>NaN</td>\n",
       "      <td>test_only</td>\n",
       "      <td>False</td>\n",
       "      <td>20304.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>kiri nichol</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9003.0</td>\n",
       "      <td>9004.0</td>\n",
       "      <td>1526212.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Neoplasticism</td>\n",
       "      <td>NaN</td>\n",
       "      <td>test_only</td>\n",
       "      <td>False</td>\n",
       "      <td>836.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103245</th>\n",
       "      <td>Jackson Pollock</td>\n",
       "      <td>1948.0</td>\n",
       "      <td>abstract</td>\n",
       "      <td>682.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>96405.0</td>\n",
       "      <td>wikiart</td>\n",
       "      <td>Action painting</td>\n",
       "      <td>Number 13A (Arabesque)</td>\n",
       "      <td>train_and_test</td>\n",
       "      <td>True</td>\n",
       "      <td>25525.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103246</th>\n",
       "      <td>Bernardo Strozzi</td>\n",
       "      <td>NaN</td>\n",
       "      <td>religious painting</td>\n",
       "      <td>329.0</td>\n",
       "      <td>456.0</td>\n",
       "      <td>127594.0</td>\n",
       "      <td>wikiart</td>\n",
       "      <td>Baroque</td>\n",
       "      <td>St. Francis of Assisi</td>\n",
       "      <td>train_only</td>\n",
       "      <td>True</td>\n",
       "      <td>47038.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103247</th>\n",
       "      <td>Josef Sima</td>\n",
       "      <td>NaN</td>\n",
       "      <td>landscape</td>\n",
       "      <td>293.0</td>\n",
       "      <td>512.0</td>\n",
       "      <td>102519.0</td>\n",
       "      <td>wikiart</td>\n",
       "      <td>Surrealism</td>\n",
       "      <td>Maisons Ã  la campagne II</td>\n",
       "      <td>train_and_test</td>\n",
       "      <td>False</td>\n",
       "      <td>7680.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103248</th>\n",
       "      <td>Brett Whiteley</td>\n",
       "      <td>1982.0</td>\n",
       "      <td>marina</td>\n",
       "      <td>293.0</td>\n",
       "      <td>512.0</td>\n",
       "      <td>167423.0</td>\n",
       "      <td>wikiart</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Thebe's Revenge</td>\n",
       "      <td>train_and_test</td>\n",
       "      <td>True</td>\n",
       "      <td>9021.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103249</th>\n",
       "      <td>Amadeo de Souza-Cardoso</td>\n",
       "      <td>1913</td>\n",
       "      <td>landscape</td>\n",
       "      <td>293.0</td>\n",
       "      <td>512.0</td>\n",
       "      <td>77577.0</td>\n",
       "      <td>wikiart</td>\n",
       "      <td>Cubism</td>\n",
       "      <td>House Manhufe</td>\n",
       "      <td>train_only</td>\n",
       "      <td>True</td>\n",
       "      <td>36564.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>103250 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         artist    date               genre  pixelsx  pixelsy  \\\n",
       "0                Barnett Newman  1955.0            abstract  15530.0   6911.0   \n",
       "1                Barnett Newman  1950.0            abstract  14559.0   6866.0   \n",
       "2                   kiri nichol  2013.0                 NaN   9003.0   9004.0   \n",
       "3                   kiri nichol  2013.0                 NaN   9003.0   9004.0   \n",
       "4                   kiri nichol  2013.0                 NaN   9003.0   9004.0   \n",
       "...                         ...     ...                 ...      ...      ...   \n",
       "103245          Jackson Pollock  1948.0            abstract    682.0    220.0   \n",
       "103246         Bernardo Strozzi     NaN  religious painting    329.0    456.0   \n",
       "103247               Josef Sima     NaN           landscape    293.0    512.0   \n",
       "103248           Brett Whiteley  1982.0              marina    293.0    512.0   \n",
       "103249  Amadeo de Souza-Cardoso    1913           landscape    293.0    512.0   \n",
       "\n",
       "        size_bytes   source                 style                     title  \\\n",
       "0        9201912.0  wikiart  Color Field Painting                     Uriel   \n",
       "1        8867532.0  wikiart  Color Field Painting     Vir Heroicus Sublimis   \n",
       "2        1756681.0      NaN         Neoplasticism                       NaN   \n",
       "3        1942046.0      NaN         Neoplasticism                       NaN   \n",
       "4        1526212.0      NaN         Neoplasticism                       NaN   \n",
       "...            ...      ...                   ...                       ...   \n",
       "103245     96405.0  wikiart       Action painting    Number 13A (Arabesque)   \n",
       "103246    127594.0  wikiart               Baroque     St. Francis of Assisi   \n",
       "103247    102519.0  wikiart            Surrealism  Maisons Ã  la campagne II   \n",
       "103248    167423.0  wikiart                   NaN           Thebe's Revenge   \n",
       "103249     77577.0  wikiart                Cubism            House Manhufe    \n",
       "\n",
       "          artist_group  in_train new_filename  \n",
       "0           train_only      True   102257.jpg  \n",
       "1           train_only      True    75232.jpg  \n",
       "2            test_only     False    32145.jpg  \n",
       "3            test_only     False    20304.jpg  \n",
       "4            test_only     False      836.jpg  \n",
       "...                ...       ...          ...  \n",
       "103245  train_and_test      True    25525.jpg  \n",
       "103246      train_only      True    47038.jpg  \n",
       "103247  train_and_test     False     7680.jpg  \n",
       "103248  train_and_test      True     9021.jpg  \n",
       "103249      train_only      True    36564.jpg  \n",
       "\n",
       "[103250 rows x 12 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv('../../all_data_info.csv')\n",
    "print(\"df.shape\", df.shape)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>date</th>\n",
       "      <th>genre</th>\n",
       "      <th>pixelsx</th>\n",
       "      <th>pixelsy</th>\n",
       "      <th>size_bytes</th>\n",
       "      <th>source</th>\n",
       "      <th>style</th>\n",
       "      <th>title</th>\n",
       "      <th>artist_group</th>\n",
       "      <th>in_train</th>\n",
       "      <th>new_filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Barnett Newman</td>\n",
       "      <td>1955.0</td>\n",
       "      <td>abstract</td>\n",
       "      <td>15530.0</td>\n",
       "      <td>6911.0</td>\n",
       "      <td>9201912.0</td>\n",
       "      <td>wikiart</td>\n",
       "      <td>Color Field Painting</td>\n",
       "      <td>Uriel</td>\n",
       "      <td>train_only</td>\n",
       "      <td>True</td>\n",
       "      <td>102257.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Barnett Newman</td>\n",
       "      <td>1950.0</td>\n",
       "      <td>abstract</td>\n",
       "      <td>14559.0</td>\n",
       "      <td>6866.0</td>\n",
       "      <td>8867532.0</td>\n",
       "      <td>wikiart</td>\n",
       "      <td>Color Field Painting</td>\n",
       "      <td>Vir Heroicus Sublimis</td>\n",
       "      <td>train_only</td>\n",
       "      <td>True</td>\n",
       "      <td>75232.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kiri nichol</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9003.0</td>\n",
       "      <td>9004.0</td>\n",
       "      <td>1756681.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Neoplasticism</td>\n",
       "      <td>NaN</td>\n",
       "      <td>test_only</td>\n",
       "      <td>False</td>\n",
       "      <td>32145.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>kiri nichol</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9003.0</td>\n",
       "      <td>9004.0</td>\n",
       "      <td>1942046.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Neoplasticism</td>\n",
       "      <td>NaN</td>\n",
       "      <td>test_only</td>\n",
       "      <td>False</td>\n",
       "      <td>20304.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>kiri nichol</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9003.0</td>\n",
       "      <td>9004.0</td>\n",
       "      <td>1526212.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Neoplasticism</td>\n",
       "      <td>NaN</td>\n",
       "      <td>test_only</td>\n",
       "      <td>False</td>\n",
       "      <td>836.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103245</th>\n",
       "      <td>Jackson Pollock</td>\n",
       "      <td>1948.0</td>\n",
       "      <td>abstract</td>\n",
       "      <td>682.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>96405.0</td>\n",
       "      <td>wikiart</td>\n",
       "      <td>Action painting</td>\n",
       "      <td>Number 13A (Arabesque)</td>\n",
       "      <td>train_and_test</td>\n",
       "      <td>True</td>\n",
       "      <td>25525.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103246</th>\n",
       "      <td>Bernardo Strozzi</td>\n",
       "      <td>NaN</td>\n",
       "      <td>religious painting</td>\n",
       "      <td>329.0</td>\n",
       "      <td>456.0</td>\n",
       "      <td>127594.0</td>\n",
       "      <td>wikiart</td>\n",
       "      <td>Baroque</td>\n",
       "      <td>St. Francis of Assisi</td>\n",
       "      <td>train_only</td>\n",
       "      <td>True</td>\n",
       "      <td>47038.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103247</th>\n",
       "      <td>Josef Sima</td>\n",
       "      <td>NaN</td>\n",
       "      <td>landscape</td>\n",
       "      <td>293.0</td>\n",
       "      <td>512.0</td>\n",
       "      <td>102519.0</td>\n",
       "      <td>wikiart</td>\n",
       "      <td>Surrealism</td>\n",
       "      <td>Maisons Ã  la campagne II</td>\n",
       "      <td>train_and_test</td>\n",
       "      <td>False</td>\n",
       "      <td>7680.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103248</th>\n",
       "      <td>Brett Whiteley</td>\n",
       "      <td>1982.0</td>\n",
       "      <td>marina</td>\n",
       "      <td>293.0</td>\n",
       "      <td>512.0</td>\n",
       "      <td>167423.0</td>\n",
       "      <td>wikiart</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Thebe's Revenge</td>\n",
       "      <td>train_and_test</td>\n",
       "      <td>True</td>\n",
       "      <td>9021.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103249</th>\n",
       "      <td>Amadeo de Souza-Cardoso</td>\n",
       "      <td>1913</td>\n",
       "      <td>landscape</td>\n",
       "      <td>293.0</td>\n",
       "      <td>512.0</td>\n",
       "      <td>77577.0</td>\n",
       "      <td>wikiart</td>\n",
       "      <td>Cubism</td>\n",
       "      <td>House Manhufe</td>\n",
       "      <td>train_only</td>\n",
       "      <td>True</td>\n",
       "      <td>36564.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>103240 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         artist    date               genre  pixelsx  pixelsy  \\\n",
       "0                Barnett Newman  1955.0            abstract  15530.0   6911.0   \n",
       "1                Barnett Newman  1950.0            abstract  14559.0   6866.0   \n",
       "2                   kiri nichol  2013.0                 NaN   9003.0   9004.0   \n",
       "3                   kiri nichol  2013.0                 NaN   9003.0   9004.0   \n",
       "4                   kiri nichol  2013.0                 NaN   9003.0   9004.0   \n",
       "...                         ...     ...                 ...      ...      ...   \n",
       "103245          Jackson Pollock  1948.0            abstract    682.0    220.0   \n",
       "103246         Bernardo Strozzi     NaN  religious painting    329.0    456.0   \n",
       "103247               Josef Sima     NaN           landscape    293.0    512.0   \n",
       "103248           Brett Whiteley  1982.0              marina    293.0    512.0   \n",
       "103249  Amadeo de Souza-Cardoso    1913           landscape    293.0    512.0   \n",
       "\n",
       "        size_bytes   source                 style                     title  \\\n",
       "0        9201912.0  wikiart  Color Field Painting                     Uriel   \n",
       "1        8867532.0  wikiart  Color Field Painting     Vir Heroicus Sublimis   \n",
       "2        1756681.0      NaN         Neoplasticism                       NaN   \n",
       "3        1942046.0      NaN         Neoplasticism                       NaN   \n",
       "4        1526212.0      NaN         Neoplasticism                       NaN   \n",
       "...            ...      ...                   ...                       ...   \n",
       "103245     96405.0  wikiart       Action painting    Number 13A (Arabesque)   \n",
       "103246    127594.0  wikiart               Baroque     St. Francis of Assisi   \n",
       "103247    102519.0  wikiart            Surrealism  Maisons Ã  la campagne II   \n",
       "103248    167423.0  wikiart                   NaN           Thebe's Revenge   \n",
       "103249     77577.0  wikiart                Cubism            House Manhufe    \n",
       "\n",
       "          artist_group  in_train new_filename  \n",
       "0           train_only      True   102257.jpg  \n",
       "1           train_only      True    75232.jpg  \n",
       "2            test_only     False    32145.jpg  \n",
       "3            test_only     False    20304.jpg  \n",
       "4            test_only     False      836.jpg  \n",
       "...                ...       ...          ...  \n",
       "103245  train_and_test      True    25525.jpg  \n",
       "103246      train_only      True    47038.jpg  \n",
       "103247  train_and_test     False     7680.jpg  \n",
       "103248  train_and_test      True     9021.jpg  \n",
       "103249      train_only      True    36564.jpg  \n",
       "\n",
       "[103240 rows x 12 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# quick fix for corrupted files\n",
    "list_of_corrupted = ['3917.jpg','18649.jpg','20153.jpg','41945.jpg','79499.jpg','91033.jpg','92899.jpg','95347.jpg','100532.jpg','101947.jpg']\n",
    "\n",
    "# completely get rid of them\n",
    "df = df[df[\"new_filename\"].isin(list_of_corrupted) == False]\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_df.shape (23814, 2)\n",
      "train_df.shape (79426, 2)\n",
      "\n",
      "number of artists: 71\n",
      "\n",
      "list of artists...\n",
      "['Ivan Aivazovsky', 'Gustave Dore', 'Utagawa Kuniyoshi', 'Odilon Redon', 'Henri de Toulouse-Lautrec', 'Konstantin Somov', 'Rembrandt', 'Ernst Ludwig Kirchner', 'Edgar Degas', 'Claude Monet', 'Theodor Severin Kittelsen', 'Albrecht Durer', 'Francisco Goya', 'Theophile Steinlen', 'Felix Vallotton ', 'Katsushika Hokusai', 'Ivan Shishkin', 'Giovanni Battista Piranesi', 'Camille Corot', 'Pierre-Auguste Renoir', 'Childe Hassam', 'Raphael Kirchner', 'James Tissot', 'Alfred Sisley', 'Paul Cezanne', 'John Singer Sargent', 'Peter Paul Rubens', 'Vasily Surikov', 'Vincent van Gogh', 'Jean Auguste Dominique Ingres', 'Zdislav Beksinski', 'Gustave Loiseau', 'David Burliuk', 'Camille Pissarro', 'Eugene Boudin', 'Gustave Courbet', 'Fernand Leger', 'Henri Fantin-Latour', 'Konstantin Yuon', 'Boris Kustodiev', 'Mary Cassatt', 'John Henry Twachtman', 'Nicholas Roerich', 'Amedeo Modigliani', 'Ilya Repin', 'William Merritt Chase', 'Martiros Saryan', 'Isaac Levitan', 'Egon Schiele', 'Pyotr Konchalovsky', 'M.C. Escher', 'Maurice Prendergast', 'Salvador Dali', 'Pablo Picasso', 'Konstantin Makovsky', 'Henri Matisse', 'Sam Francis', 'Rene Magritte', 'Max Ernst', 'Henri Martin', 'Marc Chagall', 'Erte', 'Albert Bierstadt', 'Konstantin Korovin', 'Lucian Freud', 'Paul Gauguin', 'Eyvind Earle', 'Samuel Peploe', 'Zinaida Serebriakova', 'Charles M. Russell', 'George Stefanescu-Ramnic ']\n"
     ]
    }
   ],
   "source": [
    "train_df = df[df[\"in_train\"] == True]\n",
    "test_df = df[df['in_train'] == False]\n",
    "train_df = train_df[['artist', 'new_filename']]\n",
    "test_df = test_df[['artist', 'new_filename']]\n",
    "\n",
    "print(\"test_df.shape\", test_df.shape)\n",
    "print(\"train_df.shape\", train_df.shape)\n",
    "\n",
    "artists = {} # holds artist hash & the count\n",
    "for a in train_df['artist']:\n",
    "    if (a not in artists):\n",
    "        artists[a] = 1\n",
    "    else:\n",
    "        artists[a] += 1\n",
    "# print(artists)\n",
    "\n",
    "training_set_artists = []\n",
    "for a, count in artists.items():\n",
    "    if(int(count) >= 200):\n",
    "        training_set_artists.append(a)\n",
    "\n",
    "print(\"\\nnumber of artists:\", len(training_set_artists))\n",
    "\n",
    "print(\"\\nlist of artists...\")\n",
    "print(training_set_artists)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>new_filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Ivan Aivazovsky</td>\n",
       "      <td>99442.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Gustave Dore</td>\n",
       "      <td>7486.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Gustave Dore</td>\n",
       "      <td>35766.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Utagawa Kuniyoshi</td>\n",
       "      <td>99733.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Utagawa Kuniyoshi</td>\n",
       "      <td>73690.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               artist new_filename\n",
       "14    Ivan Aivazovsky    99442.jpg\n",
       "28       Gustave Dore     7486.jpg\n",
       "29       Gustave Dore    35766.jpg\n",
       "49  Utagawa Kuniyoshi    99733.jpg\n",
       "50  Utagawa Kuniyoshi    73690.jpg"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_df = train_df[train_df[\"artist\"].isin(training_set_artists)]\n",
    "\n",
    "t_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>new_filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Ivan Aivazovsky</td>\n",
       "      <td>99442.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Utagawa Kuniyoshi</td>\n",
       "      <td>99733.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>Utagawa Kuniyoshi</td>\n",
       "      <td>93715.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>Edgar Degas</td>\n",
       "      <td>95360.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>Ernst Ludwig Kirchner</td>\n",
       "      <td>96372.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    artist new_filename\n",
       "14         Ivan Aivazovsky    99442.jpg\n",
       "49       Utagawa Kuniyoshi    99733.jpg\n",
       "51       Utagawa Kuniyoshi    93715.jpg\n",
       "147            Edgar Degas    95360.jpg\n",
       "168  Ernst Ludwig Kirchner    96372.jpg"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1_df = t_df[t_df['new_filename'].str.startswith('1')]\n",
    "\n",
    "t2_df = t_df[t_df['new_filename'].str.startswith('2')]\n",
    "\n",
    "t3_df = t_df[t_df['new_filename'].str.startswith('3')]\n",
    "\n",
    "t4_df = t_df[t_df['new_filename'].str.startswith('4')]\n",
    "\n",
    "t5_df = t_df[t_df['new_filename'].str.startswith('5')]\n",
    "\n",
    "t6_df = t_df[t_df['new_filename'].str.startswith('6')]\n",
    "\n",
    "t7_df = t_df[t_df['new_filename'].str.startswith('7')]\n",
    "\n",
    "t8_df = t_df[t_df['new_filename'].str.startswith('8')]\n",
    "\n",
    "t9_df = t_df[t_df['new_filename'].str.startswith('9')]\n",
    "\n",
    "all_train_dfs = [t1_df, t2_df, t3_df,\n",
    "                t4_df, t5_df, t6_df,\n",
    "                t7_df, t8_df, t9_df]\n",
    "\n",
    "t9_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications import ResNet50\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense, Flatten, GlobalAveragePooling2D\n",
    "\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# specify the model that classifies 38 artists ðŸŽ¨ ðŸ–Œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_set_artists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The `weights` argument should be either `None` (random initialization), 'imagenet' (pre-training on ImageNet), or the path to the weights file to be loaded.  Received: weights=../input/resnet50/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[59], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m weights_notop_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../input/resnet50/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      3\u001b[0m model \u001b[38;5;241m=\u001b[39m Sequential()\n\u001b[1;32m----> 4\u001b[0m model\u001b[38;5;241m.\u001b[39madd(\u001b[43mResNet50\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m  \u001b[49m\u001b[43minclude_top\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m  \u001b[49m\u001b[43mweights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweights_notop_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m  \u001b[49m\u001b[43mpooling\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mavg\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[0;32m      8\u001b[0m \u001b[43m)\u001b[49m)\n\u001b[0;32m      9\u001b[0m model\u001b[38;5;241m.\u001b[39madd(Dense(\n\u001b[0;32m     10\u001b[0m   num_classes,\n\u001b[0;32m     11\u001b[0m   activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msoftmax\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     12\u001b[0m ))\n\u001b[0;32m     14\u001b[0m model\u001b[38;5;241m.\u001b[39mlayers[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mtrainable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\keras\\src\\applications\\resnet.py:406\u001b[0m, in \u001b[0;36mResNet50\u001b[1;34m(include_top, weights, input_tensor, input_shape, pooling, classes, classifier_activation)\u001b[0m\n\u001b[0;32m    403\u001b[0m     x \u001b[38;5;241m=\u001b[39m stack_residual_blocks_v1(x, \u001b[38;5;241m256\u001b[39m, \u001b[38;5;241m6\u001b[39m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconv4\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    404\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m stack_residual_blocks_v1(x, \u001b[38;5;241m512\u001b[39m, \u001b[38;5;241m3\u001b[39m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconv5\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 406\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mResNet\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    407\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstack_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    408\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    409\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    410\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresnet50\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    411\u001b[0m \u001b[43m    \u001b[49m\u001b[43minclude_top\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    412\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    413\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_tensor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    414\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_shape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    415\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpooling\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    416\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclasses\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    417\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclassifier_activation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclassifier_activation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    418\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\keras\\src\\applications\\resnet.py:109\u001b[0m, in \u001b[0;36mResNet\u001b[1;34m(stack_fn, preact, use_bias, model_name, include_top, weights, input_tensor, input_shape, pooling, classes, classifier_activation)\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Instantiates the ResNet, ResNetV2, and ResNeXt architecture.\u001b[39;00m\n\u001b[0;32m     62\u001b[0m \n\u001b[0;32m     63\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    105\u001b[0m \u001b[38;5;124;03m    A Model instance.\u001b[39;00m\n\u001b[0;32m    106\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (weights \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimagenet\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m} \u001b[38;5;129;01mor\u001b[39;00m file_utils\u001b[38;5;241m.\u001b[39mexists(weights)):\n\u001b[1;32m--> 109\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    110\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe `weights` argument should be either \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    111\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`None` (random initialization), \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimagenet\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    112\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(pre-training on ImageNet), \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    113\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mor the path to the weights file to be loaded.  Received: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    114\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweights=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mweights\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    115\u001b[0m     )\n\u001b[0;32m    117\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m weights \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimagenet\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m include_top \u001b[38;5;129;01mand\u001b[39;00m classes \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1000\u001b[39m:\n\u001b[0;32m    118\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    119\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIf using `weights=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimagenet\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m` with `include_top=True`, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    120\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`classes` should be 1000.  \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    121\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReceived classes=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclasses\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    122\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: The `weights` argument should be either `None` (random initialization), 'imagenet' (pre-training on ImageNet), or the path to the weights file to be loaded.  Received: weights=../input/resnet50/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5"
     ]
    }
   ],
   "source": [
    "num_classes = len(training_set_artists) # one class per artist\n",
    "weights_notop_path = '../input/resnet50/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
    "model = Sequential()\n",
    "model.add(ResNet50(\n",
    "  include_top=False,\n",
    "  weights=weights_notop_path,\n",
    "  pooling='avg'\n",
    "))\n",
    "model.add(Dense(\n",
    "  num_classes,\n",
    "  activation='softmax'\n",
    "))\n",
    "\n",
    "model.layers[0].trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compile Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "  optimizer='adam', # lots of people reccommend Adam optimizer\n",
    "  loss='categorical_crossentropy', # aka \"log loss\" -- the cost function to minimize \n",
    "  # so 'optimizer' algorithm will minimize 'loss' function\n",
    "  metrics=['accuracy'] # ask it to report % of correct predictions\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Â setup the image data generator for each training directory "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model globals\n",
    "IMAGE_SIZE = 224\n",
    "BATCH_SIZE = 96\n",
    "TEST_BATCH_SIZE = 17 # because test has 23817 images and factors of 23817 are 3*17*467\n",
    "                     # it is important that this number evenly divides the total num images \n",
    "VAL_SPLIT = 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_generators(\n",
    "    val_split, train_dataframe, train_dir,\n",
    "    img_size, batch_size, my_seed, list_of_classes,\n",
    "    test_dataframe, test_dir, test_batch_size\n",
    "):\n",
    "    print(\"-\"*20)\n",
    "    if not preprocess_input:\n",
    "          raise Exception(\"please do import call 'from tensorflow.python.keras.applications.resnet50 import preprocess_input'\")\n",
    "\n",
    "    # setup resnet50 preprocessing \n",
    "    data_gen = ImageDataGenerator(\n",
    "        preprocessing_function=preprocess_input,\n",
    "        validation_split=val_split)\n",
    "\n",
    "    print(len(train_dataframe), \"images in\", train_dir, \"and validation_split =\", val_split)\n",
    "    print(\"\\ntraining set ImageDataGenerator\")\n",
    "    train_gen = data_gen.flow_from_dataframe(\n",
    "        dataframe=train_dataframe.reset_index(), # call reset_index() so keras can start with index 0\n",
    "        directory=train_dir,\n",
    "        x_col='new_filename',\n",
    "        y_col='artist',\n",
    "        has_ext=True,\n",
    "        target_size=(img_size, img_size),\n",
    "        subset=\"training\",\n",
    "        batch_size=batch_size,\n",
    "        seed=my_seed,\n",
    "        shuffle=True,\n",
    "        class_mode='categorical',\n",
    "        classes=list_of_classes\n",
    "    )\n",
    "\n",
    "    print(\"\\nvalidation set ImageDataGenerator\")\n",
    "    valid_gen = data_gen.flow_from_dataframe(\n",
    "        dataframe=train_dataframe.reset_index(), # call reset_index() so keras can start with index 0\n",
    "        directory=train_dir,\n",
    "        x_col='new_filename',\n",
    "        y_col='artist',\n",
    "        has_ext=True,\n",
    "        subset=\"validation\",\n",
    "        batch_size=batch_size,\n",
    "        seed=my_seed,\n",
    "        shuffle=True,\n",
    "        target_size=(img_size,img_size),\n",
    "        class_mode='categorical',\n",
    "        classes=list_of_classes\n",
    "    )\n",
    "\n",
    "    test_data_gen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "    print(\"\\ntest set ImageDataGenerator\")\n",
    "    test_gen = test_data_gen.flow_from_dataframe(\n",
    "        dataframe=test_dataframe.reset_index(), # call reset_index() so keras can start with index 0\n",
    "        directory=test_dir,\n",
    "        x_col='new_filename',\n",
    "        y_col=None,\n",
    "        has_ext=True,\n",
    "        batch_size=test_batch_size,\n",
    "        seed=my_seed,\n",
    "        shuffle=False, # dont shuffle test directory\n",
    "        class_mode=None,\n",
    "        target_size=(img_size,img_size)\n",
    "    )\n",
    "\n",
    "    return (train_gen, valid_gen, test_gen)\n",
    "\n",
    "print(\"defined setup_generators()\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete some unused dataframes to free some RAM for training\n",
    "del df\n",
    "del t_df\n",
    "del t1_df\n",
    "del t2_df\n",
    "del t3_df\n",
    "del t4_df\n",
    "del t5_df\n",
    "del t6_df\n",
    "del t7_df\n",
    "del t8_df\n",
    "del t9_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gens = [None]*len(TRAIN_DIRS)\n",
    "valid_gens = [None]*len(TRAIN_DIRS)\n",
    "test_gen  = None # only 1 test_gen\n",
    "i = 0\n",
    "for i in range(0, len(TRAIN_DIRS)):\n",
    "    train_gens[i], valid_gens[i], test_gen = setup_generators(\n",
    "        train_dataframe=all_train_dfs[i], train_dir=TRAIN_DIRS[i],\n",
    "        val_split=VAL_SPLIT, img_size=IMAGE_SIZE, batch_size=BATCH_SIZE, my_seed=MY_SEED, \n",
    "        list_of_classes=training_set_artists, test_dataframe=test_df, \n",
    "        test_dir=TEST_DIR, test_batch_size=TEST_BATCH_SIZE\n",
    "    )\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAINING TIME!  ðŸŽ‰ ðŸŽŠ ðŸŽ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_EPOCHS = 5 * len(train_gens) # should be a multiple of 9 because need evenly train each train_dir\n",
    "DIR_EPOCHS = 1 # fit each train_dir at least this many times before overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histories = []\n",
    "\n",
    "e=0\n",
    "while ( e < MAX_EPOCHS):\n",
    "    for i in range(0, len(train_gens)):\n",
    "        # train_gen.n = number of images for training\n",
    "        STEP_SIZE_TRAIN = train_gens[i].n//train_gens[i].batch_size\n",
    "        # train_gen.n = number of images for validation\n",
    "        STEP_SIZE_VALID = valid_gens[i].n//valid_gens[i].batch_size\n",
    "        print(\"STEP_SIZE_TRAIN\",STEP_SIZE_TRAIN)\n",
    "        print(\"STEP_SIZE_VALID\",STEP_SIZE_VALID)\n",
    "        histories.append(\n",
    "            model.fit_generator(generator=train_gens[i],\n",
    "                                steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "                                validation_data=valid_gens[i],\n",
    "                                validation_steps=STEP_SIZE_VALID,\n",
    "                                epochs=DIR_EPOCHS)\n",
    "        )\n",
    "        e+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the model ðŸ§ ðŸ¤”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies = []\n",
    "val_accuracies = []\n",
    "losses = []\n",
    "val_losses = []\n",
    "for hist in histories:\n",
    "    if hist:\n",
    "        accuracies += hist.history['acc']\n",
    "        val_accuracies += hist.history['val_acc']\n",
    "        losses += hist.history['loss']\n",
    "        val_losses += hist.history['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training & validation accuracy values\n",
    "plt.plot(accuracies)\n",
    "plt.plot(val_accuracies)\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.plot(losses)\n",
    "plt.plot(val_losses)\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "timestr = time.strftime(\"%Y%m%d-%H%M%S\") # e.g: 20181109-180140\n",
    "model.save('painters_adam_e45_'+timestr+'.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict the output ðŸ”® ðŸŽ©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRED_STEPS = len(test_gen) #100 # default would have been len(test_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to reset the test_gen before calling predict_generator\n",
    "# This is important because forgetting to reset the test_generator results in outputs with a weird order.\n",
    "test_gen.reset()\n",
    "pred=model.predict_generator(test_gen, verbose=1, steps=PRED_STEPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(pred),\"\\n\",pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_class_indices=np.argmax(pred,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(predicted_class_indices),\"\\n\",predicted_class_indices)\n",
    "print(\"it has values ranging from \",min(predicted_class_indices),\"...to...\",max(predicted_class_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = (train_gens[0].class_indices)\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "predictions = [labels[k] for k in predicted_class_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"*\"*20+\"\\nclass_indices\\n\"+\"*\"*20+\"\\n\",train_gens[0].class_indices,\"\\n\")\n",
    "print(\"*\"*20+\"\\nlabels\\n\"+\"*\"*20+\"\\n\",labels,\"\\n\")\n",
    "print(\"*\"*20+\"\\npredictions has\", len(predictions),\"values that look like\",\"'\"+str(predictions[0])+\"' which is the first prediction and corresponds to this index of the classes:\",train_gens[0].class_indices[predictions[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the results to a CSV file.\n",
    "filenames=test_gen.filenames[:len(predictions)] # because \"ValueError: arrays must all be same length\"\n",
    "\n",
    "real_artists = []\n",
    "for f in filenames:\n",
    "    real = test_df[test_df['new_filename'] == f].artist.get_values()[0]\n",
    "    real_artists.append(real)\n",
    "\n",
    "results=pd.DataFrame({\"Filename\":filenames,\n",
    "                      \"Predictions\":predictions,\n",
    "                      \"Real Values\":real_artists})\n",
    "results.to_csv(\"results.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(training_set_artists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(training_set_artists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "match = 0\n",
    "unexpected_count = 0\n",
    "unexpected_match = 0\n",
    "match_both_expected_unexpected = 0\n",
    "\n",
    "for p, r in zip(results['Predictions'], results['Real Values']):\n",
    "    if r in training_set_artists:\n",
    "        count += 1\n",
    "        if p == r:\n",
    "            match += 1\n",
    "    else:\n",
    "        unexpected_count += 1\n",
    "        if p == r:\n",
    "            unexpected_match += 1\n",
    "\n",
    "print(\"test accuracy on new images for TRAINED artsits\")\n",
    "acc = match/count\n",
    "print(match,\"/\",count,\"=\",\"{:.4f}\".format(acc))\n",
    "\n",
    "print(\"test accuracy on new images for UNEXPECTED artsits\")\n",
    "u_acc = unexpected_match/unexpected_count\n",
    "print(unexpected_match,\"/\",unexpected_count,\"=\",\"{:.4f}\".format(u_acc))\n",
    "\n",
    "print(\"test accuracy on new images\")\n",
    "total_match = match+unexpected_match\n",
    "total_count = count+unexpected_count\n",
    "total_acc = (total_match)/(total_count)\n",
    "print(total_match,\"/\",total_count,\"=\",\"{:.4f}\".format(total_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, it seems like the model may have learned some interesting patterns related to the artists that it expects. \n",
    "\n",
    "**Questions to explore:**\n",
    "* [What does the model actually \"see\"](https://arxiv.org/abs/1312.6034) in a painting by [Pablo Picasso](https://www.wikiart.org/en/pablo-picasso/) as opposed to [Vincent van Gogh](https://www.wikiart.org/en/vincent-van-gogh)?\n",
    "* What would happen if we trained the model on the full artist dataset or at least on artists with over 200 paintings in the dataset?\n",
    "* Can the accuracy be improved with techniques like data augmentation or with a custom convolutional neural network? How about doing transfer learning with different [pre-trained model](https://keras.io/applications)?\n",
    "* How can the learning rate be tuned to improve the accuracy?\n",
    "* Would a regularization technique like [dropout](https://machinelearningmastery.com/dropout-regularization-deep-learning-models-keras/) be helpful?\n",
    "* This notebook uses the [Adam](https://keras.io/optimizers/#adam) optimizer... what if we tried RMSprop?\n",
    "* How about using an [ensemble of models](https://machinelearningmastery.com/ensemble-machine-learning-algorithms-python-scikit-learn/)?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
