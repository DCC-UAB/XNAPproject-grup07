{"cells":[{"cell_type":"markdown","metadata":{"_uuid":"969bd0a45cfbe4f4804ac2f920de35cbbc7bf1a8"},"source":["# Overview\n","\n","Can a computer \"learn\" to classify artists by their paintings? \n","\n","ResNet50 is a good model for classifying ImageNet data. How about a set of 38 artists?\n","\n","We use transfer learning to re-train a ResNet50 model to identify one of 38 artists who have more than ~~300~~ ***200*** paintings in the dataset. \n","\n","This notebook is part of a project for CSC 480 taught by [Dr. Franz J. Kurfess](http://users.csc.calpoly.edu/~fkurfess/) at Cal Poly\n","\n","A web application is [in development](https://github.com/SomethingAboutImages/WebImageClassifier) to make use of the model that this notebook outputs. "]},{"cell_type":"code","execution_count":4,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":false,"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","scrolled":true,"trusted":true},"outputs":[],"source":["import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","%matplotlib inline\n","import matplotlib.pyplot as plt\n","from random import seed # for setting seed\n","import tensorflow\n","from IPython import sys_info\n","\n","import gc # garbage collection"]},{"cell_type":"code","execution_count":5,"metadata":{"_uuid":"4cd71d6411b0bb2bee9d5a9f2421f8310509e008","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["{'commit_hash': '37242ba43',\n"," 'commit_source': 'installation',\n"," 'default_encoding': 'utf-8',\n"," 'ipython_path': '/anaconda/envs/azureml_py38_PT_and_TF/lib/python3.8/site-packages/IPython',\n"," 'ipython_version': '8.12.0',\n"," 'os_name': 'posix',\n"," 'platform': 'Linux-5.15.0-1061-azure-x86_64-with-glibc2.10',\n"," 'sys_executable': '/anaconda/envs/azureml_py38_PT_and_TF/bin/python',\n"," 'sys_platform': 'linux',\n"," 'sys_version': '3.8.5 (default, Sep  4 2020, 07:30:14) \\n[GCC 7.3.0]'}\n"]}],"source":["MY_SEED = 42 # 480 could work too\n","seed(MY_SEED)\n","np.random.seed(MY_SEED)\n","tensorflow.random.set_seed(MY_SEED)\n","\n","print(sys_info())\n","# get module information\n","!pip freeze > frozen-requirements.txt\n","# append system information to file\n","with open(\"frozen-requirements.txt\", \"a\") as file:\n","    file.write(sys_info())"]},{"cell_type":"code","execution_count":6,"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"_uuid":"6bab4e1e53b22a9af9908fbefaeaa6f0e8b1110d","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["[name: \"/device:CPU:0\"\n","device_type: \"CPU\"\n","memory_limit: 268435456\n","locality {\n","}\n","incarnation: 7910028659058601276\n","xla_global_id: -1\n",", name: \"/device:GPU:0\"\n","device_type: \"GPU\"\n","memory_limit: 15247015936\n","locality {\n","  bus_id: 1\n","  links {\n","  }\n","}\n","incarnation: 3411629076494569092\n","physical_device_desc: \"device: 0, name: Tesla V100-PCIE-16GB, pci bus id: 0001:00:00.0, compute capability: 7.0\"\n","xla_global_id: 416903419\n","]\n"]},{"name":"stderr","output_type":"stream","text":["2024-05-09 14:56:21.599741: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-05-09 14:56:31.098864: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /device:GPU:0 with 14540 MB memory:  -> device: 0, name: Tesla V100-PCIE-16GB, pci bus id: 0001:00:00.0, compute capability: 7.0\n"]}],"source":["from tensorflow.python.client import device_lib\n","# print out the CPUs and GPUs\n","print(device_lib.list_local_devices())"]},{"cell_type":"code","execution_count":7,"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"_uuid":"1caeac96229a1e6db1d07b316cbfe62e1ee858d7","trusted":true},"outputs":[],"source":["# https://stackoverflow.com/questions/25705773/image-cropping-tool-python\n","# because painting images are hella big\n","from PIL import Image\n","Image.MAX_IMAGE_PIXELS = None"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"ca219817e229ad5e947b9a53a6bc9626cc7e2e02","trusted":true},"outputs":[],"source":["# globals\n","\n","DATA_DIR = '../input/painters-train-part-1/'\n","\n","TRAIN_1_DIR = '../input/painters-train-part-1/train_1/train_1/'\n","# TRAIN_2_DIR = '../input/painters-train-part-1/train_2/train_2/'\n","# TRAIN_3_DIR = '../input/painters-train-part-1/train_3/train_3/'\n","\n","# TRAIN_4_DIR = '../input/painters-train-part-2/train_4/train_4/'\n","# TRAIN_5_DIR = '../input/painters-train-part-2/train_5/train_5/'\n","# TRAIN_6_DIR = '../input/painters-train-part-2/train_6/train_6/'\n","\n","# TRAIN_7_DIR = '../input/painters-train-part-3/train_7/train_7/'\n","# TRAIN_8_DIR = '../input/painters-train-part-3/train_8/train_8/'\n","# TRAIN_9_DIR = '../input/painters-train-part-3/train_9/train_9/'\n","\n","# TRAIN_DIRS = [TRAIN_1_DIR, TRAIN_2_DIR, TRAIN_3_DIR,\n","#              TRAIN_4_DIR, TRAIN_5_DIR, TRAIN_6_DIR,\n","#              TRAIN_7_DIR, TRAIN_8_DIR, TRAIN_9_DIR]\n","\n","TEST_DIR = '../input/painter-test/test/test/'"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true,"_uuid":"8946b27facacf6814c81f06c53d34f8be7e5c53f","trusted":true},"outputs":[],"source":["df = pd.read_csv(DATA_DIR + 'all_data_info.csv')\n","print(\"df.shape\", df.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"_uuid":"8aa0abdf69b880c834752ab85206dfcb6fef38d9","trusted":true},"outputs":[],"source":["# quick fix for corrupted files\n","list_of_corrupted = ['3917.jpg','18649.jpg','20153.jpg','41945.jpg',\n","'79499.jpg','91033.jpg','92899.jpg','95347.jpg',\n","'100532.jpg','101947.jpg']\n","# display the corrupted rows of dataset for context\n","corrupt_df = df[df[\"new_filename\"].isin(list_of_corrupted) == True]\n","print(corrupt_df.head(len(list_of_corrupted)))\n","\n","# completely get rid of them\n","df = df[df[\"new_filename\"].isin(list_of_corrupted) == False]\n","\n","# try to see if they are still there\n","print(df[df[\"new_filename\"].isin(list_of_corrupted) == True])\n","\n","print(\"df.shape\", df.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_kg_hide-input":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"outputs":[],"source":["\n","train_df = df[df[\"in_train\"] == True]\n","test_df = df[df['in_train'] == False]\n","train_df = train_df[['artist', 'new_filename']]\n","test_df = test_df[['artist', 'new_filename']]\n","\n","print(\"test_df.shape\", test_df.shape)\n","print(\"train_df.shape\", train_df.shape)\n","\n","artists = {} # holds artist hash & the count\n","for a in train_df['artist']:\n","    if (a not in artists):\n","        artists[a] = 1\n","    else:\n","        artists[a] += 1\n","\n","training_set_artists = []\n","for a,count in artists.items():\n","    if(int(count) >= 200):\n","        training_set_artists.append(a)\n","\n","print(\"number of artsits\",len(training_set_artists))\n","\n","print(\"\\nlist of artists...\\n\", training_set_artists)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true,"_uuid":"374cf6e0025c7221bbd1973c88f3702158e38c3f","trusted":true},"outputs":[],"source":["t_df = train_df[train_df[\"artist\"].isin(training_set_artists)]\n","\n","t_df.head(5)"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true,"_uuid":"b44f0b775da104dd716f4601cc164e7c4284bcec","trusted":true},"outputs":[],"source":["t1_df = t_df[t_df['new_filename'].str.startswith('1')]\n","\n","t2_df = t_df[t_df['new_filename'].str.startswith('2')]\n","\n","t3_df = t_df[t_df['new_filename'].str.startswith('3')]\n","\n","t4_df = t_df[t_df['new_filename'].str.startswith('4')]\n","\n","t5_df = t_df[t_df['new_filename'].str.startswith('5')]\n","\n","t6_df = t_df[t_df['new_filename'].str.startswith('6')]\n","\n","t7_df = t_df[t_df['new_filename'].str.startswith('7')]\n","\n","t8_df = t_df[t_df['new_filename'].str.startswith('8')]\n","\n","t9_df = t_df[t_df['new_filename'].str.startswith('9')]\n","\n","all_train_dfs = [t1_df, t2_df, t3_df,\n","                t4_df, t5_df, t6_df,\n","                t7_df, t8_df, t9_df]\n","\n","t9_df.head(5)"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":false,"_kg_hide-output":false,"_uuid":"9f35f9102dabe4fd4c05d9b4da88929811c574cd","trusted":true},"outputs":[],"source":["from tensorflow.python.keras.applications import ResNet50\n","from tensorflow.python.keras.models import Sequential\n","from tensorflow.python.keras.layers import Dense, Flatten, GlobalAveragePooling2D\n","\n","from tensorflow.python.keras.applications.resnet50 import preprocess_input\n","from tensorflow.python.keras.preprocessing.image import ImageDataGenerator\n"]},{"cell_type":"markdown","metadata":{"_uuid":"30506b48fd6f5fd2636520b60baed80e20b8b944"},"source":["# specify the model that classifies 38 artists 🎨 🖌"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"e74625505706e025d7981c6712d21861f3ff6407","trusted":true},"outputs":[],"source":["len(training_set_artists)"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"d3222704a8161b0530f4df9911acbbc54ce97039","trusted":true},"outputs":[],"source":["num_classes = len(training_set_artists) # one class per artist\n","weights_notop_path = '../input/resnet50/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5'\n","model_adam = Sequential()\n","model_adam.add(ResNet50(\n","  include_top=False,\n","  weights=weights_notop_path,\n","  pooling='avg'\n","))\n","model_adam.add(Dense(\n","  num_classes,\n","  activation='softmax'\n","))\n","\n","model_adam.layers[0].trainable = False"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model_sgd = Sequential()\n","model_sgd.add(ResNet50(\n","  include_top=False,\n","  weights=weights_notop_path,\n","  pooling='avg'\n","))\n","model_sgd.add(Dense(\n","  num_classes,\n","  activation='softmax'\n","))\n","\n","model_sgd.layers[0].trainable = False"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model_RMS = Sequential()\n","model_RMS.add(ResNet50(\n","  include_top=False,\n","  weights=weights_notop_path,\n","  pooling='avg'\n","))\n","model_RMS.add(Dense(\n","  num_classes,\n","  activation='softmax'\n","))\n","\n","model_RMS.layers[0].trainable = False"]},{"cell_type":"markdown","metadata":{"_uuid":"b14546c60c000f6f763d7ef225c2d5bb9bad75ee"},"source":["# Compile Model"]},{"cell_type":"markdown","metadata":{},"source":["## Adam"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"431d98d4322666bf0995dd65e7370e8e8d3ff36e","trusted":true},"outputs":[],"source":["model_adam.compile(\n","  optimizer='adam', # lots of people reccommend Adam optimizer\n","  loss='categorical_crossentropy', # aka \"log loss\" -- the cost function to minimize \n","  # so 'optimizer' algorithm will minimize 'loss' function\n","  metrics=['accuracy'] # ask it to report % of correct predictions\n",")"]},{"cell_type":"markdown","metadata":{},"source":["**Observation**\n","para un problema de clasificación binaria, a menudo se utiliza la 'entropía cruzada binaria', mientras que la 'entropía cruzada categórica' se utiliza para la clasificación de clases múltiples.\n","https://www.sourcetrail.com/es/pit%C3%B3n/keras/modelo-compilar-keras/"]},{"cell_type":"markdown","metadata":{},"source":["## SGD"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model_sgd.compile(\n","  optimizer='sgd', # lots of people reccommend Adam optimizer\n","  loss='categorical_crossentropy', # aka \"log loss\" -- the cost function to minimize \n","  # so 'optimizer' algorithm will minimize 'loss' function\n","  metrics=['accuracy'] # ask it to report % of correct predictions\n",")"]},{"cell_type":"markdown","metadata":{},"source":["## RMSprop"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model_RMS.compile(optimizer ='RMSprop', \n","              loss ='binary_crossentropy', \n","              metrics =['accuracy'])"]},{"cell_type":"markdown","metadata":{"_uuid":"7e00f7674040ad997d2e3c67d8e61b7f214e3709"},"source":["# Setup the image data generator for each training directory "]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"c8005d5e86576cebc2b0fa0034ca2baed91c6de1","trusted":true},"outputs":[],"source":["# model globals\n","IMAGE_SIZE = 224\n","BATCH_SIZE = 96\n","TEST_BATCH_SIZE = 17 # because test has 23817 images and factors of 23817 are 3*17*467\n","                     # it is important that this number evenly divides the total num images \n","VAL_SPLIT = 0.25"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"_uuid":"6d229aed54ae275e7cff6382f3500a4ad21e4701","trusted":true},"outputs":[],"source":["def setup_generators(\n","    val_split, train_dataframe, train_dir,\n","    img_size, batch_size, my_seed, list_of_classes,\n","    test_dataframe, test_dir, test_batch_size\n","):\n","    print(\"-\"*20)\n","    if not preprocess_input:\n","          raise Exception(\"please do import call 'from tensorflow.python.keras.applications.resnet50 import preprocess_input'\")\n","\n","    # setup resnet50 preprocessing \n","    data_gen = ImageDataGenerator(\n","        preprocessing_function=preprocess_input,\n","        validation_split=val_split)\n","\n","    print(len(train_dataframe), \"images in\", train_dir, \"and validation_split =\", val_split)\n","    print(\"\\ntraining set ImageDataGenerator\")\n","    train_gen = data_gen.flow_from_dataframe(\n","        dataframe=train_dataframe.reset_index(), # call reset_index() so keras can start with index 0\n","        directory=train_dir,\n","        x_col='new_filename',\n","        y_col='artist',\n","        has_ext=True,\n","        target_size=(img_size, img_size),\n","        subset=\"training\",\n","        batch_size=batch_size,\n","        seed=my_seed,\n","        shuffle=True,\n","        class_mode='categorical',\n","        classes=list_of_classes\n","    )\n","\n","    print(\"\\nvalidation set ImageDataGenerator\")\n","    valid_gen = data_gen.flow_from_dataframe(\n","        dataframe=train_dataframe.reset_index(), # call reset_index() so keras can start with index 0\n","        directory=train_dir,\n","        x_col='new_filename',\n","        y_col='artist',\n","        has_ext=True,\n","        subset=\"validation\",\n","        batch_size=batch_size,\n","        seed=my_seed,\n","        shuffle=True,\n","        target_size=(img_size,img_size),\n","        class_mode='categorical',\n","        classes=list_of_classes\n","    )\n","\n","    test_data_gen = ImageDataGenerator(preprocessing_function=preprocess_input)\n","\n","    print(\"\\ntest set ImageDataGenerator\")\n","    test_gen = test_data_gen.flow_from_dataframe(\n","        dataframe=test_dataframe.reset_index(), # call reset_index() so keras can start with index 0\n","        directory=test_dir,\n","        x_col='new_filename',\n","        y_col=None,\n","        has_ext=True,\n","        batch_size=test_batch_size,\n","        seed=my_seed,\n","        shuffle=False, # dont shuffle test directory\n","        class_mode=None,\n","        target_size=(img_size,img_size)\n","    )\n","\n","    return (train_gen, valid_gen, test_gen)\n","\n","print(\"defined setup_generators()\")"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true,"_uuid":"b899ca31427b36e183abfbc897caa05ca6102e05","trusted":true},"outputs":[],"source":["# delete some unused dataframes to free some RAM for training\n","del df\n","del t_df\n","del t1_df\n","del t2_df\n","del t3_df\n","del t4_df\n","del t5_df\n","del t6_df\n","del t7_df\n","del t8_df\n","del t9_df\n","gc.collect()"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-output":true,"_uuid":"906343b306f3d44981bc0693ed5185d8e2fdb446","trusted":true},"outputs":[],"source":["train_gens = [None]*len(TRAIN_DIRS)\n","valid_gens = [None]*len(TRAIN_DIRS)\n","test_gen  = None # only 1 test_gen\n","i = 0\n","for i in range(0, len(TRAIN_DIRS)):\n","    train_gens[i], valid_gens[i], test_gen = setup_generators(\n","        train_dataframe=all_train_dfs[i], train_dir=TRAIN_DIRS[i],\n","        val_split=VAL_SPLIT, img_size=IMAGE_SIZE, batch_size=BATCH_SIZE, my_seed=MY_SEED, \n","        list_of_classes=training_set_artists, test_dataframe=test_df, \n","        test_dir=TEST_DIR, test_batch_size=TEST_BATCH_SIZE\n","    )\n","    i += 1"]},{"cell_type":"markdown","metadata":{"_uuid":"d7978eabacec7bf8c313d1fda177d876a2a38cc1"},"source":["# TRAINING TIME!  🎉 🎊 🎁"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"31f15a418cd7e0550700645090e006d3438c4f59","trusted":true},"outputs":[],"source":["MAX_EPOCHS = 5 * len(train_gens) # should be a multiple of 9 because need evenly train each train_dir\n","DIR_EPOCHS = 1 # fit each train_dir at least this many times before overfitting"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-output":true,"_uuid":"71704f10dbbf6803e03934be1f3ac8de05d878f4","trusted":true},"outputs":[],"source":["histories_adam = []\n","\n","e=0\n","while ( e < MAX_EPOCHS):\n","    for i in range(0, len(train_gens)):\n","        # train_gen.n = number of images for training\n","        STEP_SIZE_TRAIN = train_gens[i].n//train_gens[i].batch_size\n","        # train_gen.n = number of images for validation\n","        STEP_SIZE_VALID = valid_gens[i].n//valid_gens[i].batch_size\n","        print(\"STEP_SIZE_TRAIN\",STEP_SIZE_TRAIN)\n","        print(\"STEP_SIZE_VALID\",STEP_SIZE_VALID)\n","        histories_adam.append(\n","            model_adam.fit_generator(generator=train_gens[i],\n","                                steps_per_epoch=STEP_SIZE_TRAIN,\n","                                validation_data=valid_gens[i],\n","                                validation_steps=STEP_SIZE_VALID,\n","                                epochs=DIR_EPOCHS)\n","        )\n","        e+=1"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["histories_sgd = []\n","\n","e=0\n","while ( e < MAX_EPOCHS):\n","    for i in range(0, len(train_gens)):\n","        # train_gen.n = number of images for training\n","        STEP_SIZE_TRAIN = train_gens[i].n//train_gens[i].batch_size\n","        # train_gen.n = number of images for validation\n","        STEP_SIZE_VALID = valid_gens[i].n//valid_gens[i].batch_size\n","        print(\"STEP_SIZE_TRAIN\",STEP_SIZE_TRAIN)\n","        print(\"STEP_SIZE_VALID\",STEP_SIZE_VALID)\n","        histories_sgd.append(\n","            model_sgd.fit_generator(generator=train_gens[i],\n","                                steps_per_epoch=STEP_SIZE_TRAIN,\n","                                validation_data=valid_gens[i],\n","                                validation_steps=STEP_SIZE_VALID,\n","                                epochs=DIR_EPOCHS)\n","        )\n","        e+=1"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["histories_RMS = []\n","\n","e=0\n","while ( e < MAX_EPOCHS):\n","    for i in range(0, len(train_gens)):\n","        # train_gen.n = number of images for training\n","        STEP_SIZE_TRAIN = train_gens[i].n//train_gens[i].batch_size\n","        # train_gen.n = number of images for validation\n","        STEP_SIZE_VALID = valid_gens[i].n//valid_gens[i].batch_size\n","        print(\"STEP_SIZE_TRAIN\",STEP_SIZE_TRAIN)\n","        print(\"STEP_SIZE_VALID\",STEP_SIZE_VALID)\n","        histories_sgd.append(\n","            model_RMS.fit_generator(generator=train_gens[i],\n","                                steps_per_epoch=STEP_SIZE_TRAIN,\n","                                validation_data=valid_gens[i],\n","                                validation_steps=STEP_SIZE_VALID,\n","                                epochs=DIR_EPOCHS)\n","        )\n","        e+=1"]},{"cell_type":"markdown","metadata":{"_uuid":"3a05218bcf6f36b56519fd3091b182c2efd756a9"},"source":["# Evaluate the model 🧐 🤔"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true,"_uuid":"30f09ae79b59fbec2375dd5eadee5c1af61dbb03","trusted":true},"outputs":[],"source":["accuracies_adam = []\n","val_accuracies_adam = []\n","losses_adam = []\n","val_losses_adam = []\n","for hist in histories_adam:\n","    if hist:\n","        accuracies_adam += hist.history['acc']\n","        val_accuracies_adam += hist.history['val_acc']\n","        losses_adam += hist.history['loss']\n","        val_losses_adam += hist.history['val_loss']"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["accuracies_sgd = []\n","val_accuracies_sgd = []\n","losses_sgd = []\n","val_losses_sgd = []\n","for hist in histories_sgd:\n","    if hist:\n","        accuracies_sgd += hist.history['acc']\n","        val_accuracies_sgd += hist.history['val_acc']\n","        losses_sgd += hist.history['loss']\n","        val_losses_sgd += hist.history['val_loss']"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["accuracies_RMS = []\n","val_accuracies_RMS = []\n","losses_RMS = []\n","val_losses_RMS = []\n","for hist in histories_RMS:\n","    if hist:\n","        accuracies_RMS += hist.history['acc']\n","        val_accuracies_RMS += hist.history['val_acc']\n","        losses_RMS += hist.history['loss']\n","        val_losses_RMS += hist.history['val_loss']"]},{"cell_type":"markdown","metadata":{},"source":["## Plots\n","### Accuracies"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true,"_uuid":"b2b8b4d7f244b57cc3df0fba829fb73a93da8d23","trusted":true},"outputs":[],"source":["# Plot training & validation accuracy values\n","plt.plot(accuracies_adam, label = \"Adam Train\")\n","plt.plot(val_accuracies_adam, label = \"Adam Test\")\n","\n","plt.plot(accuracies_sgd, label = \"SGD Train\")\n","plt.plot(val_accuracies_sgd, label = \"SGD Test\")\n","\n","plt.plot(accuracies_RMS, label = \"RMS Train\")\n","plt.plot(val_accuracies_RMS, label = \"RMS Test\")\n","\n","plt.title('Model accuracy')\n","plt.ylabel('Accuracy')\n","plt.xlabel('Epoch')\n","plt.legend()\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["### Loss values"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Plot training & validation loss values\n","plt.plot(losses_adam, label = \"Adam Train\")\n","plt.plot(val_losses_adam, label = \"Adam Test\")\n","\n","plt.plot(losses_sgd, label = \"SGD Train\")\n","plt.plot(val_losses_sgd, label = \"SGD Test\")\n","\n","plt.plot(losses_RMS, label = \"RMS Train\")\n","plt.plot(val_losses_RMS, label = \"RMS Test\")\n","\n","plt.title('Model loss')\n","plt.ylabel('Loss')\n","plt.xlabel('Epoch')\n","plt.legend()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"15433eaf26bb11ff67095ba0cbe781b62453a62a","trusted":true},"outputs":[],"source":["import time\n","timestr = time.strftime(\"%Y%m%d-%H%M%S\") # e.g: 20181109-180140\n","model_adam.save('painters_adam_e45_'+timestr+'.h5')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["timestr = time.strftime(\"%Y%m%d-%H%M%S\") # e.g: 20181109-180140\n","model_sgd.save('painters_SGD_e45_'+timestr+'.h5')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["timestr = time.strftime(\"%Y%m%d-%H%M%S\") # e.g: 20181109-180140\n","model_RMS.save('painters_RMS_e45_'+timestr+'.h5')"]},{"cell_type":"markdown","metadata":{"_uuid":"2fa3ebde72fb64279bc367da190783f2524d2bad"},"source":["# Predict the output 🔮 🎩"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"160deb675d28625a391b3760ffa105e2272bb023","trusted":true},"outputs":[],"source":["PRED_STEPS = len(test_gen) #100 # default would have been len(test_gen)"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"98425b4ae320934e1ef68b50ea34deac31c284ab","trusted":true},"outputs":[],"source":["# Need to reset the test_gen before calling predict_generator\n","# This is important because forgetting to reset the test_generator results in outputs with a weird order.\n","test_gen.reset()\n","pred_adam = model_adam.predict_generator(test_gen, verbose=1, steps=PRED_STEPS)"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-output":true,"_uuid":"3bcf77f568962e91f1245ed77b00c5746ad4b48e","trusted":true},"outputs":[],"source":["print(len(pred_adam),\"\\n\",pred_adam)"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"dfb50c45a54612d6b6a0210d3f2c00f999bc1b52","trusted":true},"outputs":[],"source":["predicted_class_indices_adam = np.argmax(pred_adam,axis=1)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def retrieve_results(predicted_class_indices, train_gens):\n","    print(len(predicted_class_indices),\"\\n\",predicted_class_indices)\n","    print(\"it has values ranging from \",min(predicted_class_indices),\"...to...\",max(predicted_class_indices))\n","    labels = (train_gens[0].class_indices)\n","    labels = dict((v,k) for k,v in labels.items())\n","    predictions = [labels[k] for k in predicted_class_indices]\n","    print(\"*\"*20+\"\\nclass_indices\\n\"+\"*\"*20+\"\\n\",train_gens[0].class_indices,\"\\n\")\n","    print(\"*\"*20+\"\\nlabels\\n\"+\"*\"*20+\"\\n\",labels,\"\\n\")\n","    print(\"*\"*20+\"\\npredictions has\", len(predictions),\"values that look like\",\"'\"+str(predictions[0])+\"' which is the first prediction and corresponds to this index of the classes:\",train_gens[0].class_indices[predictions[0]])\n","    # Save the results to a CSV file.\n","    filenames=test_gen.filenames[:len(predictions)] # because \"ValueError: arrays must all be same length\"\n","\n","    real_artists = []\n","    for f in filenames:\n","        real = test_df[test_df['new_filename'] == f].artist.get_values()[0]\n","        real_artists.append(real)\n","\n","    results=pd.DataFrame({\"Filename\":filenames,\n","                        \"Predictions\":predictions,\n","                        \"Real Values\":real_artists})\n","    results.to_csv(\"results.csv\",index=False)\n","\n","    return results"]},{"cell_type":"markdown","metadata":{},"source":["## Adam"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["results_adam = retrieve_results(predicted_class_indices_adam, train_gens)"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"4acad3f61b891c2551a657ca242e6ee267919343","trusted":true},"outputs":[],"source":["results_adam.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"69605197bb4b01b272bccab9291b49f17e80fe0a","trusted":true},"outputs":[],"source":["len(training_set_artists)"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"8b1cd478370459daba02120d7613350baadd0518","trusted":true},"outputs":[],"source":["print(training_set_artists)"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"598d6d1189366f72d179c1f88ac026dade7dc1de","trusted":true},"outputs":[],"source":["def testing_new_images(results, training_set_artists):  \n","    count = 0\n","    match = 0\n","    unexpected_count = 0\n","    unexpected_match = 0\n","    match_both_expected_unexpected = 0\n","\n","    for p, r in zip(results['Predictions'], results['Real Values']):\n","        if r in training_set_artists:\n","            count += 1\n","            if p == r:\n","                match += 1\n","        else:\n","            unexpected_count += 1\n","            if p == r:\n","                unexpected_match += 1\n","\n","    print(\"test accuracy on new images for TRAINED artsits\")\n","    acc = match/count\n","    print(match,\"/\",count,\"=\",\"{:.4f}\".format(acc))\n","\n","    print(\"test accuracy on new images for UNEXPECTED artsits\")\n","    u_acc = unexpected_match/unexpected_count\n","    print(unexpected_match,\"/\",unexpected_count,\"=\",\"{:.4f}\".format(u_acc))\n","\n","    print(\"test accuracy on new images\")\n","    total_match = match+unexpected_match\n","    total_count = count+unexpected_count\n","    total_acc = (total_match)/(total_count)\n","    print(total_match,\"/\",total_count,\"=\",\"{:.4f}\".format(total_acc))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["testing_new_images(results_adam, training_set_artists)"]},{"cell_type":"markdown","metadata":{},"source":["## SGD"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["test_gen.reset()\n","pred_sgd = model_sgd.predict_generator(test_gen, verbose=1, steps=PRED_STEPS)\n","print(len(pred_sgd),\"\\n\",pred_sgd)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["predicted_class_indices_sgd = np.argmax(pred_sgd,axis=1)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["results_sgd = retrieve_results(predicted_class_indices_sgd, train_gens)\n","results_sgd.head()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(len(training_set_artists))\n","print(training_set_artists)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["testing_new_images(results_sgd, training_set_artists)"]},{"cell_type":"markdown","metadata":{},"source":["## RMSprop"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["test_gen.reset()\n","pred_RMS = model_RMS.predict_generator(test_gen, verbose=1, steps=PRED_STEPS)\n","print(len(pred_RMS),\"\\n\",pred_RMS)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["predicted_class_indices_RMS = np.argmax(pred_RMS,axis=1)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["results_RMS = retrieve_results(predicted_class_indices_RMS, train_gens)\n","results_RMS.head()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(len(training_set_artists))\n","print(training_set_artists)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["testing_new_images(results_RMS, training_set_artists)"]},{"cell_type":"markdown","metadata":{"_uuid":"b71eebdaf00b0fa1d0b1401d8e00dff4a7b5111e"},"source":["So, it seems like the model may have learned some interesting patterns related to the artists that it expects. \n","\n","**Questions to explore:**\n","* [What does the model actually \"see\"](https://arxiv.org/abs/1312.6034) in a painting by [Pablo Picasso](https://www.wikiart.org/en/pablo-picasso/) as opposed to [Vincent van Gogh](https://www.wikiart.org/en/vincent-van-gogh)?\n","* What would happen if we trained the model on the full artist dataset or at least on artists with over 200 paintings in the dataset?\n","* Can the accuracy be improved with techniques like data augmentation or with a custom convolutional neural network? How about doing transfer learning with different [pre-trained model](https://keras.io/applications)?\n","* How can the learning rate be tuned to improve the accuracy?\n","* Would a regularization technique like [dropout](https://machinelearningmastery.com/dropout-regularization-deep-learning-models-keras/) be helpful?\n","* This notebook uses the [Adam](https://keras.io/optimizers/#adam) optimizer... what if we tried RMSprop?\n","* How about using an [ensemble of models](https://machinelearningmastery.com/ensemble-machine-learning-algorithms-python-scikit-learn/)?"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"}},"nbformat":4,"nbformat_minor":1}
